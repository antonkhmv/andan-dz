{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HSE 2021: Mathematical Methods for Data Analysis\n",
    "\n",
    "## Homework 2\n",
    "\n",
    "### Attention!\n",
    "* For tasks where <ins>text answer</ins> is required **Russian language** is **allowed**.\n",
    "* If a task asks you to describe something (make coclusions) then **text answer** is **mandatory** and **is** part of the task\n",
    "* We **only** accept **ipynb** notebooks. If you use Google Colab then you'll have to download the notebook before passing the homework\n",
    "* **Do not** use python loops instead of NumPy vector operations over NumPy vectors - it significantly decreases performance (see why https://blog.paperspace.com/numpy-optimization-vectorization-and-broadcasting/), will be punished with -0.25 for **every** task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T16:48:20.566549Z",
     "start_time": "2020-09-26T16:48:19.893995Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn import datasets\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set(style=\"darkgrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "For this homework we use Boston Dataset from sklearn (based on UCI ML housing dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this case special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows:\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and:\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "data = load_boston() # load dataset\n",
    "\n",
    "data_X = data.data\n",
    "data_Y = data.target\n",
    "data_Columns = data.feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. [0.5 points] \n",
    "Create Pandas DataFrame and split the data into train and test sets with ratio 80:20 with random_state=0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Splitting\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_X, data_Y, train_size=.8, random_state=0)\n",
    "\n",
    "# Normalization\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "# Creating data frames\n",
    "X_train = pd.DataFrame(data=X_train, columns=data_Columns, index=np.arange(len(X_train)))\n",
    "X_test = pd.DataFrame(data=X_test, columns=data_Columns, index=np.arange(len(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 2. [1 point] \n",
    "Train models on train data using StatsModels( or sckit-learn) library and apply it to the test set; use $RMSE$ and $R^2$ as the quality measure.\n",
    "\n",
    "* [`LinearRegression`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html);\n",
    "* [`Ridge`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html) with $\\alpha = 0.01$;\n",
    "* [`Lasso`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html) with $\\alpha = 0.01$\n",
    "\n",
    "Don't forget to scale the data before training the models with StandardScaler!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression() rmse score = 5.926; r2 score = 0.569\n",
      "Ridge(alpha=0.01) rmse score = 5.926; r2 score = 0.569\n",
      "Lasso(alpha=0.01) rmse score = 5.937; r2 score = 0.567\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "\n",
    "clsfs = [\n",
    "    LinearRegression(),\n",
    "    Ridge(alpha=0.01),\n",
    "    Lasso(alpha=0.01)\n",
    "]\n",
    "\n",
    "for clsf in clsfs:\n",
    "    clsf.fit(X_train, y_train)\n",
    "    y = clsf.predict(X_test)\n",
    "    print(f\"{str(clsf)} rmse score = {mean_squared_error(y_test, y, squared=False):.3f}\"\n",
    "    + f\"; r2 score = {r2_score(y_test, y):.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 3. [1 point] \n",
    "Explore the values of the parameters of the resulting models and compare the number of zero weights in them. \n",
    "\n",
    "Comment on the significance of the coefficients, overal model significance and other related factors from the results table. \n",
    "\n",
    "`Hint` Use StatModels to obtain significance of the coefficients. They ca be found on the `summary` of the fitted linear model. \n",
    "It might be tricky to obtain `summary` for the regularized model. Please, read the documentation of the StatModels library to figure out how to do that, e.g.   [OLSResults](https://www.statsmodels.org/stable/generated/statsmodels.regression.linear_model.OLSResults.html#statsmodels.regression.linear_model.OLSResults) class might be useful here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients for LinearRegression()\n",
      "intercept = 22.611881188118836\n",
      "LSTAT -> -3.592\n",
      "DIS -> -2.881\n",
      "RM -> 2.573\n",
      "PTRATIO -> -2.293\n",
      "RAD -> 2.112\n",
      "TAX -> -1.875\n",
      "NOX -> -1.855\n",
      "ZN -> 1.057\n",
      "CRIM -> -0.971\n",
      "B -> 0.718\n",
      "CHAS -> 0.595\n",
      "AGE -> -0.088\n",
      "INDUS -> 0.038\n",
      "\n",
      "Coefficients for Ridge(alpha=0.01)\n",
      "intercept = 22.611881188118836\n",
      "LSTAT -> -3.592\n",
      "DIS -> -2.881\n",
      "RM -> 2.573\n",
      "PTRATIO -> -2.293\n",
      "RAD -> 2.111\n",
      "TAX -> -1.875\n",
      "NOX -> -1.855\n",
      "ZN -> 1.057\n",
      "CRIM -> -0.971\n",
      "B -> 0.718\n",
      "CHAS -> 0.595\n",
      "AGE -> -0.088\n",
      "INDUS -> 0.038\n",
      "\n",
      "Coefficients for Lasso(alpha=0.01)\n",
      "intercept = 22.611881188118836\n",
      "LSTAT -> -3.596\n",
      "DIS -> -2.809\n",
      "RM -> 2.585\n",
      "PTRATIO -> -2.279\n",
      "RAD -> 1.956\n",
      "NOX -> -1.804\n",
      "TAX -> -1.738\n",
      "ZN -> 1.022\n",
      "CRIM -> -0.940\n",
      "B -> 0.705\n",
      "CHAS -> 0.595\n",
      "AGE -> -0.069\n",
      "INDUS -> -0.000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for clsf in clsfs:\n",
    "    arr = clsf.coef_\n",
    "    print(f'Coefficients for {str(clsf)}')\n",
    "    print(f\"intercept = {clsf.intercept_}\")\n",
    "    # In order of importance\n",
    "    for i in np.argsort(-np.abs(arr)):\n",
    "        print(f'{data_Columns[i]} -> {arr[i]:.3f}')\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Conclusion```\n",
    "\n",
    "There are two almost-zero parameters: AGE and INDUS\n",
    "\n",
    "Most coefficients are significant (abs is >1 with intercept = 22.6) so most features are relevant to the model\n",
    "\n",
    "About 57% of the variance in target is explained by the model (R2 score) which is pretty decent.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 4. [1 point] \n",
    "Implement one of the elimination algorithms that were described in the Seminar_4 (Elimination by P-value, Forward elimination, Backward elimination), make conclusions. \n",
    "It's enough to apply to one of the models above (e.g simple linear regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backward elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "data_X = scaler.fit_transform(data_X)\n",
    "data_X = pd.DataFrame(data=data_X, columns=data_Columns, index=np.arange(len(data_X)))\n",
    "\n",
    "y = data_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "eliminated = []\n",
    "features = list(data_Columns)\n",
    "loss_history = []\n",
    "\n",
    "while len(features) > 1:\n",
    "    X = data_X[features]\n",
    "    X = sm.add_constant(X)\n",
    "    model = sm.OLS(y, X)\n",
    "    res = model.fit()\n",
    "    s = res.summary2()\n",
    "    t = s.tables[1]['P>|t|']\n",
    "    \n",
    "    worst_index = t.argmax() - 1\n",
    "    \n",
    "    # R2-adjusted\n",
    "    score = float(s.tables[0][1][6])\n",
    "    \n",
    "    if len(loss_history) and loss_history[-1] > score:\n",
    "        break\n",
    "    else:\n",
    "        loss_history.append( score )\n",
    "        eliminated.append(features[worst_index])\n",
    "        del features[worst_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 3 artists>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_history=np.array(loss_history)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.bar(eliminated, loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CRIM', 'ZN', 'NOX', 'RM', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Conclusion```\n",
    "\n",
    "The score was best before deleting the feature 'CHAS' so the remaining features are:\n",
    "\n",
    "'CRIM', 'ZN', 'NOX', 'RM', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 5. [1 point] \n",
    "Find the best (in terms of RMSE) $\\alpha$ for Ridge regression using cross-validation with 5 folds. You must select values from range $[10^{-4}, 10^{3}]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.00199475, 0.00199475, 0.00119658, 0.00199442, 0.00139651,\n",
       "        0.00119677, 0.00179505, 0.00179496, 0.00139604, 0.00199456,\n",
       "        0.00199466, 0.00179515, 0.00159569, 0.0021946 , 0.00219369,\n",
       "        0.00159554, 0.0019949 , 0.00199485, 0.00179548, 0.00179501,\n",
       "        0.0019948 , 0.00119681, 0.0017951 , 0.00199428, 0.00119696,\n",
       "        0.00179491, 0.0009974 , 0.00119705, 0.0015955 , 0.00119681,\n",
       "        0.00179501, 0.00199413, 0.00199537, 0.00199461, 0.00199456,\n",
       "        0.00139618, 0.00199475, 0.00219421, 0.00159569, 0.00179496,\n",
       "        0.00139613, 0.00199451, 0.00199451, 0.00199432, 0.00199447,\n",
       "        0.00159569, 0.00099735, 0.00159559, 0.0009974 , 0.00159602,\n",
       "        0.00159574, 0.00199475, 0.00199461, 0.00219402, 0.00179501,\n",
       "        0.0017952 , 0.00159578, 0.00139632, 0.00139651, 0.0019948 ,\n",
       "        0.00219407, 0.0017952 , 0.00139604, 0.00199471, 0.00119677,\n",
       "        0.0015955 , 0.00099754, 0.00159578, 0.00199447, 0.00199456,\n",
       "        0.00179505, 0.00179558, 0.00219407, 0.00239372, 0.00219431,\n",
       "        0.0017951 , 0.00159526, 0.00199418, 0.00179548, 0.00179558,\n",
       "        0.00199442, 0.00099721, 0.0017952 , 0.00139647, 0.00179486,\n",
       "        0.00199442, 0.00159559, 0.00139608, 0.00139604, 0.00199471,\n",
       "        0.00139632, 0.00139632, 0.0015955 , 0.00159569, 0.00159545,\n",
       "        0.00139632, 0.00179505, 0.00099735, 0.00119705, 0.00139632]),\n",
       " 'std_fit_time': array([5.35248383e-07, 2.86102295e-07, 3.98898164e-04, 1.78416128e-07,\n",
       "        4.88538777e-04, 3.99041215e-04, 3.98874696e-04, 3.98826628e-04,\n",
       "        4.88636062e-04, 2.78041453e-07, 2.33601546e-07, 3.98683619e-04,\n",
       "        4.88577702e-04, 3.99136639e-04, 3.99352558e-04, 4.88850199e-04,\n",
       "        6.31128077e-04, 6.21719590e-07, 3.99208581e-04, 3.98731517e-04,\n",
       "        2.78041453e-07, 3.98898278e-04, 3.98898306e-04, 3.23406696e-07,\n",
       "        3.99184323e-04, 3.99160399e-04, 2.86102295e-07, 3.99017476e-04,\n",
       "        4.88714100e-04, 3.98778987e-04, 3.98969949e-04, 1.50789149e-07,\n",
       "        9.34406182e-07, 6.31354276e-04, 2.78041453e-07, 4.88616621e-04,\n",
       "        6.30751076e-04, 3.98970377e-04, 4.88772308e-04, 3.98945876e-04,\n",
       "        4.88558203e-04, 2.43140197e-07, 1.90734863e-07, 1.78416128e-07,\n",
       "        1.16800773e-07, 4.88577935e-04, 1.78416128e-07, 4.88791827e-04,\n",
       "        3.56832255e-07, 4.88655531e-04, 4.88713960e-04, 6.30374189e-04,\n",
       "        6.31203613e-04, 3.99781553e-04, 3.98612489e-04, 3.99066285e-04,\n",
       "        4.88947725e-04, 4.88986441e-04, 4.88344078e-04, 1.78416128e-07,\n",
       "        3.99160513e-04, 3.98826656e-04, 4.88441402e-04, 4.15696997e-07,\n",
       "        3.98564549e-04, 4.88519261e-04, 2.61174468e-07, 4.88655601e-04,\n",
       "        2.86102295e-07, 1.78416128e-07, 3.99113328e-04, 3.99256222e-04,\n",
       "        3.99279776e-04, 4.89005910e-04, 7.46314783e-04, 3.99136810e-04,\n",
       "        4.88421929e-04, 3.16297988e-07, 3.98970006e-04, 3.99018103e-04,\n",
       "        2.78041453e-07, 2.43140197e-07, 3.98945905e-04, 4.88772378e-04,\n",
       "        3.98898420e-04, 3.50402318e-07, 4.88499773e-04, 4.88305129e-04,\n",
       "        4.88733398e-04, 1.16800773e-07, 4.88402484e-04, 4.88305175e-04,\n",
       "        4.88421929e-04, 4.88382996e-04, 4.88675027e-04, 4.88597160e-04,\n",
       "        3.98874411e-04, 1.78416128e-07, 3.98898278e-04, 4.88791827e-04]),\n",
       " 'mean_score_time': array([0.00179501, 0.00099721, 0.00159597, 0.00099759, 0.00139599,\n",
       "        0.00119743, 0.00139632, 0.00099764, 0.0011971 , 0.00119691,\n",
       "        0.00119677, 0.00119672, 0.00159588, 0.00139599, 0.0011971 ,\n",
       "        0.00139685, 0.00139627, 0.00119677, 0.00119681, 0.00119691,\n",
       "        0.00119667, 0.001197  , 0.00119681, 0.00099769, 0.00119662,\n",
       "        0.00099759, 0.00139642, 0.00119658, 0.0011971 , 0.0009975 ,\n",
       "        0.00119729, 0.00139675, 0.00099688, 0.00119662, 0.00139651,\n",
       "        0.00159645, 0.00119658, 0.00139627, 0.00159612, 0.001197  ,\n",
       "        0.00159588, 0.0009975 , 0.00099745, 0.00099764, 0.00099769,\n",
       "        0.00099745, 0.00119715, 0.0009975 , 0.00099764, 0.00119667,\n",
       "        0.00159574, 0.001197  , 0.00159602, 0.00119672, 0.00119677,\n",
       "        0.00159564, 0.00099754, 0.00159564, 0.00119672, 0.00099726,\n",
       "        0.00159597, 0.00139623, 0.0011971 , 0.0009973 , 0.0009974 ,\n",
       "        0.00119729, 0.00179515, 0.00099745, 0.00099754, 0.00099745,\n",
       "        0.00139666, 0.00159526, 0.00119658, 0.0009973 , 0.00139589,\n",
       "        0.00159569, 0.0015964 , 0.00139689, 0.00119672, 0.00139613,\n",
       "        0.001197  , 0.00139656, 0.00119677, 0.0009973 , 0.00099773,\n",
       "        0.00099754, 0.0009974 , 0.00099769, 0.001197  , 0.00099726,\n",
       "        0.0009974 , 0.0009973 , 0.00099759, 0.00139632, 0.00139656,\n",
       "        0.00099716, 0.00099754, 0.00099759, 0.00139632, 0.00099726]),\n",
       " 'std_score_time': array([3.98970291e-04, 3.23406696e-07, 4.88519261e-04, 3.50402318e-07,\n",
       "        4.88675027e-04, 3.98826799e-04, 4.88889156e-04, 2.43140197e-07,\n",
       "        3.98755084e-04, 3.98850623e-04, 3.99041300e-04, 3.99303693e-04,\n",
       "        4.88928500e-04, 4.88577889e-04, 3.98874468e-04, 4.88460832e-04,\n",
       "        4.89317425e-04, 3.98564378e-04, 3.99017362e-04, 3.99088927e-04,\n",
       "        3.98850509e-04, 3.98802796e-04, 3.99136696e-04, 4.15696997e-07,\n",
       "        3.98993617e-04, 3.16297988e-07, 4.88616597e-04, 3.98778958e-04,\n",
       "        3.98874525e-04, 1.78416128e-07, 3.99136696e-04, 4.88733793e-04,\n",
       "        1.78416128e-07, 3.98755654e-04, 4.88441425e-04, 4.88811420e-04,\n",
       "        3.99494541e-04, 4.88538730e-04, 4.88636341e-04, 3.98922081e-04,\n",
       "        4.88538753e-04, 1.78416128e-07, 1.90734863e-07, 4.42200589e-07,\n",
       "        1.90734863e-07, 3.87384339e-07, 3.98731289e-04, 3.81469727e-07,\n",
       "        2.43140197e-07, 3.98492856e-04, 4.88909419e-04, 3.99518223e-04,\n",
       "        4.88656112e-04, 3.98826742e-04, 3.98684275e-04, 4.88246827e-04,\n",
       "        5.00111031e-07, 4.88441472e-04, 3.98588195e-04, 3.50402318e-07,\n",
       "        4.88616760e-04, 4.88480312e-04, 3.98993588e-04, 2.61174468e-07,\n",
       "        1.90734863e-07, 3.98779044e-04, 3.98564406e-04, 4.67203091e-07,\n",
       "        3.01578299e-07, 2.43140197e-07, 4.88422022e-04, 4.88908768e-04,\n",
       "        3.98660002e-04, 2.13248060e-07, 4.88558226e-04, 4.88480312e-04,\n",
       "        4.88480429e-04, 4.88811513e-04, 3.99184266e-04, 4.88363535e-04,\n",
       "        3.98922024e-04, 4.88597113e-04, 3.98922081e-04, 1.50789149e-07,\n",
       "        5.09122765e-07, 4.26496120e-07, 1.90734863e-07, 2.43140197e-07,\n",
       "        3.98922052e-04, 1.78416128e-07, 3.56832255e-07, 1.50789149e-07,\n",
       "        3.81469727e-07, 4.88402461e-04, 4.88791781e-04, 2.43140197e-07,\n",
       "        3.37174788e-07, 4.62310777e-07, 4.88402600e-04, 2.33601546e-07]),\n",
       " 'param_alpha': masked_array(data=[0.0001, 0.0001176811952434998, 0.00013848863713938732,\n",
       "                    0.00016297508346206434, 0.00019179102616724886,\n",
       "                    0.0002257019719633919, 0.00026560877829466864,\n",
       "                    0.00031257158496882353, 0.0003678379771828634,\n",
       "                    0.0004328761281083057, 0.000509413801481638,\n",
       "                    0.0005994842503189409, 0.0007054802310718645,\n",
       "                    0.0008302175681319744, 0.0009770099572992247,\n",
       "                    0.0011497569953977356, 0.0013530477745798076,\n",
       "                    0.0015922827933410922, 0.001873817422860383,\n",
       "                    0.0022051307399030455, 0.002595024211399737,\n",
       "                    0.0030538555088334154, 0.003593813663804626,\n",
       "                    0.0042292428743894986, 0.0049770235643321085,\n",
       "                    0.005857020818056662, 0.006892612104349695,\n",
       "                    0.008111308307896872, 0.009545484566618337,\n",
       "                    0.011233240329780276, 0.013219411484660288,\n",
       "                    0.015556761439304723, 0.01830738280295368,\n",
       "                    0.021544346900318822, 0.025353644939701114,\n",
       "                    0.029836472402833374, 0.03511191734215131,\n",
       "                    0.04132012400115335, 0.04862601580065353,\n",
       "                    0.057223676593502144, 0.06734150657750822,\n",
       "                    0.0792482898353917, 0.093260334688322,\n",
       "                    0.10974987654930557, 0.1291549665014884,\n",
       "                    0.1519911082952933, 0.1788649529057435,\n",
       "                    0.21049041445120198, 0.2477076355991709,\n",
       "                    0.2915053062825176, 0.34304692863149155,\n",
       "                    0.40370172585965536, 0.4750810162102793,\n",
       "                    0.5590810182512223, 0.6579332246575675,\n",
       "                    0.774263682681127, 0.9111627561154887,\n",
       "                    1.072267222010323, 1.261856883066021,\n",
       "                    1.4849682622544635, 1.747528400007683,\n",
       "                    2.0565123083486516, 2.4201282647943834,\n",
       "                    2.848035868435799, 3.351602650938841,\n",
       "                    3.944206059437656, 4.641588833612772,\n",
       "                    5.462277217684337, 6.4280731172843195,\n",
       "                    7.56463327554629, 8.902150854450374, 10.47615752789664,\n",
       "                    12.32846739442066, 14.508287784959402,\n",
       "                    17.073526474706888, 20.09233002565046,\n",
       "                    23.644894126454073, 27.825594022071257,\n",
       "                    32.74549162877725, 38.53528593710527,\n",
       "                    45.34878508128582, 53.36699231206302,\n",
       "                    62.80291441834247, 73.90722033525775,\n",
       "                    86.97490026177834, 102.35310218990247,\n",
       "                    120.45035402587811, 141.74741629268047,\n",
       "                    166.81005372000593, 196.30406500402685,\n",
       "                    231.01297000831582, 271.85882427329403,\n",
       "                    319.92671377973846, 376.49358067924635,\n",
       "                    443.06214575838777, 521.4008287999684,\n",
       "                    613.5907273413163, 722.0809018385456,\n",
       "                    849.7534359086438, 1000.0],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'alpha': 0.0001},\n",
       "  {'alpha': 0.0001176811952434998},\n",
       "  {'alpha': 0.00013848863713938732},\n",
       "  {'alpha': 0.00016297508346206434},\n",
       "  {'alpha': 0.00019179102616724886},\n",
       "  {'alpha': 0.0002257019719633919},\n",
       "  {'alpha': 0.00026560877829466864},\n",
       "  {'alpha': 0.00031257158496882353},\n",
       "  {'alpha': 0.0003678379771828634},\n",
       "  {'alpha': 0.0004328761281083057},\n",
       "  {'alpha': 0.000509413801481638},\n",
       "  {'alpha': 0.0005994842503189409},\n",
       "  {'alpha': 0.0007054802310718645},\n",
       "  {'alpha': 0.0008302175681319744},\n",
       "  {'alpha': 0.0009770099572992247},\n",
       "  {'alpha': 0.0011497569953977356},\n",
       "  {'alpha': 0.0013530477745798076},\n",
       "  {'alpha': 0.0015922827933410922},\n",
       "  {'alpha': 0.001873817422860383},\n",
       "  {'alpha': 0.0022051307399030455},\n",
       "  {'alpha': 0.002595024211399737},\n",
       "  {'alpha': 0.0030538555088334154},\n",
       "  {'alpha': 0.003593813663804626},\n",
       "  {'alpha': 0.0042292428743894986},\n",
       "  {'alpha': 0.0049770235643321085},\n",
       "  {'alpha': 0.005857020818056662},\n",
       "  {'alpha': 0.006892612104349695},\n",
       "  {'alpha': 0.008111308307896872},\n",
       "  {'alpha': 0.009545484566618337},\n",
       "  {'alpha': 0.011233240329780276},\n",
       "  {'alpha': 0.013219411484660288},\n",
       "  {'alpha': 0.015556761439304723},\n",
       "  {'alpha': 0.01830738280295368},\n",
       "  {'alpha': 0.021544346900318822},\n",
       "  {'alpha': 0.025353644939701114},\n",
       "  {'alpha': 0.029836472402833374},\n",
       "  {'alpha': 0.03511191734215131},\n",
       "  {'alpha': 0.04132012400115335},\n",
       "  {'alpha': 0.04862601580065353},\n",
       "  {'alpha': 0.057223676593502144},\n",
       "  {'alpha': 0.06734150657750822},\n",
       "  {'alpha': 0.0792482898353917},\n",
       "  {'alpha': 0.093260334688322},\n",
       "  {'alpha': 0.10974987654930557},\n",
       "  {'alpha': 0.1291549665014884},\n",
       "  {'alpha': 0.1519911082952933},\n",
       "  {'alpha': 0.1788649529057435},\n",
       "  {'alpha': 0.21049041445120198},\n",
       "  {'alpha': 0.2477076355991709},\n",
       "  {'alpha': 0.2915053062825176},\n",
       "  {'alpha': 0.34304692863149155},\n",
       "  {'alpha': 0.40370172585965536},\n",
       "  {'alpha': 0.4750810162102793},\n",
       "  {'alpha': 0.5590810182512223},\n",
       "  {'alpha': 0.6579332246575675},\n",
       "  {'alpha': 0.774263682681127},\n",
       "  {'alpha': 0.9111627561154887},\n",
       "  {'alpha': 1.072267222010323},\n",
       "  {'alpha': 1.261856883066021},\n",
       "  {'alpha': 1.4849682622544635},\n",
       "  {'alpha': 1.747528400007683},\n",
       "  {'alpha': 2.0565123083486516},\n",
       "  {'alpha': 2.4201282647943834},\n",
       "  {'alpha': 2.848035868435799},\n",
       "  {'alpha': 3.351602650938841},\n",
       "  {'alpha': 3.944206059437656},\n",
       "  {'alpha': 4.641588833612772},\n",
       "  {'alpha': 5.462277217684337},\n",
       "  {'alpha': 6.4280731172843195},\n",
       "  {'alpha': 7.56463327554629},\n",
       "  {'alpha': 8.902150854450374},\n",
       "  {'alpha': 10.47615752789664},\n",
       "  {'alpha': 12.32846739442066},\n",
       "  {'alpha': 14.508287784959402},\n",
       "  {'alpha': 17.073526474706888},\n",
       "  {'alpha': 20.09233002565046},\n",
       "  {'alpha': 23.644894126454073},\n",
       "  {'alpha': 27.825594022071257},\n",
       "  {'alpha': 32.74549162877725},\n",
       "  {'alpha': 38.53528593710527},\n",
       "  {'alpha': 45.34878508128582},\n",
       "  {'alpha': 53.36699231206302},\n",
       "  {'alpha': 62.80291441834247},\n",
       "  {'alpha': 73.90722033525775},\n",
       "  {'alpha': 86.97490026177834},\n",
       "  {'alpha': 102.35310218990247},\n",
       "  {'alpha': 120.45035402587811},\n",
       "  {'alpha': 141.74741629268047},\n",
       "  {'alpha': 166.81005372000593},\n",
       "  {'alpha': 196.30406500402685},\n",
       "  {'alpha': 231.01297000831582},\n",
       "  {'alpha': 271.85882427329403},\n",
       "  {'alpha': 319.92671377973846},\n",
       "  {'alpha': 376.49358067924635},\n",
       "  {'alpha': 443.06214575838777},\n",
       "  {'alpha': 521.4008287999684},\n",
       "  {'alpha': 613.5907273413163},\n",
       "  {'alpha': 722.0809018385456},\n",
       "  {'alpha': 849.7534359086438},\n",
       "  {'alpha': 1000.0}],\n",
       " 'split0_test_score': array([-3.52991302, -3.52991265, -3.52991222, -3.52991171, -3.52991111,\n",
       "        -3.52991041, -3.52990958, -3.5299086 , -3.52990746, -3.52990611,\n",
       "        -3.52990452, -3.52990265, -3.52990045, -3.52989786, -3.52989481,\n",
       "        -3.52989122, -3.529887  , -3.52988204, -3.52987619, -3.52986931,\n",
       "        -3.52986122, -3.52985169, -3.52984049, -3.52982729, -3.52981177,\n",
       "        -3.52979351, -3.52977201, -3.52974672, -3.52971696, -3.52968193,\n",
       "        -3.52964072, -3.52959223, -3.52953516, -3.52946802, -3.52938903,\n",
       "        -3.52929608, -3.52918672, -3.52905807, -3.52890672, -3.52872868,\n",
       "        -3.52851925, -3.52827293, -3.52798324, -3.52764259, -3.52724205,\n",
       "        -3.52677119, -3.52621775, -3.52556738, -3.52480331, -3.52390593,\n",
       "        -3.52285233, -3.52161584, -3.52016539, -3.51846493, -3.51647267,\n",
       "        -3.51414034, -3.51141238, -3.50822505, -3.50450561, -3.5001715 ,\n",
       "        -3.49512969, -3.48927617, -3.48249585, -3.47466297, -3.46564221,\n",
       "        -3.45529087, -3.44346235, -3.4300114 , -3.41480153, -3.39771497,\n",
       "        -3.37866578, -3.35761615, -3.33459637, -3.30972787, -3.28324896,\n",
       "        -3.25554158, -3.22715694, -3.19883679, -3.17152641, -3.14637496,\n",
       "        -3.12471933, -3.10804844, -3.09794724, -3.09602206, -3.1038114 ,\n",
       "        -3.1226887 , -3.15376444, -3.19779539, -3.25510827, -3.3255443 ,\n",
       "        -3.40843059, -3.50258322, -3.60634645, -3.71766971, -3.83422133,\n",
       "        -3.95353269, -4.07316192, -4.19086125, -4.30472945, -4.41333059]),\n",
       " 'split1_test_score': array([-5.10378223, -5.10378174, -5.10378117, -5.1037805 , -5.1037797 ,\n",
       "        -5.10377877, -5.10377767, -5.10377638, -5.10377486, -5.10377307,\n",
       "        -5.10377097, -5.10376849, -5.10376557, -5.10376214, -5.1037581 ,\n",
       "        -5.10375335, -5.10374776, -5.10374118, -5.10373344, -5.10372432,\n",
       "        -5.1037136 , -5.10370098, -5.10368613, -5.10366866, -5.1036481 ,\n",
       "        -5.1036239 , -5.10359542, -5.10356192, -5.10352249, -5.1034761 ,\n",
       "        -5.10342151, -5.10335728, -5.1032817 , -5.10319279, -5.10308817,\n",
       "        -5.1029651 , -5.10282031, -5.10264999, -5.10244965, -5.10221403,\n",
       "        -5.10193692, -5.10161107, -5.10122795, -5.10077757, -5.10024823,\n",
       "        -5.09962622, -5.09889551, -5.09803737, -5.09702996, -5.0958478 ,\n",
       "        -5.09446131, -5.09283615, -5.09093258, -5.08870481, -5.08610019,\n",
       "        -5.0830586 , -5.07951167, -5.0753823 , -5.07058429, -5.06502238,\n",
       "        -5.05859284, -5.05118481, -5.04268288, -5.03297114, -5.02193921,\n",
       "        -5.00949089, -4.99555561, -4.98010332, -4.96316255, -4.94484121,\n",
       "        -4.92534875, -4.90501733, -4.88431857, -4.86387188, -4.84443999,\n",
       "        -4.82690891, -4.8122517 , -4.80147951, -4.79558736, -4.7955052 ,\n",
       "        -4.8020651 , -4.81599261, -4.8379237 , -4.86844179, -4.90812278,\n",
       "        -4.95757308, -5.01744697, -5.08843421, -5.17121571, -5.26639223,\n",
       "        -5.37439701, -5.49540704, -5.62926869, -5.77545179, -5.93304133,\n",
       "        -6.10076942, -6.27708257, -6.46023282, -6.64837715, -6.83966947]),\n",
       " 'split2_test_score': array([-5.75101108, -5.75101094, -5.75101076, -5.75101056, -5.75101032,\n",
       "        -5.75101004, -5.75100971, -5.75100932, -5.75100887, -5.75100833,\n",
       "        -5.75100769, -5.75100695, -5.75100607, -5.75100504, -5.75100383,\n",
       "        -5.7510024 , -5.75100072, -5.75099874, -5.75099641, -5.75099367,\n",
       "        -5.75099044, -5.75098665, -5.75098218, -5.75097693, -5.75097074,\n",
       "        -5.75096347, -5.75095491, -5.75094483, -5.75093298, -5.75091903,\n",
       "        -5.75090263, -5.75088332, -5.75086061, -5.75083389, -5.75080246,\n",
       "        -5.75076549, -5.75072202, -5.75067088, -5.75061076, -5.75054007,\n",
       "        -5.75045698, -5.75035932, -5.75024456, -5.75010976, -5.74995147,\n",
       "        -5.74976565, -5.74954761, -5.74929191, -5.74899222, -5.74864123,\n",
       "        -5.74823051, -5.74775037, -5.74718974, -5.74653604, -5.74577507,\n",
       "        -5.74489095, -5.74386611, -5.74268134, -5.7413161 , -5.73974886,\n",
       "        -5.73795786, -5.73592214, -5.73362314, -5.73104687, -5.72818689,\n",
       "        -5.72504818, -5.72165226, -5.71804341, -5.71429638, -5.7105255 ,\n",
       "        -5.70689516, -5.7036315 , -5.7010351 , -5.69949408, -5.69949724,\n",
       "        -5.70164625, -5.70666624, -5.71541346, -5.72887894, -5.7481865 ,\n",
       "        -5.77458393, -5.80942564, -5.85414574, -5.91022048, -5.9791196 ,\n",
       "        -6.06224643, -6.16086764, -6.27603502, -6.40850357, -6.55865324,\n",
       "        -6.72642358, -6.91127247, -7.11216871, -7.32762461, -7.55576859,\n",
       "        -7.79444988, -8.04136114, -8.29416065, -8.55057609, -8.80847663]),\n",
       " 'split3_test_score': array([-8.98678727, -8.98678702, -8.98678672, -8.98678637, -8.98678596,\n",
       "        -8.98678547, -8.9867849 , -8.98678423, -8.98678344, -8.98678251,\n",
       "        -8.98678142, -8.98678013, -8.98677861, -8.98677683, -8.98677473,\n",
       "        -8.98677226, -8.98676935, -8.98676593, -8.98676191, -8.98675717,\n",
       "        -8.98675159, -8.98674503, -8.98673731, -8.98672823, -8.98671754,\n",
       "        -8.98670495, -8.98669015, -8.98667272, -8.98665222, -8.98662809,\n",
       "        -8.98659969, -8.98656628, -8.98652696, -8.98648068, -8.98642623,\n",
       "        -8.98636215, -8.98628674, -8.98619801, -8.98609359, -8.98597073,\n",
       "        -8.98582615, -8.98565603, -8.98545586, -8.98522033, -8.98494322,\n",
       "        -8.98461717, -8.98423359, -8.98378231, -8.98325145, -8.982627  ,\n",
       "        -8.98189251, -8.98102869, -8.98001289, -8.97881852, -8.97741442,\n",
       "        -8.97576412, -8.97382489, -8.97154685, -8.96887173, -8.96573172,\n",
       "        -8.96204796, -8.95772912, -8.95266975, -8.94674868, -8.93982746,\n",
       "        -8.93174907, -8.922337  , -8.91139515, -8.89870876, -8.88404702,\n",
       "        -8.86716767, -8.84782432, -8.82577678, -8.80080469, -8.77272433,\n",
       "        -8.74140788, -8.70680392, -8.66895742, -8.62802702, -8.58429745,\n",
       "        -8.53818544, -8.49023818, -8.44112474, -8.39162135, -8.34259242,\n",
       "        -8.29496864, -8.24972277, -8.20784271, -8.17030063, -8.13801703,\n",
       "        -8.11182039, -8.09240534, -8.08029547, -8.07581916, -8.07910634,\n",
       "        -8.09011125, -8.10866003, -8.13451464, -8.16743818, -8.20724378]),\n",
       " 'split4_test_score': array([-5.77178775, -5.77178664, -5.77178533, -5.77178379, -5.77178197,\n",
       "        -5.77177984, -5.77177732, -5.77177437, -5.77177089, -5.77176679,\n",
       "        -5.77176197, -5.7717563 , -5.77174962, -5.77174177, -5.77173252,\n",
       "        -5.77172164, -5.77170884, -5.77169378, -5.77167605, -5.77165519,\n",
       "        -5.77163064, -5.77160175, -5.77156776, -5.77152775, -5.77148068,\n",
       "        -5.77142529, -5.77136011, -5.77128341, -5.77119317, -5.77108699,\n",
       "        -5.77096205, -5.77081506, -5.77064212, -5.77043866, -5.77019931,\n",
       "        -5.76991775, -5.76958658, -5.76919707, -5.76873899, -5.76820035,\n",
       "        -5.76756705, -5.76682259, -5.76594761, -5.76491948, -5.7637117 ,\n",
       "        -5.76229332, -5.76062823, -5.75867436, -5.75638276, -5.75369665,\n",
       "        -5.75055029, -5.7468678 , -5.74256191, -5.73753268, -5.7316662 ,\n",
       "        -5.72483342, -5.7168892 , -5.70767165, -5.69700211, -5.68468583,\n",
       "        -5.67051385, -5.65426623, -5.63571712, -5.61464198, -5.5908272 ,\n",
       "        -5.56408224, -5.53425402, -5.50124317, -5.46502075, -5.42564414,\n",
       "        -5.38326956, -5.33815921, -5.29068032, -5.2412946 , -5.19053764,\n",
       "        -5.13898917, -5.08723748, -5.03584237, -4.98530248, -4.93603253,\n",
       "        -4.88835552, -4.84251315, -4.79869544, -4.75708884, -4.71793931,\n",
       "        -4.6816256 , -4.64873596, -4.62014017, -4.59704812, -4.58104514,\n",
       "        -4.57409462, -4.57849925, -4.59681464, -4.63171301, -4.68580142,\n",
       "        -4.76140678, -4.8603489 , -4.98372901, -5.1317627 , -5.3036816 ]),\n",
       " 'mean_test_score': array([-5.82865627, -5.8286558 , -5.82865524, -5.82865458, -5.82865381,\n",
       "        -5.82865291, -5.82865184, -5.82865058, -5.8286491 , -5.82864736,\n",
       "        -5.82864531, -5.8286429 , -5.82864007, -5.82863673, -5.8286328 ,\n",
       "        -5.82862818, -5.82862273, -5.82861633, -5.8286088 , -5.82859993,\n",
       "        -5.8285895 , -5.82857722, -5.82856277, -5.82854577, -5.82852577,\n",
       "        -5.82850222, -5.82847452, -5.82844192, -5.82840356, -5.82835843,\n",
       "        -5.82830532, -5.82824283, -5.82816931, -5.82808281, -5.82798104,\n",
       "        -5.82786131, -5.82772047, -5.8275548 , -5.82735994, -5.82713077,\n",
       "        -5.82686127, -5.82654439, -5.82617185, -5.82573395, -5.82521933,\n",
       "        -5.82461471, -5.82390454, -5.82307067, -5.82209194, -5.82094372,\n",
       "        -5.81959739, -5.81801977, -5.8161725 , -5.81401139, -5.81148571,\n",
       "        -5.80853749, -5.80510085, -5.80110144, -5.79645597, -5.79107206,\n",
       "        -5.78484844, -5.77767569, -5.76943775, -5.76001433, -5.74928459,\n",
       "        -5.73713225, -5.72345225, -5.70815929, -5.691198  , -5.67255457,\n",
       "        -5.65226939, -5.6304497 , -5.60728143, -5.58303862, -5.55808963,\n",
       "        -5.53289876, -5.50802325, -5.48410591, -5.46186444, -5.44207933,\n",
       "        -5.42558186, -5.4132436 , -5.40596737, -5.4046789 , -5.4103171 ,\n",
       "        -5.42382049, -5.44610756, -5.4780495 , -5.52043526, -5.57393039,\n",
       "        -5.63903324, -5.71603347, -5.80497879, -5.90565566, -6.0175878 ,\n",
       "        -6.140054  , -6.27212291, -6.41269967, -6.56057671, -6.71448042]),\n",
       " 'std_test_score': array([1.77722914, 1.7772292 , 1.77722926, 1.77722933, 1.77722942,\n",
       "        1.77722952, 1.77722964, 1.77722978, 1.77722995, 1.77723014,\n",
       "        1.77723037, 1.77723065, 1.77723096, 1.77723134, 1.77723178,\n",
       "        1.7772323 , 1.77723291, 1.77723363, 1.77723448, 1.77723548,\n",
       "        1.77723665, 1.77723803, 1.77723965, 1.77724156, 1.77724381,\n",
       "        1.77724646, 1.77724957, 1.77725324, 1.77725755, 1.77726262,\n",
       "        1.77726859, 1.77727562, 1.77728388, 1.77729361, 1.77730505,\n",
       "        1.77731851, 1.77733434, 1.77735297, 1.77737488, 1.77740065,\n",
       "        1.77743095, 1.77746658, 1.77750848, 1.77755772, 1.7776156 ,\n",
       "        1.77768361, 1.77776349, 1.7778573 , 1.77796741, 1.7780966 ,\n",
       "        1.77824809, 1.7784256 , 1.77863345, 1.77887657, 1.77916063,\n",
       "        1.77949204, 1.77987806, 1.78032674, 1.78084696, 1.78144826,\n",
       "        1.78214068, 1.78293435, 1.78383888, 1.7848625 , 1.78601072,\n",
       "        1.78728459, 1.7886783 , 1.79017626, 1.79174951, 1.79335174,\n",
       "        1.7949152 , 1.79634703, 1.79752669, 1.79830542, 1.79850842,\n",
       "        1.79794041, 1.79639454, 1.7936642 , 1.78955676, 1.78390787,\n",
       "        1.77659546, 1.76755326, 1.75678421, 1.74437479, 1.7305103 ,\n",
       "        1.71548983, 1.69973695, 1.68380041, 1.66833787, 1.6540774 ,\n",
       "        1.6417557 , 1.63203932, 1.62544334, 1.62226821, 1.62257518,\n",
       "        1.62621253, 1.632889  , 1.64227432, 1.65409592, 1.66820135]),\n",
       " 'rank_test_score': array([ 93,  92,  91,  90,  89,  88,  87,  86,  85,  84,  83,  82,  81,\n",
       "         80,  79,  78,  77,  76,  75,  74,  73,  72,  71,  70,  69,  68,\n",
       "         67,  66,  65,  64,  63,  62,  61,  60,  59,  58,  57,  56,  55,\n",
       "         54,  53,  52,  51,  50,  49,  48,  47,  46,  45,  44,  43,  42,\n",
       "         41,  40,  39,  38,  37,  35,  34,  33,  32,  31,  30,  29,  28,\n",
       "         27,  26,  24,  23,  22,  21,  19,  18,  17,  15,  14,  12,  11,\n",
       "          9,   7,   6,   4,   2,   1,   3,   5,   8,  10,  13,  16,  20,\n",
       "         25,  36,  94,  95,  96,  97,  98,  99, 100])}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data_X#[best_features]\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "clsf = Ridge()\n",
    "\n",
    "parameters = {\n",
    "    'alpha': np.logspace(-4, 3, 100), \n",
    "}\n",
    "\n",
    "srch = GridSearchCV(\n",
    "    estimator=clsf,\n",
    "    scoring='neg_root_mean_squared_error', \n",
    "    param_grid=parameters,\n",
    "    \n",
    "#     # Cross-validation splits\n",
    "    cv = 5\n",
    ")\n",
    "\n",
    "srch.fit(X, y)\n",
    "\n",
    "res = srch.cv_results_\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best value of alpha for Ridge is 73.907\n",
      "With a RMSE of 5.405\n"
     ]
    }
   ],
   "source": [
    "best_alpha_index = res['rank_test_score'].argmin()\n",
    "\n",
    "print(f\"The best value of alpha for Ridge is {res['params'][best_alpha_index]['alpha']:.3f}\")\n",
    "print(f\"With a RMSE of {-res['mean_test_score'][best_alpha_index]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1bb7278a400>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ids = np.arange(10,50)\n",
    "plt.figure(figsize=(15,15))\n",
    "\n",
    "plt.xscale('log',base=10)\n",
    "arr = np.array(list(map(lambda x: x['alpha'], res['params'])))\n",
    "vals = res['mean_test_score']\n",
    "\n",
    "plt.plot(arr, vals)\n",
    "plt.scatter([res['params'][best_alpha_index]['alpha']], [res['mean_test_score'][best_alpha_index]], c='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Gradient descent\n",
    "\n",
    "#### 6. [3.5 points] \n",
    "**Implement a linear regression model for the MSE loss function, trained by gradient descent.**\n",
    "\n",
    "All calculations must be vectorized, and python loops can only be used for gradient descent iterations. As a stop criterion, you must use (simultaneously):\n",
    "\n",
    "* checking for the Euclidean norm of the weight difference on two adjacent iterations (for example, less than some small number of the order of $10^{-6}$, set by the `tolerance` parameter);\n",
    "* reaching the maximum number of iterations (for example, 10000, set by the `max_iter` parameter).\n",
    "\n",
    "You need to implement:\n",
    "\n",
    "* Full gradient descent:\n",
    "\n",
    "$$\n",
    "w_{k + 1} = w_{k} - \\eta_{k} \\nabla_{w} Q(w_{k}).\n",
    "$$\n",
    "\n",
    "* Stochastic Gradient Descent:\n",
    "\n",
    "$$\n",
    "w_{k + 1} = w_{k} - \\eta_{k} \\nabla_{w} q_{i_{k}}(w_{k}).\n",
    "$$\n",
    "\n",
    "$\\nabla_{w} q_{i_{k}}(w_{k}) \\, $ is the estimate of the gradient over the batch of objects selected randomly.\n",
    "\n",
    "* Momentum method:\n",
    "\n",
    "$$\n",
    "h_0 = 0, \\\\\n",
    "h_{k + 1} = \\alpha h_{k} + \\eta_k \\nabla_{w} q_{i_{k}} (w_{k}), \\\\\n",
    "w_{k + 1} = w_{k} - h_{k + 1}.\n",
    "$$\n",
    "\n",
    "Exponentially weighed averages can provide a better estimate which is closer to the actual gradient.\n",
    "\n",
    "\n",
    "To make sure that the optimization process really converges, we will use the `loss_history` class attribute. After calling the `fit` method, it should contain the values of the loss function for all iterations, starting from the first one (before the first step on the anti-gradient).\n",
    "\n",
    "You need to initialize the weights with a zero or random (from a normal distribution) vector. The following is a template class that needs to contain the code implementing all variations of the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculations \n",
    "\n",
    "$$\n",
    "\\nabla_{w} Q(w_{k}) = \\nabla_{w} (y-Xw)^{T} (y-Xw) = \\nabla_{w} [y^{T} y - y^{T}Xw - w^{T}X^{T}y + w^{T}X^{T}Xw] =\n",
    "$$\n",
    "\n",
    "$$\n",
    "=\\nabla_{w} [-(y^{T}X)^{T} -X^{T}y + (X^{T}X + (X^{T}X)^{T})w] = -2X^{T}y + 2X^{T}Xw = 2X^{T}(Xw-y).\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class LinReg(BaseEstimator):\n",
    "    def __init__(self, delta=0.2, gd_type='Momentum', \n",
    "                 tolerance=1e-4, max_iter=1000, w0=None, eta=1e-2, alpha=1e-3):\n",
    "        \"\"\"\n",
    "        gd_type: str\n",
    "            'GradientDescent', 'StochasticDescent', 'Momentum'\n",
    "        delta: float\n",
    "            proportion of object in a batch (fot stochastic GD)\n",
    "        tolerance: float\n",
    "            for stopping gradient descent\n",
    "        max_iter: int\n",
    "            maximum number of steps in gradient descent\n",
    "        w0: np.array of shape (d)\n",
    "            init weights\n",
    "        eta: float\n",
    "            learning rate\n",
    "        alpha: float\n",
    "            momentum coefficient\n",
    "        \"\"\"\n",
    "        \n",
    "        self.gd_type = gd_type\n",
    "        self.delta = delta\n",
    "        self.tolerance = tolerance\n",
    "        self.max_iter = max_iter\n",
    "        self.w0 = w0\n",
    "        self.alpha = alpha\n",
    "        self.w = None\n",
    "        self.eta = eta\n",
    "        self.loss_history = None # list of loss function values at each training iteration\n",
    "    \n",
    "    def __full_iter(self, X, y):\n",
    "        self.w -= self.eta * self.calc_gradient(X, y)\n",
    "    \n",
    "    def __stochastic_iter(self, X, y):\n",
    "        randind = np.random.choice(len(X), self.batch_size, replace=False)\n",
    "        rand_X, rand_y = X[randind], y[randind]\n",
    "        self.w -= self.eta * self.calc_gradient(rand_X, rand_y)\n",
    "        \n",
    "    def __momentum_iter(self, X, y):\n",
    "        randind = np.random.choice(len(X), self.batch_size, replace=False)\n",
    "        rand_X, rand_y = X[randind], y[randind]\n",
    "        \n",
    "        dh = self.eta * self.calc_gradient(rand_X, rand_y)\n",
    "        \n",
    "        self.h = self.alpha * self.h + dh\n",
    "        \n",
    "        self.w -= self.h\n",
    "        \n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        X: np.array of shape (l, d)\n",
    "        y: np.array of shape (l)\n",
    "        ---\n",
    "        output: self\n",
    "        \"\"\"\n",
    "        \n",
    "        iterations = 0\n",
    "        \n",
    "        X = np.column_stack([X, np.ones(X.shape[0])])\n",
    "        \n",
    "        if self.w0 is None:\n",
    "            self.w = np.zeros(X.shape[1])\n",
    "            self.w[-1] = np.mean(y)\n",
    "        else:\n",
    "            self.w = np.array(self.w0)\n",
    "        \n",
    "        if self.gd_type == 'Momentum':\n",
    "            self.h = np.zeros(*self.w.shape)\n",
    "            \n",
    "        if self.gd_type != 'GradientDescent':\n",
    "            self.batch_size = int(self.delta * X.shape[0])\n",
    "            assert self.batch_size > 0, 'Batch size is too small.'\n",
    "        \n",
    "        \n",
    "        self.loss_history = [self.calc_loss(X, y)]\n",
    "        \n",
    "        iter_function = {\n",
    "            'GradientDescent' :   self.__full_iter,\n",
    "            'StochasticDescent' : self.__stochastic_iter,\n",
    "            'Momentum' :          self.__momentum_iter\n",
    "        } [self.gd_type]\n",
    "        \n",
    "        while iterations < self.max_iter:\n",
    "            \n",
    "            prev_w = np.array(self.w)\n",
    "            \n",
    "            iter_function(X, y)\n",
    "            \n",
    "            if not np.all(np.isfinite(self.w)):\n",
    "                self.w = prev_w\n",
    "                return self\n",
    "            \n",
    "            self.loss_history.append(self.calc_loss(X, y))\n",
    "            \n",
    "            if np.sqrt(np.sum((prev_w - self.w)**2)) < self.tolerance:\n",
    "                break\n",
    "            \n",
    "            iterations += 1\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if self.w is None:\n",
    "            raise Exception('Not trained yet')\n",
    "        X = np.column_stack([X, np.ones(X.shape[0])])\n",
    "        return X.dot(self.w)\n",
    "    \n",
    "    def __predict(self, X):\n",
    "        return X.dot(self.w)\n",
    "    \n",
    "    def calc_gradient(self, X, y):\n",
    "        \"\"\"\n",
    "        X: np.array of shape (l, d) (l can be equal to 1 if stochastic)\n",
    "        y: np.array of shape (l)\n",
    "        ---\n",
    "        output: np.array of shape (d)\n",
    "        \"\"\"\n",
    "        return 2*X.T.dot(self.__predict(X) - y)\n",
    "\n",
    "    def calc_loss(self, X, y):\n",
    "        \"\"\"\n",
    "        X: np.array of shape (l, d)\n",
    "        y: np.array of shape (l)\n",
    "        ---\n",
    "        output: float \n",
    "        \"\"\" \n",
    "        return np.mean((self.__predict(X) - y)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. [1 points] \n",
    "Train and validate \"hand-written\" model (simple linear regression) on the same data, and compare the quality with the Sklearn or StatsModels methods. Investigate the effect of the `max_iter` and `alpha` parameters on the optimization process. Is it consistent with your expectations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.05396099, 0.1215786 , 0.17194505, 0.18641109, 0.18870034,\n",
       "        0.0550561 , 0.14840488, 0.38947392, 0.43395352, 0.43126221,\n",
       "        0.04767494, 0.13833275, 0.42647409, 0.55513148, 0.55722885,\n",
       "        0.04577847, 0.14491873, 0.41809363, 0.66534286, 0.66504459,\n",
       "        0.04109249, 0.14431829, 0.43226109, 0.7631815 , 0.74433093,\n",
       "        0.04079161, 0.13424463, 0.41310787, 0.78014069, 0.7761488 ,\n",
       "        0.04278646, 0.13574066, 0.41480398, 0.74882383, 0.76916699,\n",
       "        0.04428377, 0.13743672, 0.41629801, 0.72927365, 0.75929675,\n",
       "        0.04498081, 0.15329347, 0.44333005, 0.72179461, 0.71251993,\n",
       "        0.04916949, 0.14701114, 0.44312811, 0.73326364, 0.73934946,\n",
       "        0.0425868 , 0.15090189, 0.41101303, 0.77794456, 0.83529263,\n",
       "        0.04278636, 0.16287031, 0.42906713, 0.79878974, 0.90680633,\n",
       "        0.04837127, 0.1728435 , 0.44382629, 0.74283752, 0.79519982,\n",
       "        0.04687638, 0.22809854, 0.51773639, 0.85644379, 0.75570517,\n",
       "        0.0499671 , 0.14651518, 0.72718797, 0.72000599, 0.64789209,\n",
       "        0.05654955, 0.1468111 , 0.4763412 , 0.52720876, 0.54955039,\n",
       "        0.05734711, 0.16227112, 0.41390834, 0.38228908, 0.41380663,\n",
       "        0.04577818, 0.19518309, 0.42278738, 0.32144933, 0.32992988,\n",
       "        0.04478259, 0.16336937, 0.25363264, 0.25582447, 0.25981321,\n",
       "        0.04547811, 0.13813334, 0.18660674, 0.19817591, 0.2010694 ,\n",
       "        0.04577842, 0.15459199, 0.19658256, 0.20356226, 0.15429349,\n",
       "        0.04567728, 0.11439991, 0.11300073, 0.11280112, 0.10931001,\n",
       "        0.04667773, 0.09025965, 0.0820857 , 0.08198318, 0.07909164,\n",
       "        0.04428148, 0.05954418, 0.06173606, 0.05914359, 0.06074052,\n",
       "        0.04328399, 0.04587922, 0.04568028, 0.04527831, 0.04368296]),\n",
       " 'std_fit_time': array([0.01084472, 0.05432785, 0.11434307, 0.11463063, 0.11815875,\n",
       "        0.00310297, 0.01329468, 0.0468938 , 0.07558082, 0.07923856,\n",
       "        0.00615503, 0.00652951, 0.0197296 , 0.11320111, 0.09194616,\n",
       "        0.00858147, 0.00796367, 0.02153383, 0.09901532, 0.10316628,\n",
       "        0.00067773, 0.01160898, 0.01582392, 0.05586283, 0.07869203,\n",
       "        0.00236932, 0.00686994, 0.00586346, 0.03170255, 0.0216259 ,\n",
       "        0.00331601, 0.01176697, 0.00975436, 0.02826148, 0.02191744,\n",
       "        0.00364286, 0.00938609, 0.01041484, 0.04426769, 0.06171648,\n",
       "        0.00334642, 0.00859183, 0.01325719, 0.0479168 , 0.07035717,\n",
       "        0.00790166, 0.01293551, 0.00952235, 0.11313373, 0.11899967,\n",
       "        0.00153122, 0.01614818, 0.00659032, 0.0716232 , 0.12264721,\n",
       "        0.00161934, 0.01244716, 0.00233186, 0.09459548, 0.09961913,\n",
       "        0.00295993, 0.03515384, 0.01521738, 0.06758174, 0.15300266,\n",
       "        0.0035247 , 0.02359555, 0.03588037, 0.10119204, 0.138745  ,\n",
       "        0.00749268, 0.00850112, 0.07148882, 0.09016161, 0.06273226,\n",
       "        0.00504034, 0.01321476, 0.03246841, 0.0790516 , 0.08102077,\n",
       "        0.02530846, 0.01904296, 0.04479983, 0.05868673, 0.09913936,\n",
       "        0.00386988, 0.02511524, 0.01510989, 0.06386201, 0.04099321,\n",
       "        0.00495101, 0.01726952, 0.03516746, 0.04865633, 0.02945587,\n",
       "        0.00319178, 0.00424423, 0.0283116 , 0.03564523, 0.01809262,\n",
       "        0.00289649, 0.03340624, 0.03309466, 0.03186888, 0.02023813,\n",
       "        0.00171588, 0.01658585, 0.01009375, 0.01057124, 0.01419613,\n",
       "        0.002329  , 0.00512502, 0.00909095, 0.00900337, 0.00745612,\n",
       "        0.00135265, 0.00597377, 0.0086972 , 0.00601124, 0.00614298,\n",
       "        0.00249142, 0.00538083, 0.00585574, 0.0068115 , 0.00395921]),\n",
       " 'mean_score_time': array([0.00059843, 0.        , 0.00039902, 0.00059834, 0.00129857,\n",
       "        0.00019941, 0.00039897, 0.00019946, 0.00019941, 0.00059853,\n",
       "        0.00039883, 0.00039897, 0.00019951, 0.00059853, 0.00039892,\n",
       "        0.00039892, 0.00019946, 0.        , 0.00019965, 0.00019956,\n",
       "        0.00019951, 0.00019951, 0.        , 0.00079808, 0.00019946,\n",
       "        0.00039902, 0.00059853, 0.00019946, 0.00039897, 0.00039892,\n",
       "        0.00039897, 0.00079808, 0.        , 0.00039887, 0.00019932,\n",
       "        0.00039897, 0.00019946, 0.0001996 , 0.00019941, 0.        ,\n",
       "        0.00030189, 0.00019927, 0.        , 0.00059867, 0.00019956,\n",
       "        0.        , 0.00019946, 0.00039897, 0.        , 0.00019946,\n",
       "        0.        , 0.        , 0.00019946, 0.        , 0.00059843,\n",
       "        0.00019946, 0.00039902, 0.00039907, 0.00059838, 0.00059834,\n",
       "        0.        , 0.        , 0.00039892, 0.00019941, 0.00039892,\n",
       "        0.        , 0.        , 0.00019946, 0.0001996 , 0.00039887,\n",
       "        0.00079789, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.00019941, 0.00019956, 0.00039887, 0.0001996 , 0.        ,\n",
       "        0.00030241, 0.00039916, 0.00039902, 0.00039921, 0.00059834,\n",
       "        0.00039911, 0.00059829, 0.00039868, 0.00159559, 0.00019937,\n",
       "        0.00079679, 0.00019937, 0.00039897, 0.0001996 , 0.        ,\n",
       "        0.00059857, 0.00039892, 0.00039883, 0.00039916, 0.00019965,\n",
       "        0.00019951, 0.00059843, 0.00039873, 0.0001997 , 0.00059838,\n",
       "        0.00039907, 0.00019946, 0.00059857, 0.        , 0.00019951,\n",
       "        0.00039892, 0.00039902, 0.00019951, 0.0001996 , 0.00039907,\n",
       "        0.00019951, 0.00039926, 0.00079808, 0.        , 0.00019946,\n",
       "        0.        , 0.00039911, 0.00039892, 0.        , 0.        ]),\n",
       " 'std_score_time': array([0.00048862, 0.        , 0.00048869, 0.00048854, 0.00166074,\n",
       "        0.00039883, 0.00048864, 0.00039892, 0.00039883, 0.00048869,\n",
       "        0.00048846, 0.00048864, 0.00039902, 0.00048869, 0.00048858,\n",
       "        0.00048858, 0.00039892, 0.        , 0.0003993 , 0.00039911,\n",
       "        0.00039902, 0.00039902, 0.        , 0.00039904, 0.00039892,\n",
       "        0.00048869, 0.00048869, 0.00039892, 0.00048864, 0.00048858,\n",
       "        0.00048864, 0.00039904, 0.        , 0.00048852, 0.00039864,\n",
       "        0.00048864, 0.00039892, 0.00039921, 0.00039883, 0.        ,\n",
       "        0.00040013, 0.00039854, 0.        , 0.00048881, 0.00039911,\n",
       "        0.        , 0.00039892, 0.00048864, 0.        , 0.00039892,\n",
       "        0.        , 0.        , 0.00039892, 0.        , 0.00048862,\n",
       "        0.00039892, 0.00048869, 0.00048875, 0.00048858, 0.00048854,\n",
       "        0.        , 0.        , 0.00048858, 0.00039883, 0.00048858,\n",
       "        0.        , 0.        , 0.00039892, 0.00039921, 0.00048852,\n",
       "        0.00039895, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.00039883, 0.00039911, 0.00048852, 0.00039921, 0.        ,\n",
       "        0.00040081, 0.00048887, 0.00048869, 0.00048893, 0.00048854,\n",
       "        0.00048881, 0.0004885 , 0.00048829, 0.00162017, 0.00039873,\n",
       "        0.00039841, 0.00039873, 0.00048864, 0.00039921, 0.        ,\n",
       "        0.00048873, 0.00048858, 0.00048846, 0.00048887, 0.0003993 ,\n",
       "        0.00039902, 0.00048862, 0.00048834, 0.0003994 , 0.00048858,\n",
       "        0.00048875, 0.00039892, 0.00048873, 0.        , 0.00039902,\n",
       "        0.00048858, 0.00048869, 0.00039902, 0.00039921, 0.00048875,\n",
       "        0.00039902, 0.00048899, 0.00039904, 0.        , 0.00039892,\n",
       "        0.        , 0.00048881, 0.00048858, 0.        , 0.        ]),\n",
       " 'param_eta': masked_array(data=[1e-08, 1e-08, 1e-08, 1e-08, 1e-08,\n",
       "                    1.4677992676220705e-08, 1.4677992676220705e-08,\n",
       "                    1.4677992676220705e-08, 1.4677992676220705e-08,\n",
       "                    1.4677992676220705e-08, 2.1544346900318822e-08,\n",
       "                    2.1544346900318822e-08, 2.1544346900318822e-08,\n",
       "                    2.1544346900318822e-08, 2.1544346900318822e-08,\n",
       "                    3.162277660168379e-08, 3.162277660168379e-08,\n",
       "                    3.162277660168379e-08, 3.162277660168379e-08,\n",
       "                    3.162277660168379e-08, 4.641588833612782e-08,\n",
       "                    4.641588833612782e-08, 4.641588833612782e-08,\n",
       "                    4.641588833612782e-08, 4.641588833612782e-08,\n",
       "                    6.812920690579608e-08, 6.812920690579608e-08,\n",
       "                    6.812920690579608e-08, 6.812920690579608e-08,\n",
       "                    6.812920690579608e-08, 1e-07, 1e-07, 1e-07, 1e-07,\n",
       "                    1e-07, 1.4677992676220674e-07, 1.4677992676220674e-07,\n",
       "                    1.4677992676220674e-07, 1.4677992676220674e-07,\n",
       "                    1.4677992676220674e-07, 2.1544346900318822e-07,\n",
       "                    2.1544346900318822e-07, 2.1544346900318822e-07,\n",
       "                    2.1544346900318822e-07, 2.1544346900318822e-07,\n",
       "                    3.162277660168379e-07, 3.162277660168379e-07,\n",
       "                    3.162277660168379e-07, 3.162277660168379e-07,\n",
       "                    3.162277660168379e-07, 4.6415888336127725e-07,\n",
       "                    4.6415888336127725e-07, 4.6415888336127725e-07,\n",
       "                    4.6415888336127725e-07, 4.6415888336127725e-07,\n",
       "                    6.812920690579608e-07, 6.812920690579608e-07,\n",
       "                    6.812920690579608e-07, 6.812920690579608e-07,\n",
       "                    6.812920690579608e-07, 1e-06, 1e-06, 1e-06, 1e-06,\n",
       "                    1e-06, 1.4677992676220675e-06, 1.4677992676220675e-06,\n",
       "                    1.4677992676220675e-06, 1.4677992676220675e-06,\n",
       "                    1.4677992676220675e-06, 2.1544346900318822e-06,\n",
       "                    2.1544346900318822e-06, 2.1544346900318822e-06,\n",
       "                    2.1544346900318822e-06, 2.1544346900318822e-06,\n",
       "                    3.162277660168379e-06, 3.162277660168379e-06,\n",
       "                    3.162277660168379e-06, 3.162277660168379e-06,\n",
       "                    3.162277660168379e-06, 4.641588833612773e-06,\n",
       "                    4.641588833612773e-06, 4.641588833612773e-06,\n",
       "                    4.641588833612773e-06, 4.641588833612773e-06,\n",
       "                    6.8129206905796085e-06, 6.8129206905796085e-06,\n",
       "                    6.8129206905796085e-06, 6.8129206905796085e-06,\n",
       "                    6.8129206905796085e-06, 1e-05, 1e-05, 1e-05, 1e-05,\n",
       "                    1e-05, 1.4677992676220675e-05, 1.4677992676220675e-05,\n",
       "                    1.4677992676220675e-05, 1.4677992676220675e-05,\n",
       "                    1.4677992676220675e-05, 2.1544346900318823e-05,\n",
       "                    2.1544346900318823e-05, 2.1544346900318823e-05,\n",
       "                    2.1544346900318823e-05, 2.1544346900318823e-05,\n",
       "                    3.1622776601683795e-05, 3.1622776601683795e-05,\n",
       "                    3.1622776601683795e-05, 3.1622776601683795e-05,\n",
       "                    3.1622776601683795e-05, 4.641588833612772e-05,\n",
       "                    4.641588833612772e-05, 4.641588833612772e-05,\n",
       "                    4.641588833612772e-05, 4.641588833612772e-05,\n",
       "                    6.812920690579608e-05, 6.812920690579608e-05,\n",
       "                    6.812920690579608e-05, 6.812920690579608e-05,\n",
       "                    6.812920690579608e-05, 0.0001, 0.0001, 0.0001, 0.0001,\n",
       "                    0.0001],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_iter': masked_array(data=[1000.0, 3162.2776601683795, 10000.0,\n",
       "                    31622.776601683792, 100000.0, 1000.0,\n",
       "                    3162.2776601683795, 10000.0, 31622.776601683792,\n",
       "                    100000.0, 1000.0, 3162.2776601683795, 10000.0,\n",
       "                    31622.776601683792, 100000.0, 1000.0,\n",
       "                    3162.2776601683795, 10000.0, 31622.776601683792,\n",
       "                    100000.0, 1000.0, 3162.2776601683795, 10000.0,\n",
       "                    31622.776601683792, 100000.0, 1000.0,\n",
       "                    3162.2776601683795, 10000.0, 31622.776601683792,\n",
       "                    100000.0, 1000.0, 3162.2776601683795, 10000.0,\n",
       "                    31622.776601683792, 100000.0, 1000.0,\n",
       "                    3162.2776601683795, 10000.0, 31622.776601683792,\n",
       "                    100000.0, 1000.0, 3162.2776601683795, 10000.0,\n",
       "                    31622.776601683792, 100000.0, 1000.0,\n",
       "                    3162.2776601683795, 10000.0, 31622.776601683792,\n",
       "                    100000.0, 1000.0, 3162.2776601683795, 10000.0,\n",
       "                    31622.776601683792, 100000.0, 1000.0,\n",
       "                    3162.2776601683795, 10000.0, 31622.776601683792,\n",
       "                    100000.0, 1000.0, 3162.2776601683795, 10000.0,\n",
       "                    31622.776601683792, 100000.0, 1000.0,\n",
       "                    3162.2776601683795, 10000.0, 31622.776601683792,\n",
       "                    100000.0, 1000.0, 3162.2776601683795, 10000.0,\n",
       "                    31622.776601683792, 100000.0, 1000.0,\n",
       "                    3162.2776601683795, 10000.0, 31622.776601683792,\n",
       "                    100000.0, 1000.0, 3162.2776601683795, 10000.0,\n",
       "                    31622.776601683792, 100000.0, 1000.0,\n",
       "                    3162.2776601683795, 10000.0, 31622.776601683792,\n",
       "                    100000.0, 1000.0, 3162.2776601683795, 10000.0,\n",
       "                    31622.776601683792, 100000.0, 1000.0,\n",
       "                    3162.2776601683795, 10000.0, 31622.776601683792,\n",
       "                    100000.0, 1000.0, 3162.2776601683795, 10000.0,\n",
       "                    31622.776601683792, 100000.0, 1000.0,\n",
       "                    3162.2776601683795, 10000.0, 31622.776601683792,\n",
       "                    100000.0, 1000.0, 3162.2776601683795, 10000.0,\n",
       "                    31622.776601683792, 100000.0, 1000.0,\n",
       "                    3162.2776601683795, 10000.0, 31622.776601683792,\n",
       "                    100000.0, 1000.0, 3162.2776601683795, 10000.0,\n",
       "                    31622.776601683792, 100000.0],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'eta': 1e-08, 'max_iter': 1000.0},\n",
       "  {'eta': 1e-08, 'max_iter': 3162.2776601683795},\n",
       "  {'eta': 1e-08, 'max_iter': 10000.0},\n",
       "  {'eta': 1e-08, 'max_iter': 31622.776601683792},\n",
       "  {'eta': 1e-08, 'max_iter': 100000.0},\n",
       "  {'eta': 1.4677992676220705e-08, 'max_iter': 1000.0},\n",
       "  {'eta': 1.4677992676220705e-08, 'max_iter': 3162.2776601683795},\n",
       "  {'eta': 1.4677992676220705e-08, 'max_iter': 10000.0},\n",
       "  {'eta': 1.4677992676220705e-08, 'max_iter': 31622.776601683792},\n",
       "  {'eta': 1.4677992676220705e-08, 'max_iter': 100000.0},\n",
       "  {'eta': 2.1544346900318822e-08, 'max_iter': 1000.0},\n",
       "  {'eta': 2.1544346900318822e-08, 'max_iter': 3162.2776601683795},\n",
       "  {'eta': 2.1544346900318822e-08, 'max_iter': 10000.0},\n",
       "  {'eta': 2.1544346900318822e-08, 'max_iter': 31622.776601683792},\n",
       "  {'eta': 2.1544346900318822e-08, 'max_iter': 100000.0},\n",
       "  {'eta': 3.162277660168379e-08, 'max_iter': 1000.0},\n",
       "  {'eta': 3.162277660168379e-08, 'max_iter': 3162.2776601683795},\n",
       "  {'eta': 3.162277660168379e-08, 'max_iter': 10000.0},\n",
       "  {'eta': 3.162277660168379e-08, 'max_iter': 31622.776601683792},\n",
       "  {'eta': 3.162277660168379e-08, 'max_iter': 100000.0},\n",
       "  {'eta': 4.641588833612782e-08, 'max_iter': 1000.0},\n",
       "  {'eta': 4.641588833612782e-08, 'max_iter': 3162.2776601683795},\n",
       "  {'eta': 4.641588833612782e-08, 'max_iter': 10000.0},\n",
       "  {'eta': 4.641588833612782e-08, 'max_iter': 31622.776601683792},\n",
       "  {'eta': 4.641588833612782e-08, 'max_iter': 100000.0},\n",
       "  {'eta': 6.812920690579608e-08, 'max_iter': 1000.0},\n",
       "  {'eta': 6.812920690579608e-08, 'max_iter': 3162.2776601683795},\n",
       "  {'eta': 6.812920690579608e-08, 'max_iter': 10000.0},\n",
       "  {'eta': 6.812920690579608e-08, 'max_iter': 31622.776601683792},\n",
       "  {'eta': 6.812920690579608e-08, 'max_iter': 100000.0},\n",
       "  {'eta': 1e-07, 'max_iter': 1000.0},\n",
       "  {'eta': 1e-07, 'max_iter': 3162.2776601683795},\n",
       "  {'eta': 1e-07, 'max_iter': 10000.0},\n",
       "  {'eta': 1e-07, 'max_iter': 31622.776601683792},\n",
       "  {'eta': 1e-07, 'max_iter': 100000.0},\n",
       "  {'eta': 1.4677992676220674e-07, 'max_iter': 1000.0},\n",
       "  {'eta': 1.4677992676220674e-07, 'max_iter': 3162.2776601683795},\n",
       "  {'eta': 1.4677992676220674e-07, 'max_iter': 10000.0},\n",
       "  {'eta': 1.4677992676220674e-07, 'max_iter': 31622.776601683792},\n",
       "  {'eta': 1.4677992676220674e-07, 'max_iter': 100000.0},\n",
       "  {'eta': 2.1544346900318822e-07, 'max_iter': 1000.0},\n",
       "  {'eta': 2.1544346900318822e-07, 'max_iter': 3162.2776601683795},\n",
       "  {'eta': 2.1544346900318822e-07, 'max_iter': 10000.0},\n",
       "  {'eta': 2.1544346900318822e-07, 'max_iter': 31622.776601683792},\n",
       "  {'eta': 2.1544346900318822e-07, 'max_iter': 100000.0},\n",
       "  {'eta': 3.162277660168379e-07, 'max_iter': 1000.0},\n",
       "  {'eta': 3.162277660168379e-07, 'max_iter': 3162.2776601683795},\n",
       "  {'eta': 3.162277660168379e-07, 'max_iter': 10000.0},\n",
       "  {'eta': 3.162277660168379e-07, 'max_iter': 31622.776601683792},\n",
       "  {'eta': 3.162277660168379e-07, 'max_iter': 100000.0},\n",
       "  {'eta': 4.6415888336127725e-07, 'max_iter': 1000.0},\n",
       "  {'eta': 4.6415888336127725e-07, 'max_iter': 3162.2776601683795},\n",
       "  {'eta': 4.6415888336127725e-07, 'max_iter': 10000.0},\n",
       "  {'eta': 4.6415888336127725e-07, 'max_iter': 31622.776601683792},\n",
       "  {'eta': 4.6415888336127725e-07, 'max_iter': 100000.0},\n",
       "  {'eta': 6.812920690579608e-07, 'max_iter': 1000.0},\n",
       "  {'eta': 6.812920690579608e-07, 'max_iter': 3162.2776601683795},\n",
       "  {'eta': 6.812920690579608e-07, 'max_iter': 10000.0},\n",
       "  {'eta': 6.812920690579608e-07, 'max_iter': 31622.776601683792},\n",
       "  {'eta': 6.812920690579608e-07, 'max_iter': 100000.0},\n",
       "  {'eta': 1e-06, 'max_iter': 1000.0},\n",
       "  {'eta': 1e-06, 'max_iter': 3162.2776601683795},\n",
       "  {'eta': 1e-06, 'max_iter': 10000.0},\n",
       "  {'eta': 1e-06, 'max_iter': 31622.776601683792},\n",
       "  {'eta': 1e-06, 'max_iter': 100000.0},\n",
       "  {'eta': 1.4677992676220675e-06, 'max_iter': 1000.0},\n",
       "  {'eta': 1.4677992676220675e-06, 'max_iter': 3162.2776601683795},\n",
       "  {'eta': 1.4677992676220675e-06, 'max_iter': 10000.0},\n",
       "  {'eta': 1.4677992676220675e-06, 'max_iter': 31622.776601683792},\n",
       "  {'eta': 1.4677992676220675e-06, 'max_iter': 100000.0},\n",
       "  {'eta': 2.1544346900318822e-06, 'max_iter': 1000.0},\n",
       "  {'eta': 2.1544346900318822e-06, 'max_iter': 3162.2776601683795},\n",
       "  {'eta': 2.1544346900318822e-06, 'max_iter': 10000.0},\n",
       "  {'eta': 2.1544346900318822e-06, 'max_iter': 31622.776601683792},\n",
       "  {'eta': 2.1544346900318822e-06, 'max_iter': 100000.0},\n",
       "  {'eta': 3.162277660168379e-06, 'max_iter': 1000.0},\n",
       "  {'eta': 3.162277660168379e-06, 'max_iter': 3162.2776601683795},\n",
       "  {'eta': 3.162277660168379e-06, 'max_iter': 10000.0},\n",
       "  {'eta': 3.162277660168379e-06, 'max_iter': 31622.776601683792},\n",
       "  {'eta': 3.162277660168379e-06, 'max_iter': 100000.0},\n",
       "  {'eta': 4.641588833612773e-06, 'max_iter': 1000.0},\n",
       "  {'eta': 4.641588833612773e-06, 'max_iter': 3162.2776601683795},\n",
       "  {'eta': 4.641588833612773e-06, 'max_iter': 10000.0},\n",
       "  {'eta': 4.641588833612773e-06, 'max_iter': 31622.776601683792},\n",
       "  {'eta': 4.641588833612773e-06, 'max_iter': 100000.0},\n",
       "  {'eta': 6.8129206905796085e-06, 'max_iter': 1000.0},\n",
       "  {'eta': 6.8129206905796085e-06, 'max_iter': 3162.2776601683795},\n",
       "  {'eta': 6.8129206905796085e-06, 'max_iter': 10000.0},\n",
       "  {'eta': 6.8129206905796085e-06, 'max_iter': 31622.776601683792},\n",
       "  {'eta': 6.8129206905796085e-06, 'max_iter': 100000.0},\n",
       "  {'eta': 1e-05, 'max_iter': 1000.0},\n",
       "  {'eta': 1e-05, 'max_iter': 3162.2776601683795},\n",
       "  {'eta': 1e-05, 'max_iter': 10000.0},\n",
       "  {'eta': 1e-05, 'max_iter': 31622.776601683792},\n",
       "  {'eta': 1e-05, 'max_iter': 100000.0},\n",
       "  {'eta': 1.4677992676220675e-05, 'max_iter': 1000.0},\n",
       "  {'eta': 1.4677992676220675e-05, 'max_iter': 3162.2776601683795},\n",
       "  {'eta': 1.4677992676220675e-05, 'max_iter': 10000.0},\n",
       "  {'eta': 1.4677992676220675e-05, 'max_iter': 31622.776601683792},\n",
       "  {'eta': 1.4677992676220675e-05, 'max_iter': 100000.0},\n",
       "  {'eta': 2.1544346900318823e-05, 'max_iter': 1000.0},\n",
       "  {'eta': 2.1544346900318823e-05, 'max_iter': 3162.2776601683795},\n",
       "  {'eta': 2.1544346900318823e-05, 'max_iter': 10000.0},\n",
       "  {'eta': 2.1544346900318823e-05, 'max_iter': 31622.776601683792},\n",
       "  {'eta': 2.1544346900318823e-05, 'max_iter': 100000.0},\n",
       "  {'eta': 3.1622776601683795e-05, 'max_iter': 1000.0},\n",
       "  {'eta': 3.1622776601683795e-05, 'max_iter': 3162.2776601683795},\n",
       "  {'eta': 3.1622776601683795e-05, 'max_iter': 10000.0},\n",
       "  {'eta': 3.1622776601683795e-05, 'max_iter': 31622.776601683792},\n",
       "  {'eta': 3.1622776601683795e-05, 'max_iter': 100000.0},\n",
       "  {'eta': 4.641588833612772e-05, 'max_iter': 1000.0},\n",
       "  {'eta': 4.641588833612772e-05, 'max_iter': 3162.2776601683795},\n",
       "  {'eta': 4.641588833612772e-05, 'max_iter': 10000.0},\n",
       "  {'eta': 4.641588833612772e-05, 'max_iter': 31622.776601683792},\n",
       "  {'eta': 4.641588833612772e-05, 'max_iter': 100000.0},\n",
       "  {'eta': 6.812920690579608e-05, 'max_iter': 1000.0},\n",
       "  {'eta': 6.812920690579608e-05, 'max_iter': 3162.2776601683795},\n",
       "  {'eta': 6.812920690579608e-05, 'max_iter': 10000.0},\n",
       "  {'eta': 6.812920690579608e-05, 'max_iter': 31622.776601683792},\n",
       "  {'eta': 6.812920690579608e-05, 'max_iter': 100000.0},\n",
       "  {'eta': 0.0001, 'max_iter': 1000.0},\n",
       "  {'eta': 0.0001, 'max_iter': 3162.2776601683795},\n",
       "  {'eta': 0.0001, 'max_iter': 10000.0},\n",
       "  {'eta': 0.0001, 'max_iter': 31622.776601683792},\n",
       "  {'eta': 0.0001, 'max_iter': 100000.0}],\n",
       " 'split0_test_score': array([-5.76009817, -5.53891597, -5.22746221, -5.22746221, -5.22746221,\n",
       "        -5.70827727, -5.41213409, -4.89042951, -4.84201924, -4.84201924,\n",
       "        -5.63631855, -5.25583905, -4.70750469, -4.5854139 , -4.5854139 ,\n",
       "        -5.53896913, -5.07710647, -4.51814567, -4.27744866, -4.27744866,\n",
       "        -5.41219516, -4.89030542, -4.28319155, -3.81054288, -3.81054288,\n",
       "        -5.25590275, -4.70739511, -3.97118438, -3.41356545, -3.41356545,\n",
       "        -5.07716834, -4.51803934, -3.60970209, -3.15872882, -3.15872882,\n",
       "        -4.89037302, -4.28304276, -3.28088507, -3.01474625, -3.01474625,\n",
       "        -4.70749853, -3.97095237, -3.06221032, -2.98115554, -2.98115554,\n",
       "        -4.51820931, -3.60941165, -2.97869537, -3.08030835, -3.08030835,\n",
       "        -4.28324615, -3.28061929, -3.00653372, -3.21270991, -3.21270991,\n",
       "        -3.97107917, -3.06204179, -3.10700726, -3.32196332, -3.32196332,\n",
       "        -3.60938646, -2.97864339, -3.24155331, -3.40264635, -3.40264635,\n",
       "        -3.28047982, -3.00657766, -3.3706917 , -3.45804955, -3.45804955,\n",
       "        -3.06188055, -3.10711737, -3.46254377, -3.49240293, -3.49240293,\n",
       "        -2.97853231, -3.24169711, -3.50869283, -3.51100378, -3.51100378,\n",
       "        -3.00654172, -3.37083051, -3.5200841 , -3.5200841 , -3.5200841 ,\n",
       "        -3.1071584 , -3.46264248, -3.52444653, -3.52444653, -3.52444653,\n",
       "        -3.24180933, -3.50874073, -3.52665946, -3.52665946, -3.52665946,\n",
       "        -3.37098649, -3.52450905, -3.52787185, -3.52787185, -3.52787185,\n",
       "        -3.46278635, -3.52858722, -3.52858722, -3.52858722, -3.52858722,\n",
       "        -3.50882448, -3.52903351, -3.52903351, -3.52903351, -3.52903351,\n",
       "        -3.52453765, -3.52932402, -3.52932402, -3.52932402, -3.52932402,\n",
       "        -3.52866567, -3.52951626, -3.52951626, -3.52951626, -3.52951626,\n",
       "        -3.52964497, -3.52964497, -3.52964497, -3.52964497, -3.52964497]),\n",
       " 'split1_test_score': array([-9.65031128, -9.29637725, -9.12849091, -9.12849091, -9.12849091,\n",
       "        -9.57013888, -9.07726159, -8.08263599, -8.08263599, -8.08263599,\n",
       "        -9.4561596 , -8.78548023, -7.45367076, -7.25057712, -7.25057712,\n",
       "        -9.29646525, -8.41269052, -6.92093219, -6.45255342, -6.45255342,\n",
       "        -9.0773668 , -7.96199794, -6.39913468, -5.71465647, -5.71465647,\n",
       "        -8.78559222, -7.45324878, -5.91213366, -5.26530324, -5.26530324,\n",
       "        -8.41278678, -6.9204824 , -5.4780397 , -5.00323605, -5.00323605,\n",
       "        -7.96204567, -6.39869342, -5.12427433, -4.84268835, -4.84268835,\n",
       "        -7.45321979, -5.91172805, -4.88074662, -4.74248537, -4.74248537,\n",
       "        -6.92037855, -5.47768302, -4.74975   , -4.70163611, -4.70163611,\n",
       "        -6.39855464, -5.12398193, -4.70379967, -4.72644166, -4.72644166,\n",
       "        -5.91159459, -4.88054231, -4.7108134 , -4.78609781, -4.78609781,\n",
       "        -5.47754486, -4.74963999, -4.75201003, -4.86461385, -4.86461385,\n",
       "        -5.12380576, -4.70376855, -4.82857125, -4.94284665, -4.94284665,\n",
       "        -4.88035279, -4.7108372 , -4.93876136, -5.0072971 , -5.0072971 ,\n",
       "        -4.74949689, -4.75206955, -5.04700279, -5.05446444, -5.05446444,\n",
       "        -4.70370674, -4.82866871, -5.08610983, -5.08610983, -5.08610983,\n",
       "        -4.71084947, -4.93889609, -5.10546168, -5.10546168, -5.10546168,\n",
       "        -4.75211529, -5.04713224, -5.11563467, -5.11563467, -5.11563467,\n",
       "        -4.828739  , -5.10829292, -5.11927292, -5.11927292, -5.11927292,\n",
       "        -4.93903024, -5.11896927, -5.11878172, -5.11878172, -5.11878172,\n",
       "        -5.0473191 , -5.1162986 , -5.1162986 , -5.1162986 , -5.1162986 ,\n",
       "        -5.10843553, -5.11336305, -5.11336305, -5.11336305, -5.11336305,\n",
       "        -5.11900933, -5.1107739 , -5.1107739 , -5.1107739 , -5.1107739 ,\n",
       "        -5.11070885, -5.10872945, -5.10872945, -5.10872945, -5.10872945]),\n",
       " 'split2_test_score': array([-12.50917293, -12.50917293, -12.50917293, -12.50917293,\n",
       "        -12.50917293, -12.39332996, -11.86977017, -11.18362127,\n",
       "        -11.18362127, -11.18362127, -12.27317903, -11.55442349,\n",
       "        -10.13756809, -10.13756809, -10.13756809, -12.10393334,\n",
       "        -11.14457642,  -9.39135553,  -9.13211551,  -9.13211551,\n",
       "        -11.86988761, -10.63665655,  -8.71095543,  -7.87864571,\n",
       "         -7.87864571, -11.5545541 , -10.04290351,  -8.01839638,\n",
       "         -6.87031914,  -6.87031914, -11.14469936,  -9.390808  ,\n",
       "         -7.32043121,  -6.23855482,  -6.23855482, -10.63673852,\n",
       "         -8.71038212,  -6.64904816,  -5.83930796,  -5.83930796,\n",
       "        -10.04291156,  -8.01781778,  -6.08439504,  -5.60017774,\n",
       "         -5.60017774,  -9.39073717,  -7.31984682,  -5.71007943,\n",
       "         -5.52145585,  -5.52145585,  -8.71027237,  -6.64847038,\n",
       "         -5.54314694,  -5.56723614,  -5.56723614,  -8.01771459,\n",
       "         -6.08389134,  -5.5288962 ,  -5.63178981,  -5.63178981,\n",
       "         -7.31971836,  -5.70973457,  -5.58906945,  -5.68303819,\n",
       "         -5.68303819,  -6.64821438,  -5.54299072,  -5.66264666,\n",
       "         -5.71698857,  -5.71698857,  -6.08348578,  -5.52888982,\n",
       "         -5.71644411,  -5.73561875,  -5.73561875,  -5.70930307,\n",
       "         -5.58913989,  -5.74181289,  -5.74414342,  -5.74414342,\n",
       "         -5.54268899,  -5.66273172,  -5.74770706,  -5.74770706,\n",
       "         -5.74770706,  -5.52878202,  -5.71650669,  -5.74922805,\n",
       "         -5.74922805,  -5.74922805,  -5.58917803,  -5.74184097,\n",
       "         -5.74994338,  -5.74994338,  -5.74994338,  -5.66283463,\n",
       "         -5.74905325,  -5.75032619,  -5.75032619,  -5.75032619,\n",
       "         -5.71660792,  -5.75055429,  -5.75055429,  -5.75055429,\n",
       "         -5.75055429,  -5.74189565,  -5.75070137,  -5.75070137,\n",
       "         -5.75070137,  -5.75070137,  -5.74906794,  -5.75079982,\n",
       "         -5.75079982,  -5.75079982,  -5.75079982,  -5.75055809,\n",
       "         -5.75086707,  -5.75086707,  -5.75086707,  -5.75086707,\n",
       "         -5.75091273,  -5.75091273,  -5.75091273,  -5.75091273,\n",
       "         -5.75091273]),\n",
       " 'split3_test_score': array([-9.72087939, -9.44150835, -9.15405573, -9.15405573, -9.15405573,\n",
       "        -9.65547442, -9.28158183, -8.65851049, -8.60177928, -8.60177928,\n",
       "        -9.56458048, -9.08598517, -8.49637417, -8.41476423, -8.41476423,\n",
       "        -9.44157633, -8.86818359, -8.40306972, -8.34218674, -8.34218674,\n",
       "        -9.28165927, -8.65837467, -8.35151239, -8.24200765, -8.24200765,\n",
       "        -9.0860625 , -8.49629257, -8.28902127, -8.17887612, -8.17887612,\n",
       "        -8.86824757, -8.40306063, -8.21104189, -8.19627443, -8.19627443,\n",
       "        -8.65842152, -8.35154117, -8.17729026, -8.26013843, -8.26013843,\n",
       "        -8.49635093, -8.28902372, -8.23228593, -8.35057809, -8.35057809,\n",
       "        -8.40318974, -8.21100995, -8.35603256, -8.4737547 , -8.4737547 ,\n",
       "        -8.35175575, -8.17729026, -8.50375427, -8.64171139, -8.64171139,\n",
       "        -8.28922085, -8.23236355, -8.65254632, -8.78544454, -8.78544454,\n",
       "        -8.21107674, -8.35616442, -8.79527543, -8.88349329, -8.88349329,\n",
       "        -8.1772684 , -8.50389822, -8.91502899, -8.94709022, -8.94709022,\n",
       "        -8.23236873, -8.65268892, -8.98555621, -8.98555621, -8.98555621,\n",
       "        -8.35622947, -8.79541881, -9.00545804, -9.00545804, -9.00545804,\n",
       "        -8.50398253, -8.91515706, -9.01172538, -9.01172538, -9.01172538,\n",
       "        -8.65277514, -8.98883093, -9.00969186, -9.00969186, -9.00969186,\n",
       "        -8.79553713, -9.01165921, -9.00467289, -9.00467289, -9.00467289,\n",
       "        -8.91531491, -9.00477707, -8.99975987, -8.99975987, -8.99975987,\n",
       "        -8.98897644, -8.99588374, -8.99588374, -8.99588374, -8.99588374,\n",
       "        -9.01173226, -8.99306272, -8.99306272, -8.99306272, -8.99306272,\n",
       "        -9.00478004, -8.99108833, -8.99108833, -8.99108833, -8.99108833,\n",
       "        -8.99365248, -8.98972444, -8.98972444, -8.98972444, -8.98972444,\n",
       "        -8.98878851, -8.98878851, -8.98878851, -8.98878851, -8.98878851]),\n",
       " 'split4_test_score': array([-9.32459214, -9.25044367, -9.25044367, -9.25044367, -9.25044367,\n",
       "        -9.22316769, -8.5903661 , -7.16274925, -7.16274925, -7.16274925,\n",
       "        -9.07824016, -8.20864446, -6.44170562, -5.76610903, -5.76610903,\n",
       "        -8.87374477, -7.71464353, -5.78591315, -5.03916542, -5.03916542,\n",
       "        -8.59050542, -7.11252918, -5.26053748, -4.86966032, -4.86966032,\n",
       "        -8.20879436, -6.44113317, -4.95371602, -4.90708911, -4.90708911,\n",
       "        -7.71476905, -5.7853344 , -4.86864628, -4.98298595, -4.98298595,\n",
       "        -7.11256838, -5.26006603, -4.92877847, -5.05435353, -5.05435353,\n",
       "        -6.4410107 , -4.95345092, -5.03534532, -5.11106067, -5.11106067,\n",
       "        -5.78501464, -4.86860084, -5.11529036, -5.14283282, -5.14283282,\n",
       "        -5.25962712, -4.92887606, -5.14335562, -5.13915616, -5.13915616,\n",
       "        -4.95307871, -5.03548422, -5.1401433 , -5.1620127 , -5.1620127 ,\n",
       "        -4.86844667, -5.11539525, -5.14602715, -5.25289953, -5.25289953,\n",
       "        -4.92894039, -5.14339797, -5.19803952, -5.38392044, -5.38392044,\n",
       "        -5.03567138, -5.14014214, -5.31318   , -5.50108905, -5.50108905,\n",
       "        -5.11559387, -5.14602231, -5.47010741, -5.58719861, -5.58719861,\n",
       "        -5.14351624, -5.19807355, -5.61708511, -5.64660658, -5.64660658,\n",
       "        -5.14015228, -5.31328347, -5.68691077, -5.68691077, -5.68691077,\n",
       "        -5.14594784, -5.47026576, -5.71415541, -5.71415541, -5.71415541,\n",
       "        -5.19797423, -5.61723888, -5.73263855, -5.73263855, -5.73263855,\n",
       "        -5.31325597, -5.71429392, -5.74515113, -5.74515113, -5.74515113,\n",
       "        -5.47036761, -5.75367623, -5.75367623, -5.75367623, -5.75367623,\n",
       "        -5.617414  , -5.75946395, -5.75946395, -5.75946395, -5.75946395,\n",
       "        -5.71444619, -5.76340696, -5.76340696, -5.76340696, -5.76340696,\n",
       "        -5.75824905, -5.76609445, -5.76609445, -5.76609445, -5.76609445]),\n",
       " 'mean_test_score': array([-9.39301078, -9.20728363, -9.05392509, -9.05392509, -9.05392509,\n",
       "        -9.31007764, -8.84622276, -7.9955893 , -7.97456101, -7.97456101,\n",
       "        -9.20169557, -8.57807448, -7.44736466, -7.23088648, -7.23088648,\n",
       "        -9.05093776, -8.24344011, -7.00388325, -6.64869395, -6.64869395,\n",
       "        -8.84632285, -7.85197275, -6.60106631, -6.10310261, -6.10310261,\n",
       "        -8.57818118, -7.42819463, -6.22889034, -5.72703061, -5.72703061,\n",
       "        -8.24353422, -7.00354495, -5.89757223, -5.51595601, -5.51595601,\n",
       "        -7.85202942, -6.6007451 , -5.63205526, -5.40224691, -5.40224691,\n",
       "        -7.4281983 , -6.22859457, -5.45899665, -5.35709148, -5.35709148,\n",
       "        -7.00350588, -5.89731045, -5.38196954, -5.38399757, -5.38399757,\n",
       "        -6.60069121, -5.63184758, -5.38011804, -5.45745105, -5.45745105,\n",
       "        -6.22853758, -5.45886464, -5.4278813 , -5.53746163, -5.53746163,\n",
       "        -5.89723462, -5.38191552, -5.50478707, -5.61733824, -5.61733824,\n",
       "        -5.63174175, -5.38012662, -5.59499563, -5.68977909, -5.68977909,\n",
       "        -5.45875185, -5.42793509, -5.68329709, -5.74439281, -5.74439281,\n",
       "        -5.38183112, -5.50486953, -5.75461479, -5.78045366, -5.78045366,\n",
       "        -5.38008724, -5.59509231, -5.79654229, -5.80244659, -5.80244659,\n",
       "        -5.42794346, -5.68403193, -5.81514778, -5.81514778, -5.81514778,\n",
       "        -5.50491752, -5.75592778, -5.82221316, -5.82221316, -5.82221316,\n",
       "        -5.59516985, -5.80077423, -5.82597388, -5.82597388, -5.82597388,\n",
       "        -5.68413138, -5.82165769, -5.82779162, -5.82779162, -5.82779162,\n",
       "        -5.75602782, -5.82855449, -5.82855449, -5.82855449, -5.82855449,\n",
       "        -5.80084703, -5.82880783, -5.82880783, -5.82880783, -5.82880783,\n",
       "        -5.82126635, -5.82885772, -5.82885772, -5.82885772, -5.82885772,\n",
       "        -5.82766082, -5.82883403, -5.82883403, -5.82883403, -5.82883403]),\n",
       " 'std_test_score': array([2.14880912, 2.2101609 , 2.30801913, 2.30801913, 2.30801913,\n",
       "        2.12950205, 2.06122212, 2.04676473, 2.0579119 , 2.0579119 ,\n",
       "        2.11459701, 2.01659964, 1.83607396, 1.94909468, 1.94909468,\n",
       "        2.09279647, 1.95657029, 1.75082666, 1.859417  , 1.859417  ,\n",
       "        2.06123839, 1.88335358, 1.7161603 , 1.71204956, 1.71204956,\n",
       "        2.01661792, 1.80860188, 1.68938521, 1.64658874, 1.64658874,\n",
       "        1.95658569, 1.75079088, 1.66407425, 1.66190943, 1.66190943,\n",
       "        1.88335805, 1.71614945, 1.66089956, 1.70251939, 1.70251939,\n",
       "        1.80859327, 1.68938048, 1.69355808, 1.73801015, 1.73801015,\n",
       "        1.75078944, 1.66406891, 1.74351673, 1.7547795 , 1.7547795 ,\n",
       "        1.71618317, 1.66091368, 1.78499564, 1.77910741, 1.77910741,\n",
       "        1.68943402, 1.69360102, 1.81064101, 1.79845673, 1.79845673,\n",
       "        1.66409848, 1.74356785, 1.82493979, 1.80423696, 1.80423696,\n",
       "        1.66092046, 1.78503272, 1.82864467, 1.80238123, 1.80238123,\n",
       "        1.69362202, 1.81066166, 1.81819028, 1.79884309, 1.79884309,\n",
       "        1.74360876, 1.82495176, 1.79966499, 1.79537084, 1.79537084,\n",
       "        1.78506784, 1.82864839, 1.79214777, 1.79159536, 1.79159536,\n",
       "        1.81067935, 1.81934076, 1.78756083, 1.78756083, 1.78756083,\n",
       "        1.8249661 , 1.80187841, 1.78402743, 1.78402743, 1.78402743,\n",
       "        1.82866694, 1.78677967, 1.78146292, 1.78146292, 1.78146292,\n",
       "        1.81934898, 1.78012566, 1.77981115, 1.77981115, 1.77981115,\n",
       "        1.80186591, 1.77881339, 1.77881339, 1.77881339, 1.77881339,\n",
       "        1.78675872, 1.77822377, 1.77822377, 1.77822377, 1.77822377,\n",
       "        1.77930474, 1.77786728, 1.77786728, 1.77786728, 1.77786728,\n",
       "        1.77754513, 1.77764683, 1.77764683, 1.77764683, 1.77764683]),\n",
       " 'rank_test_score': array([125, 123, 119, 119, 119, 124, 116, 111, 109, 109, 122, 114, 106,\n",
       "        102, 102, 118, 112, 101,  97,  97, 117, 107,  96,  89,  89, 115,\n",
       "        104,  93,  41,  41, 113, 100,  88,  24,  24, 108,  95,  35,  11,\n",
       "         11, 105,  92,  20,   1,   1,  99,  87,   8,   9,   9,  94,  34,\n",
       "          4,  16,  16,  91,  19,  13,  26,  26,  86,   7,  21,  31,  31,\n",
       "         33,   5,  28,  39,  39,  18,  14,  36,  43,  43,   6,  22,  45,\n",
       "         48,  48,   3,  29,  50,  53,  53,  15,  37,  55,  55,  55,  23,\n",
       "         46,  60,  60,  60,  30,  51,  63,  63,  63,  38,  59,  67,  67,\n",
       "         67,  47,  70,  70,  70,  70,  52,  74,  74,  74,  74,  58,  82,\n",
       "         82,  82,  82,  66,  78,  78,  78,  78])}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data_X\n",
    "\n",
    "clsf = LinReg(gd_type='GradientDescent')\n",
    "\n",
    "max_iter_parameters = {\n",
    "    'eta': np.logspace(-8, -4, 25), \n",
    "    'max_iter': np.logspace(3, 5, 5)\n",
    "}\n",
    "\n",
    "max_iter_srch = GridSearchCV(\n",
    "    estimator=clsf,\n",
    "    scoring='neg_root_mean_squared_error', \n",
    "    param_grid=max_iter_parameters,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "max_iter_srch.fit(X, y)\n",
    "\n",
    "max_iter_srch.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(srch_obj, p1, p2, tol='.2f', is_log=True, get_dataframe=False, transpose=False):\n",
    "    \n",
    "    parameters = srch_obj.param_grid\n",
    "    res = srch_obj.cv_results_\n",
    "    \n",
    "#     if transpose:\n",
    "#         p1, p2 = p2, p1\n",
    "    \n",
    "    grid_param_1 = parameters[p1]\n",
    "    grid_param_2 = parameters[p2]\n",
    "\n",
    "    scores_mean = res['mean_test_score']\n",
    "    \n",
    "    if not transpose:\n",
    "        scores_mean = np.array(scores_mean).reshape(len(grid_param_1), len(grid_param_2)).T\n",
    "    else:\n",
    "        scores_mean = np.array(scores_mean).reshape(len(grid_param_2), len(grid_param_1))\n",
    "    \n",
    "    plt.figure(figsize=(16,10))\n",
    "    \n",
    "    if is_log:\n",
    "        plt.xscale('log',base=10) \n",
    "\n",
    "    d = {'X':grid_param_1}\n",
    "        \n",
    "    for idx, val in enumerate(grid_param_2):\n",
    "        vals = scores_mean[idx,:]\n",
    "        title = f'{p2}: {f\"{{0{tol}}}\".format(val)}'\n",
    "        \n",
    "        plt.plot(grid_param_1, vals, '-o', label=title)\n",
    "        if get_dataframe:\n",
    "            d[title] = vals\n",
    "            \n",
    "    plt.title(\"Grid Search Results\", fontsize=16)\n",
    "    plt.xlabel(p1, fontsize=16)\n",
    "    plt.ylabel('Average neg_root_mean_sqaured_error', fontsize=16)\n",
    "    plt.legend(loc=\"best\", fontsize=16)\n",
    "    \n",
    "    if get_dataframe:\n",
    "        return pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a plot of negative loss vs. eta for different values `max_iter`. The values are sampled to be equaliy spaced in a log scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.float64' object has no attribute '2f'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-746564c4512e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mp2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'max_iter'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplot_results\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_iter_srch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_dataframe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-20-29fa651da696>\u001b[0m in \u001b[0;36mplot_results\u001b[1;34m(srch_obj, p1, p2, tol, is_log, get_dataframe, transpose)\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrid_param_2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mvals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscores_mean\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0mtitle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf'{p2}: {f\"{{0{tol}}}\".format(val)}'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrid_param_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'-o'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.float64' object has no attribute '2f'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p1 = 'eta'\n",
    "p2 = 'max_iter'\n",
    "\n",
    "df = plot_results(max_iter_srch, p1, p2, get_dataframe=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graphs loss vs. eta for different values of `max_iter` seem to match each other exactly with some extra offset.\n",
    "\n",
    "Let's plot the graphs for max_iter `1000`, `3162` and `10000` with added offsets (the x-axis is logorithmic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "plt.xscale('log', base=10) \n",
    "\n",
    "plt.plot(df.X * 1000.0, df['max_iter: 1000.00'])\n",
    "plt.plot(df.X * 3162.28, df['max_iter: 3162.28'])\n",
    "plt.plot(df.X * 10000.0, df['max_iter: 10000.00'])\n",
    "\n",
    "# Do not match the pattern\n",
    "plt.plot(df.X * 31622.78, df['max_iter: 31622.78'], '--')\n",
    "plt.plot(df.X * 100000.0, df['max_iter: 100000.00'], '--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Conclusion```\n",
    "\n",
    "As we can see, for `max_iter` of `1000`, `3162` and `10000` the graphs are basically the same after adding some offset. However, for `31622` and `100000` the pattern breaks. Additionally, on the original diagram (Grid Search Results),\n",
    "the `loss vs. eta` graphs for `31622` and `100000` are equal.\n",
    "\n",
    "So it seems like there is a critical point, after which increasing `max_iter` has no effect. This value is somewhere between `10000` and `31622`. \n",
    "\n",
    "Otherwise, as long as the value of `max_iter` x `eta` stays constant, the loss stays roughly the same.\n",
    "\n",
    "This goes against my expectations, since I thought that increasing max_iter would increase the quality of the model.\n",
    "\n",
    "The quality of this model with the best params seems to match and even exceed the quality from sklearn (neg_rmse ~= -5.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "np.mean(cross_val_score(LinearRegression(), X, y, scoring='neg_root_mean_squared_error'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best value for `max_iter` x `eta`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iter_best_val = df.X[df['max_iter: 1000.00'].argmax()] * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iter_best_val "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = data_X\n",
    "\n",
    "clsf = LinReg(delta=1.0, max_iter=1000)\n",
    "\n",
    "parameters = {\n",
    "    'alpha': 1 - np.logspace(-1.3, -0.3, 5),\n",
    "    'eta': np.logspace(-9, -5, 15),\n",
    "}\n",
    "\n",
    "alpha_srch = GridSearchCV(\n",
    "    estimator=clsf,\n",
    "    scoring='neg_root_mean_squared_error', \n",
    "    param_grid=parameters,\n",
    ")\n",
    "\n",
    "alpha_srch.fit(X, y)\n",
    "\n",
    "alpha_srch.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a plot of negative loss vs. eta for different values `alpha`. The values are sampled such that `1 - alpha` is  equaliy spaced in a log scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "p1 = 'eta'\n",
    "p2 = 'alpha'\n",
    "\n",
    "df = plot_results(alpha_srch, p1, p2, tol=':.2f', is_log=True, get_dataframe=True, transpose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graphs loss vs. eta for different values of `alpha` seem to match each other exactly with some extra offset.\n",
    "\n",
    "Let's plot these graphs with some added offsets (the x-axis is logorithmic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "one_minus_alpha = np.logspace(-1.3, -0.3, 5)\n",
    "\n",
    "plt.xscale('log', base=10) \n",
    "\n",
    "cols = list(df.columns)[1:]\n",
    "\n",
    "for i in range(len(cols)):\n",
    "    plt.plot(df.X / one_minus_alpha[i], df[cols[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Conclusion```\n",
    "\n",
    "All the graphs seem to match after we divided the x scale by the value of `1 - alpha` corresponding to the graph.\n",
    "\n",
    "It seems that as long as `eta / (1 - alpha)` stays constant, the loss stays roughly the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To sum up, both optimal `max_iter` and `alpha` depend on `eta`, and the best loss is reached when  \n",
    "\n",
    "`eta / (1 - alpha)` = 1.4359617019622137e-05\n",
    "\n",
    "and `max_iter x eta` = 0.004641588833612773"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_best_val = df.X[df['alpha: 0.95'].argmax()] / one_minus_alpha[0]\n",
    "alpha_best_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iter_best_val "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. [1 points] \n",
    "Plot graphs (on the same picture) of the dependence of the loss function value on the iteration number for Full GD, SGD and Momentum. Draw conclusions about the rate of convergence of various modifications of gradient descent.\n",
    "\n",
    "Don't forget about what *beautiful* graphics should look like!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GD_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = data_X\n",
    "\n",
    "clsf = LinReg(delta = 0.4, eta=0.000004641588833612773, alpha=.8)\n",
    "\n",
    "type_parameters = {\n",
    "    'max_iter': np.logspace(2, 4, 10), \n",
    "    'gd_type': [\n",
    "        'GradientDescent',\n",
    "        'StochasticDescent',\n",
    "        'Momentum'\n",
    "    ]\n",
    "}\n",
    "\n",
    "type_srch = GridSearchCV(\n",
    "    estimator=clsf,\n",
    "    scoring='neg_root_mean_squared_error', \n",
    "    param_grid=type_parameters,\n",
    ")\n",
    "\n",
    "type_srch.fit(X, y)\n",
    "\n",
    "type_srch.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = 'max_iter'\n",
    "p2 = 'gd_type'\n",
    "\n",
    "plot_results(type_srch, p1, p2, tol='', transpose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Conclusion```\n",
    "\n",
    "The Momemtum method converges the fastest, \n",
    "\n",
    "The Gradient Descent method is the second,\n",
    "\n",
    "and the Stochastic Descent is the slowest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a8f61be024eba58adef938c9aa1e29e02cb3dece83a5348b1a2dafd16a070453"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
