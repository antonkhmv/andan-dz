{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HSE 2021: Mathematical Methods for Data Analysis\n",
    "\n",
    "## Homework 4\n",
    "\n",
    "### Attention!\n",
    "* For tasks where <ins>text answer</ins> is required **Russian language** is **allowed**.\n",
    "* If a task asks you to describe something (make coclusions) then **text answer** is **mandatory** and **is** part of the task\n",
    "* **Do not** upload the dataset to the grading system (we already have it)\n",
    "* We **only** accept **ipynb** notebooks. If you use Google Colab then you'll have to download the notebook before passing the homework\n",
    "* **Do not** use python loops instead of NumPy vector operations over NumPy vectors - it significantly decreases performance (see why https://blog.paperspace.com/numpy-optimization-vectorization-and-broadcasting/), will be punished with -0.25 for **every** task. \n",
    "\n",
    "\n",
    "### Contents\n",
    "\n",
    "#### Decision Trees - 7 points\n",
    "* [Task 1](#task1) (0.5 points)\n",
    "* [Task 2](#task2) (0.5 points)\n",
    "* [Task 3](#task3) (2 points)\n",
    "* [Task 4](#task4) (0.5 points)\n",
    "* [Task 5](#task5) (0.5 points)\n",
    "* [Task 6](#task6) (2 points)\n",
    "* [Task 7](#task7) (0.5 points)\n",
    "* [Task 8](#task8) (0.5 points)\n",
    "\n",
    "#### Ensembles - 3 points\n",
    "* [Task 1](#task2_1) (1 point)\n",
    "* [Task 2](#task2_2) (0.7 points)\n",
    "* [Task 3](#task2_3) (0.5 points)\n",
    "* [Task 4](#task2_4) (0.7 points)\n",
    "* [Task 5](#task2_5) (0.1 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (11, 5)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1. Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task you will be implementing decision tree for the regression by hands. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 <a id=\"task1\"></a> (0.5 points)\n",
    "\n",
    "Implement the function `H()` which calculates impurity criterion. We will be training regression tree, therefore, impurity criterion will be variance.\n",
    "\n",
    "* You cannot use loops\n",
    "* If `y` is empty, the function should return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def H(y):\n",
    "    \"\"\"\n",
    "    Calculate impurity criterion\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y : np.array\n",
    "        array of objects target values in the node\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    H(R) : float\n",
    "        Impurity in the node (measuread by variance)\n",
    "    \"\"\"\n",
    "    if len(y) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return np.mean((y-y.mean())**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the function\n",
    "assert np.allclose(H(np.array([4,2,2, 2])), 0.75)\n",
    "assert np.allclose(H(np.array([])), 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 <a id=\"task2\"></a>  (0.5 points)\n",
    "\n",
    "To find the best split in the node we need to calculate the cost function. Denote: \n",
    "- `R` all the object in the node\n",
    "- `j` index of the feature selected for the split\n",
    "- `t` threshold\n",
    "- `R_l` and `R_r` objects in the left and right child nodes correspondingly\n",
    "\n",
    "We get the following cost function:\n",
    "\n",
    "$$\n",
    "Q(R, j, t) =\\frac{|R_\\ell|}{|R|}H(R_\\ell) + \\frac{|R_r|}{|R|}H(R_r) \\to \\min_{j, t},\n",
    "$$\n",
    "\n",
    "Implement the function `Q`, which should calculate value of the cost function for a given feature and threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q(X, y, j, t):\n",
    "    \"\"\"\n",
    "    Calculate cost function\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : ndarray\n",
    "        array of objects in the node \n",
    "    y : ndarray\n",
    "        array of target values in the node \n",
    "    j : int\n",
    "        feature index (column in X)\n",
    "    t : float\n",
    "        threshold\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Q : float\n",
    "        Value of the cost function\n",
    "    \"\"\"   \n",
    "    col = X[:,j]\n",
    "    R_l, R_r = y[col <= t], y[col > t]\n",
    "    return len(R_l) * H(R_l) / len(y) + len(R_r) * H(R_r) / len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3 <a id=\"task3\"></a>  (2 points)\n",
    "\n",
    "Now, let's implement `MyDecisionTreeRegressor` class. More specifically, you need to implement the following methods:\n",
    "\n",
    "- `best_split`\n",
    "- `grow_tree`\n",
    "- `get_prediction`\n",
    "\n",
    "Read docstrings for more details. Do not forget to use function `Q` implemented above, when finding the `best_split`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node(object):\n",
    "    \"\"\"\n",
    "    Class for a decision tree node.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    right : Node() or None\n",
    "        Right child\n",
    "    right : Node() or None\n",
    "        Left child\n",
    "    threshold: float\n",
    "        \n",
    "    column: int\n",
    "        \n",
    "    depth: int\n",
    "        \n",
    "    prediction: float\n",
    "        prediction of the target value in the node (average values calculated on a train dataset)\n",
    "    is_terminal:bool\n",
    "        indicates whether it is a terminal node (leaf) or not\n",
    "    \"\"\"    \n",
    "    def __init__(self):        \n",
    "        self.right = None\n",
    "        self.left = None\n",
    "        self.threshold = None\n",
    "        self.column = None\n",
    "        self.depth = None\n",
    "        self.is_terminal = False\n",
    "        self.prediction = None\n",
    "        \n",
    "    def __repr__(self):\n",
    "        if self.is_terminal:\n",
    "            node_desc = 'Pred: {:.2f}'.format(self.prediction)\n",
    "        else:\n",
    "            node_desc = 'Col {}, t {:.2f}, Pred: {:.2f}'.format(self.column, self.threshold, self.prediction)\n",
    "        return node_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "\n",
    "class MyDecisionTreeRegressor(RegressorMixin, BaseEstimator):\n",
    "    \"\"\"\n",
    "    Class for a Decision Tree Regressor.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    max_depth : int\n",
    "        Max depth of a decision tree.\n",
    "    min_samples_split : int\n",
    "        Minimal number of samples (objects) in a node to make a split.\n",
    "    \"\"\" \n",
    "    def __init__(self, max_depth=3, min_samples_split=2):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "    \n",
    "    def _more_tags(self):\n",
    "        return {\n",
    "            'requires_y': False\n",
    "        }\n",
    "            \n",
    "    def best_split(self, X, y):\n",
    "        \"\"\"\n",
    "        Find the best split in terms of Q of data in a given decision tree node. \n",
    "        Try all features and thresholds. \n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray, shape (n_objects, n_features)\n",
    "            Objects in the parent node\n",
    "        y : ndarray, shape (n_objects, )\n",
    "            1D array with the object labels. \n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        best_split_column : int\n",
    "            Index of the best split column\n",
    "        best_threshold : float\n",
    "            The best split condition.\n",
    "        X_left : ndarray, shape (n_objects_l, n_features)\n",
    "            Objects in the left child\n",
    "        y_left : ndarray, shape (n_objects_l, )\n",
    "            Objects labels in the left child. \n",
    "        X_right : ndarray, shape (n_objects_r, n_features)\n",
    "            Objects in the right child\n",
    "        y_right : ndarray, shape (n_objects_r, )\n",
    "            Objects labels in the right child. \n",
    "        \"\"\"\n",
    "        \n",
    "        # To store best split parameters\n",
    "        best_split_column = None\n",
    "        best_threshold = None\n",
    "        # without splitting\n",
    "        best_cost = H(y) \n",
    "        X_left, y_left, X_right, y_right = (None,)*4\n",
    "        \n",
    "        for i, column in enumerate(X.T):\n",
    "            for threshold in column:\n",
    "                cost = Q(X, y, i, threshold)\n",
    "                if cost < best_cost:\n",
    "                    best_threshold = threshold\n",
    "                    best_cost = cost\n",
    "                    best_split_column = i\n",
    "        \n",
    "        if not best_split_column is None:\n",
    "            index = X[:,best_split_column] > best_threshold\n",
    "            X_left, y_left = X[~index], y[~index]\n",
    "            X_right, y_right = X[index], y[index]\n",
    "            \n",
    "        return best_split_column, best_threshold, X_left, y_left, X_right, y_right\n",
    "    \n",
    "    def is_terminal(self, node, y):\n",
    "        \"\"\"\n",
    "        Check terminality conditions based on `max_depth` and `min_samples_split` parameters for a given node. \n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        node : Node, \n",
    "            \n",
    "        y : ndarray, shape (n_objects, )\n",
    "            Object labels. \n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        Is_termial : bool\n",
    "            If True, node is terminal\n",
    "        \"\"\"\n",
    "        if node.depth >= self.max_depth:    \n",
    "            return True\n",
    "        if len(y) < self.min_samples_split:   \n",
    "            return True\n",
    "        return False\n",
    "        \n",
    "    def grow_tree(self, node, X, y):\n",
    "        \"\"\"\n",
    "        Reccurently grow the tree from the `node` using a `X` and `y` as a dataset:\n",
    "         - check terminality conditions\n",
    "         - find best split if node is not terminal\n",
    "         - add child nodes to the node\n",
    "         - call the function recursively for the added child nodes\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        node : Node() object\n",
    "            Current node of the decision tree.\n",
    "        X : ndarray, shape (n_objects, n_features)\n",
    "            Objects \n",
    "        y : ndarray, shape (n_objects)\n",
    "            Labels\n",
    "        \"\"\"\n",
    "        if not self.is_terminal(node, y): \n",
    "            best_split_column, best_threshold, X_left, y_left, X_right, y_right = self.best_split(X, y)\n",
    "\n",
    "        if self.is_terminal(node, y) or best_split_column is None:\n",
    "            node.prediction = np.mean(y)\n",
    "            node.is_terminal = True\n",
    "            return\n",
    "        \n",
    "        node.column = best_split_column\n",
    "        node.threshold = best_threshold\n",
    "        node.left, node.right = Node(), Node()\n",
    "        node.left.depth, node.right.depth = node.depth + 1, node.depth + 1\n",
    "        self.grow_tree(node.left, X_left, y_left)\n",
    "        self.grow_tree(node.right, X_right, y_right)\n",
    "        \n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit the Decision Tree Regressor.\n",
    "            \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray, shape (n_samples, n_features)\n",
    "            The input samples.\n",
    "        y : ndarray, shape (n_samples,) or (n_samples, n_outputs)\n",
    "            The target values.\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "            Returns self.\n",
    "        \"\"\"\n",
    "        # Check the input\n",
    "        if y is None:\n",
    "            raise ValueError('Y should not be None')\n",
    "        X, y = check_X_y(X, y, accept_sparse=False)\n",
    "        self.is_fitted_ = True\n",
    "        self.n_features_in_ = X.shape[1]\n",
    "        \n",
    "        # Initialize the tree (root node, depth = 0)\n",
    "        self.tree_ = Node()                             \n",
    "        self.tree_.depth = 0                            \n",
    "        self.tree_.prediction = np.mean(y)\n",
    "        \n",
    "        # Grow the tree\n",
    "        self.grow_tree(self.tree_, X, y)\n",
    "        return self        \n",
    "    \n",
    "    def get_prediction(self, node, x):\n",
    "        \"\"\"\n",
    "        Get prediction for an object `x`\n",
    "            - Return prediction of the `node` if it is terminal\n",
    "            - Otherwise, recursively call the function to get predictions of the proper child\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        node : Node() object\n",
    "            Current node of the decision tree.\n",
    "        x : ndarray, shape (n_features,)\n",
    "            Array of feature values of one object.\n",
    "        Returns\n",
    "        -------\n",
    "        y_pred : float\n",
    "            Prediction for an object x\n",
    "        \"\"\"\n",
    "        if node.is_terminal:\n",
    "            return node.prediction\n",
    "        \n",
    "        node = node.right if x[node.column] > node.threshold else node.left\n",
    "        return self.get_prediction(node, x)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\" \n",
    "        Get prediction for each object in X\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray, shape (n_samples, n_features)\n",
    "            The input samples.\n",
    "        Returns\n",
    "        -------\n",
    "        y : ndarray, shape (n_samples,)\n",
    "            Returns predictions.\n",
    "        \"\"\"\n",
    "        # Check input and that `fit` had been called\n",
    "        X = check_array(X, accept_sparse=False)\n",
    "        check_is_fitted(self, 'is_fitted_')\n",
    "        \n",
    "        # Get predictions\n",
    "        y_predicted = []\n",
    "        for x in X:\n",
    "            y_curr = self.get_prediction(self.tree_, x)\n",
    "            y_predicted.append(y_curr)\n",
    "        return np.array(y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check yourself\n",
    "from sklearn.utils.estimator_checks import check_estimator\n",
    "\n",
    "check_estimator(MyDecisionTreeRegressor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4 <a id=\"task4\"></a>  (0.5 points)\n",
    "\n",
    "Load boston dataset and split it on the train ($70\\%$) and test ($30\\%$). Fit Decision Tree of depth 1 and make the following plot:\n",
    "\n",
    "- Scatter plot of the traning points (selected for split feature on the x-axis, target variable on the y-axis)\n",
    "- Fitted model \n",
    "\n",
    "P.S. Depth of the tree is equal to the longest path from the root note to the leaf. Thus, tree with depth 1 will have exactly 1 split. \n",
    "\n",
    "P.P.S. Both fitted model and the training points should be on the same plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "data = load_boston()\n",
    "X = data.data\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyDecisionTreeRegressor(max_depth=1)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7)\n",
    "model = MyDecisionTreeRegressor(max_depth=1)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = model.tree_.column\n",
    "t = model.tree_.threshold\n",
    "column = X_train[:,i]\n",
    "pred = model.predict(X_train)\n",
    "labels = [pred[column.argmin()], pred[column.argmax()]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x17f6095ac40>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD4CAYAAADxeG0DAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAABdnElEQVR4nO2dd3hURReH39lekkBCQu8dpEsRUKooINIUQUVUVCzYK/rZFewFK2IDRBGkCAgoHenSFJCA9BogEFI3ybb5/rgksOxuemdenzzJzr137rkJ/nb2zClCSolCoVAoSi+64jZAoVAoFPlDCblCoVCUcpSQKxQKRSlHCblCoVCUcpSQKxQKRSnHUJQ3i4yMlLVr1y7KWyoUCkWpZ8uWLWeklFHBjhepkNeuXZvNmzcX5S0VCoWi1COEOJzVceVaUSgUilKOEnKFQqEo5SghVygUilKOEnKFQqEo5RTpZqeiYEhIS2D7qe1UDqlMgwoNitucAicxPZF/Tv5DpZBKNKzQsEDmTHWlsjVmK2HmMJpVbIYQokDmvSw4exb+/Rdq1oT8Rp15PLBlC6Sng9cLkZHQtClk/D3S0rTjISHQosWFcYADB+DYMWjeHMLDc3/vuDjYuRNq1IA6dfL3HMFITdXsj4mBqlWhbVswmwvnXhcjpcz2CzgE7AD+BjafH4sAlgB7z38Pz26eK6+8Uiryx5ur3pSWNy2y3FvlpPVNq+z4TUd5JuVMcZtVYLy95m1pfdMqw94Kk9Y3rbL91+3lqeRT+Zpz0rZJMmRciAx7K0zax9pl488ay/1x+wvI4jKM1yvlU09JabFIWa6c9v2666RMTMzbfH/+KWVUlDYPSCmElGazlM2aSXn4sJQ//yxlaKiUYWFS2u1S1q8v5Z49Up47J2X37lJarRfseOEFzb6cPsezz/o+R8+eUiYk5O05gjFlipQ2m/ZcGc8XEiLlL7/ke+oM3Q32JWQOqh8KIQ4BbaWUZy4aexeIk1K+LYQYc17In8tqnrZt20oVfph3ft39K7fPvh2Hy5E5ZtQZubrm1Sy/c3kxWlYwLPhvAUNnDiXFlZI5ZtQZ6VC9A6vvXp2nObec2EKXSV18fmc6oaN2+drse2SfWplnxTffwGOPgePC7w6zGQYMgOnTczdXXBzUqgXJyf7HdDptpR8To61oMxACqlWDVq1g8WJwOi8cs9thwgQYPjz7e0+aBA8/DCkX/l1hNsMNN8CsWbl7jmBs2wadOmmfKC7FZoOtW6FRozxPL4TYIqVsG+x4fnzkA4DJ53+eDAzMx1yKHPD+uvd9BAnA5XWx/uh6TiSdKCarCo4P1n/gI+KgPd/mE5s5knAkT3N+sekL0ty+/3N5pZfTKafZcGxDnm29LPjgA18RB80lMnduYEHOiunTNVdKILxeOHLEV6gBpIT4ePjjD/9jKSnw/vs5u/cHH/iKOGjPsWABJCTkbI7s+OILbc5ApKfDxIkFc58g5FTIJbBYCLFFCDHq/FglKWUMwPnvFQNdKIQYJYTYLITYHBsbm3+LL2NiHYF/f0a9kbjUuCK2puA5nXI64LhJb+Ks42ye5oxJjsEr/QVEJ3SccZwJcIUik7gg/6aEgKSk3M119qzvajsQHo//mJS+fvJL58wJwZ5Dp4PExJzNkR0xMZqtgfB44OTJgrlPEHIq5J2llG2APsBoIUSXnN5ASjlRStlWStk2KipohqkiB/Rt0Bejzug3rhd6GlXI+8e2ksINDW7ApDf5jUspaRrVNE9z9mvYD5vR5jfu9DjpWKNjnua8bLj2Wk3sLqVCBahcOXdzdeumuRiyItBxjwdCQ/3HDQa47rqc3btXL9Dr/cfLl9dcNwVBv35gsQQ+ZrNB374Fc58g5EjIpZQnzn8/DcwB2gOnhBBVAM5/D7ycUhQYYzqPIcIagVmv7YILBDajjU/7fopR7y/wpY2nOz1NpC3S7/nG9x6P2ZC3nf+7Wt1FrXK1sBqsmWN2o50Xrn6BSFtkgdhdZnnzTShXDkzn31x1Ok2Uvvoq+Co5GJ07Q48egcXaaoU33oAGDbSfM7Db4fHH4euvtesy7mkyaXa9+mrO7v3664GfY8IEOHRIE2GzWXvDeOih3LuNAEaMgLp1/d8wDAZo0gSGDMn9nLkhq53Q8xuhdiD0op/XAb2B94Ax58fHAO9mN5eKWsk/p5NPy/8t+59sP7G9vHn6zXLdkXXFbVKBcibljHxp+Uuy/cT2cvD0wXLN4TX5njMpPUm+t/Y9edU3V8m+U/vKRXsXFYCllwnHj2uRK+3aSXnbbVJu3Zr3udxuKSdNkrJzZynr1pWyalUpq1WTslMnKadOlTI+XsqPP5ayY0cpe/eWct68C5EpmzZJOXSoZsezz0oZE5O7e584IeUzz2jX33qrlFu2SBkXJ2VkpJQ6nRZlAloUTefOOY+IuZikJCnfe0/Khg21eZs0kXL8eCkdjtzPdQnkN2pFCFEXbRUOWtz5T1LKsUKICsAMoCZwBBgipczSUauiVhQKBaBtQL78suY3l1JbfbdpA8uWgbGAPl3u3g1jx2px3VdcAS+8AK1bXzj+4Yfw4ov+vnu7HVasgHbtCsaOAiC7qJVsE4KklAeAlgHGzwI982eeQqG47DhzRhPQi0P1UlK0EL2ZM+HWW/N/jy1boGtX7R4ejybqCxfCb79B9+7aOVu3Bt6AFQJ27SpRQp4dKkVfoVAULatWXfBXX0xKCsyeXTD3eOIJbb6MSBgptVDK0aMvnNOqla9PPgMpoXHjgrGjiFBCrlAoipZAUSigbUJGRBTMPf76K/D4nj0XYtLvvluLNLl449Zk0tww7dsXjB1FhBJyhUJRtHTvHrj+iMUC991XMPcI9oZgtV7wwVeoABs3atE0er1m0+23w5IluY/KKWaUkCsUiqLFaNSyNStWhLAw7ctigXff1YpMFQRPPukf6mi1woMP+op0gwawdCm4XJq//LvvNHtKGar6oUKhKHpat4bjx+HPP7W47S5dtASdguLJJ7X5J0zQ3CVOJwwdCuPGBT6/lK3ALyVHRbMKChV+qFCUcRIT4dNPYc4czb3x6KNawk1xER8P+/drBbsiS28CWL7DDxUKhSJHJCdrrpGjRy+EFq5bB888A6+8Ujw2lS8PV15ZPPcuQpSPXKFQFAzff6+5My6ND3/7bS12XFFoKCFXKBT55++/NcG+tOwtaD7qjRuL3KTLCSXkCoUif0ybphXFiokJfNzrBVX5tFBRQq5QKPKO0wkPPKCtxAMFTuh0UKWKf7q72+3fLEKRZ5SQKxSKvLNjR/CGCkJoWZIXJ9jExcEtt2gx3lartpLftavo7C2jqKgVhUKRd8LCtNV1INq3hw0XtdOTUsvqjI7WEnAA1q/XxHzv3lIdHljcqBW5QqHIOw0aaE2FL22oYLfDmDG+Y2vWwIEDF0QcNHFPT9ciXhR5Rgm5QqHIH/PmQf36EBJyId3+8cdhwADf8/btC+yGSU2FnTuLxNSyinKtKBSK/FGjhuYu2bwZTp3SXCoVA/Rib948sJDbbKWq9ndJRAm5QqHIP0JkL8Zt22rnbNx4IWlIr9fK2o4YUfg2lmGUa0WhUPizcKEmvBERcM01mn+7oOZ9+GGthGxICNx8s7aSL4UVB0sSqmiWQqHwZcYMrenCxVmaNhssWADduhWbWZcz2RXNUityhUJxASnh6af9U+0dDm0DU1EiUUKuUCgukJYGJ04EPvbPP1q8t6LEoYRcoVBcwGLRfNfBaNwYmjSBWbOKziZFtighVygUFxBC60AfDK8Xdu/WokymTi06u/LKvn1aPfRhw2DyZN8Su2UItdmpUCh8cTq1zU2PJ+vzqlWDY8eKxqa8sGCBVtfF5dK+7HaoU0crC5DVp44SiNrsVCgUucNk0lbcJlPW5504AadPw5Qp8NVXcORI0diXE9xu7RkcjgslAVJStBX6Z58Vr22FgBJyhULhz6efaqGGVmvwxsShoVC7NowerbljGjWCsWOL0srg7NjhW9Mlg7Q0+PnnorenkFFCrlAo/LHb4Y8/tEiVZ57RBP1ibDatRkpqqtarMzVVE8lx47QEn+LGbg/uGiplbpWcoIRcoVAEp0EDeOcdzR1RqZKWUh8RAUOGgNnsf35amuZqKW4aNtQ+LegukTi7Xav50qGD9n3sWO2NqJSjhFyhKMm4XFqkSHEzcqTWyi0xUWuk3KtX4PO8Xq0sbUlg3jxtQzY0VFuFWyxaga8pU+Cvv7SKi2++CR07lhyb84gScoWiJLJ1q1ZgymLR3Bj33FP8K0chNFuEgOuvD9xQwm7XIkVKAvXqwcGDMGcOTJigRbEcPuybtZqWpp3zyy/FZ2cBoIRcoShpHDkCXbtqvuaMFe6PP/rX9y5OIiPh448137nBoIm73a4VwerRo7itu4BeDz17wu23a7/XS10toEWzLFlS9LYVIKqMrUJR0vj0U//GxOnpWtu06Ggts7IkcP/9WmTL1KnaKnfgQLj66uBRLsVN5cqBhdxk0lwupRgl5ApFSWP79sAd5g0G+O+/kiPkoIUcvvFGcVuRM669ViuXm5Liu+9gMMC99xafXQWAcq0oFCWNDh0CR4Q4nVpXekXeMBhg5Upo2lRzCYWEaJ2Mfv1Vi3ApxagVuUJR0hg9Wgv3czovtEazWqF3b603piLv1K+vJQvt36/FvjdtGtjdUsrI8RMIIfRCiG1CiN/Ov44QQiwRQuw9/z288MxUKC4jKlXS2qH17asJeIUKWuZkGcxILDbq1YNmzcqEiEPuVuSPAdFARk+mMcAyKeXbQogx518/V8D2KRSXJw0awG+/FbcVilJCjt6OhBDVgRuAby4aHgBMPv/zZGBggVqmUCgUihyR088VHwPPAhenmFWSUsYAnP9eMdCFQohRQojNQojNsbGx+bFVoVAoFAHIVsiFEP2A01LKLXm5gZRyopSyrZSybVRUVF6mUCgUCkUW5MRH3hnoL4ToC1iAMCHEVOCUEKKKlDJGCFEFOF2YhioUCgXnzsH338OWLdCypVa6oEKF4raq2MlVhyAhRDfgaSllPyHEe8DZizY7I6SUz2Z1veoQpFAo8szBg9C+vZbQk5qqRfRYLFrHn0aNitu6QqUwOwS9DfQSQuwFep1/rVAoFIXDo49CXJwm4qB9j4+HBx8sVrNKAqpnp0JR1jh3TisWFRaW/bmlCYslcLlZnU4r91tGYsIDoXp2KhSXCzt3Qps2WkJRVJRW0Kok9dHML8F6iBqNJbdQVxGhhFyhKAvEx8M118C2bdrq1OmENWu0aoSB6oaXNk6d0rIxLxVskwluvVUJeXEboFAoCoCpU/0rJno8msAvWlQsJhUYp05Bixbw778Xas+AJuKtWsH48cVmWklBFc1SKMoCO3f6dr7JwOmEQ4eK3JwC5f33tTckl8t3XKeD5cu1hhaXOWpFrlCUBXbuDDzudmt+89LM4sWB67ObTLBrV9HbUwJRQq5QlAW2BEm89nq15sKlmWrVAo87nVo9cYVyrSgUJR2vF7p3h337sjgpLchBCehPgtUCYeW0sMTSRvpsEHG+/nEArwk6lZ6yH1Onan/HwkAJuaLMcTj+MBM2T2Bf3D661e7Gna3uJMQUUtxm5ZkzZ+DPP6Fz5yy6vC2LhkOHQXoDH08V4DXD0KHBw/hKLBaITtBqtAu0d7aKlbSmypbiti3nFGapKZUQpChTrD68mj4/9sHldeH0OLEZbUTZotg8ajORtsjiNi9P7NqldXibNg2GDQtyUkyM1iLu+HHffpSXEhWlbRA2agTffguTJ1/oWTl8eMlesaelab+MqKhS3yw5t2SXEKRW5Ioyg5SSEb+OIMWVkjnmcDk4kXSCN1a9wfg+pTNMLaP6c2RW70NVqmhx4/XqZS3ksbHQpYtWcOqvvy5EumzbBgsXwvTpBWZ3gWOxlP6N20JCbXYqygzHk45zMvmk37jL62J29OxisKhgiD2mpaVHhWeT2GOx5GxFnZamFZq6OFwxJUXrSLR1az4sVRQXSsgVZQarwYo3iI/YbiqFscZOJzz0ELF3PQNA1LUt4Ztvgp9fsaLWhzK7LMf09MA1S9xuWLUqHwafR0qtwfHGjYHDBhUFjhJyRZmhgq0CnWp0wiB8PYY2o43R7UYXk1WBOZ54nEcWPkKjzxrRfVJ3Fu0NkH352GMwaRKx7vIARMbv1cay6uX500+aDyarJBm9PvCGp8mU/x253buhYUMt5PG667Q3l7lz8zenIlvUZqeiTBGTFEOPKT04lngMgcDldTG48WCmDJqCXlcyNvJOJJ2gxZctSExPxOXVshVtRhtv9XyLRzs8qp2UkqIJcloajzKeKYwgnnDtmE4HlStr5Vufe04rGnUxqakwZ46W0Tl1Khw4cGEFbrNp4S/r1mn3uJhy5bTN0rxmSrrdULMmnDzpGypotcI//2gNpRV5IrvNTiXkijKHlJK1R9dyNOEobau2pUGFkiUgjy16jC83f5kp4hnYjXZin4nFarRqVQsbN4bUVG7lJzbRjn1c8hxWK9xwA/zyS/CbpaXBZ5/BlCnaJmiNGtqqu3p1+PprTeClhPLl4ddf4cor8/5gf/wBQ4ZAUpLvuNEIjz8O776b97kvc1TUiuKyQwjB1TWvLm4zgrL04FI/EQfQCz3RZ6JpU6UNVK2aGX0SSxRRBGhcnpqquVn27YP69QPfzGKBp5/Woj3694e9ezW/td0OtWrBF19oK/GWLfNfQTA21j9pB7QaKSdO5G9uRZYoH7lCUcRUD60ecNzpcVLJXkl7YTBoQksWQg6aX3vHjqxv6PXC7bdrrpSMzceUFM3lsnKlVkGwIMrAXnNN4JK5djv06ZP/+RVBUUKuUBQxz3Z+FpvR5jNm0pu4ptY1VAu7qK5Ir16g03GGyOBC7nZD3brBbxYfr4UUXuruAM3tUpBx47VqwX33+frYrVZt83PIkIK7j8IPJeQKRRHTs25PPrr+I0JNoYSaQrEYLPSo3YMZQ2b4nvj440iLNfiK3GTS6nS3bOl/bPt2zZ1SsaIWQZLR5/JSbLbA43ll/HgtW7RnT61R8rhxsHZtKSwLULpQPnKFohgYdeUo7mx5J3vO7iHKFkWV0Cr+J9WvT+KcZbiuNxGpiwOdAUJCIDlZi1wZNAi++sr/urNntezNhISsjbDZ/BsXSwmbNsGxY9C2rRaFkhuEgJtu0r4URYYScoWimDAbzLSo1CJoEhNAbN0OAER9/hrc9bq2eZmUpK1wzebAF02aFDgRRwjtKyOFv2pVLeolg5MntfJ8Bw5obxReL4wYob1ZlOHGxmUB9ddRKIqJ2dGzqTu+LvrX9VR8ryKfbPyES8OBY49rghz1+O3aCrptW4iOviDiHo8WuTJ6NLzyChw8CP/9F9iVIqVvHZaDBzX3R3Ky9vraa7WEHqdT8587ndqbQlbZpIoSgRJyhaIYWLh3IXfMuYOD8QcBiHXE8vyy53l/3fs+553530cARKUf1YR4yxbo0UMLI3S54PrrtebDX3wBb7+tlUk0GnOW1OPxaG6YH36A/fu1npiX4nbDO+/k+3kVhYsScoWiGPjf8v/hcPn22HS4HIxbPQ6P16MNHDtG7MYDAL6bnenpWh/LH3+EDRsurKidTm0lPnkyVKjgn/EZCIdDy/LMKu3/9OncPJqiGFBCrlAUA/vj9gccd7gdJKYnai/27iXWUBmASM5cOMnt1lLef/zRP80eNH/2+PEwcqQWj54VRqNWmzwiIngseZ062T2OophRQq5QFDEer4eaYYGjQexGO+Us5bQXjRoR6wrHQip2LhJso1FLpXc4As6BlFrY4dNPZ78qN5u1phJ9+gQ+Vwh4880cPJWiOFFCrlAUIX/s+4OqH1Zlf3yQFbnTwcTNE7UXVasSW6stUeIMPmtls1kL7wvWcNlm07oFxcVlLeTVqsGKFVoBrshI+PJLbe6MCBWjEe6+G268MdfPqShaVPihQlFE7D27l8EzBvv5xi8m3ZvOU0ueok54Ha6vfz1nGnUiyhEDzggt7LBjR/jkE5g4MXA6PGjZlRMmaEW3PB7/43q95naZONF3fORI6NoVfv5Z87X3769FtShKPErIFYoiYsLmCbg8/sWyLsXhcvD2mre5vv71xJ7REdmiGvxx1vekXbsCi7QQ8MEH2s96PVSqpPXzTEvTXC4Wi1b98O23tXOmT4cXXoDDh7XKiGPHwv/+l88nVRQ1SsgViiLiUMKhgFUPA3Es6RigFRRs2DDACVddpbVru7TTj5S+MeQul7ay9ni0CoR9+8LDD0N4uCbiI0de8LUfOqSt5r1erRGzotSgfOQKRRHRq24vv2JZgTDoDPSs0xPQhDxg055HH9UKUmWXcZmeDsuXw6xZmvC/9JIm4qCtxC/dMHU41Iq8FKKEXKEoIu5ocQdVQ6uiy+J/O53QEWoK5YVrXiA1VYsuzBTyhAT49lt47z0tnX7TJm21HRoKVaoEDx8M5ks/fDjw+NGjgeuKK0osyrWiUBQB/539j++2fUfH6h2pVa4Wyw4u8ztHIBh2xTDeuvYtaparydGj2nhUFLB6teYWkVJL/Hn1VRg8WFtpZ6zKr75aS+65WIQNBhg4MLBRNWpo7pRLqVatYOqTK4oMJeQKRSHz046fuHfevbi8LtxeNyHGEGqE1eCM4wxp7jR0QodJb+Llri8z5uoxmdfFnk/mjAz3aJUOMzI4QfN9z5kD/fppP0+erImv3a75uB0OrVJiRETwFPuxYzWf+MXuFZtNxY2XQpSQKxQFwMFzB3lt1WusOLSCyiGVGdN5DIOaDCLFmcJ98+8j1X1hAzLZlYxE8mznZ0l2JmPQGbit+W20qNTCZ84MIY86/W/gaoYpKfDII5oQZ2R42mxavZX27bUCW0OHar70QNx2myb6//uf5k6pXh3eeAPuvLMgfiWKIiRbIRdCWIA/AfP582dKKV8RQkQA04HawCHgFinlucIzVaEoWWw6vokFexfg8rr47K/PSHGm4JEejiQcYfic4bx+7nWaV2qOQef/v1mKK4W/jv/FwtsXsvHYRh747QG2xmylgq0Cz3R6hsc6PEZsrObeiHIdDyzkoBW9uriiocOhFb/66ito3Tr7hxg+XPuSUrlTSjE5WZGnAz2klMlCCCOwRgixCBgMLJNSvi2EGAOMAZ4rRFsVihKBlJJR80fx086fSHOlgcCvprjD5eCVla8we+hsv9K0GdiNdraf2k6PKT0yk4ROJJ3gf8v/x8nkk1Q+8RpgJuqJO0Cm+09gNGpulUtxu2HZspwJeQZKxEs12UatSI0M55zx/JcEBgCTz49PBgYWhoEKRUljyYElTNs5DYfLgRdv0MYQep2eCGsEFoPF75jdaOe+K+/jjVVvkOryrR3ucDmYvHI8p8d9gx435WWc/+QWi1bsKlBzCaNRq36ouGzIUfihEEIvhPgbOA0skVJuBCpJKWMAzn+vGOTaUUKIzUKIzbGxQRrIKhQlnFRXKtN3TueTjZ/w6V+fkuIKUHXwEpxuJ9XDqrPgtgWUt5Qn1BSK3WjHYrDwcPuHua7edWw9uRWJ/4r9ibUeYhPNVOAsugDH6dULFi/WsjcvJaPdmuKyIUebnVJKD9BKCFEemCOEaJbTG0gpJwITAdq2bauCUxWljh2ndtBtcjdcHhdOjxO3N0hc9kWY9Wauq3cdlUMqUzmkMjFPxbBo7yLi0+LpUacHtcrXAqBpZFMOnjvoJ+YDdroZIysEbroMMH8+LFmi9ebcuPGCn9xshl9/hbCwfDyxorSRq6gVKWW8EGIl0Bs4JYSoIqWMEUJUQVutKxRlAikli/Yt4ustX7N4/2Ic7uCFri7GrDPj8rooZylHz7o9SXOnYTFYsBgsDGoyyO/8l7q+xPJDy30KadkMNizl7cSeiQou5KDVT1m1Cpo31+qrGAxatEp2NcgVZY5sXStCiKjzK3GEEFbgWmA3MA/IiFO6E5hbSDYqFEXOE388wS2/3MKve34NKuICgUlvwma0YTVYGdBwAG7pxouX0ymneX7Z83T6thNp7rSg92lfrT2/Dv2VhhUaIhCEmEJ47KrHqP7C25wRFbMWctBS8DN6eHbqpET8MiUnf/UqwGQhhB5N+GdIKX8TQqwHZggh7gGOAEMK0U6FokiQUrL91Ha+2vJVlgIM0DiyMfe0vgezwcx3W79j7n++axmHy8Ges3uY8s8URl05Kug89SLqMarNKDxeDzc1vYl6EfVASmIfTCHKvRysIVp0SkZW56UIoYl5hw55emZF6SdbIZdSbgf84piklGeBnoVhlKJ0E5MUQ2J6IvUj6qPXBdiMK6HM3zOfRxc9yuGEwwE3IC/GarBy/5X389hVj/HishfZdmpbwPMcLgfTd04nLjWOHad20KF6B+5seWdmF6DxG8czZumYzMiXV1a9wrge43ik3RPEpYcQ+egw6BQOVatqtVVefNG3uiFoAt+0af5/AYpSiwgW41oYtG3bVm7evLnI7qcoWk4mn2TIL0PYfHwzep0em9HGt/2/5cZGJb/DzOrDq+n9Y+8smz5kEGIKoUWlFiwfsRyzwUzEOxGcSwueC2fUGdHr9KS507AZbYSYQth832ZcXhdXfHGF38rfYrCw8qZormpSm08/1arOAnDunFbTNi7Od3OzTRtYu1bFgpdhhBBbpJRtgx1X1Q8VBYKUkut/uJ4NRzeQ5kkjxZVCrCOWYbOG8e/pf4vbvGx5fdXr2Yq4QRi4t/W9TLtpGn/e9SdmgxbD7fQEybo8j9vrzhRrh8vBWcdZnlr8FHOi5wSMQXd73fy4cTFwSQnb8HAtQqV3by1W3G6Hu+7SwhCViF/WKCFXFAjbTm5j/7n9uKVvaF66O51P//q0mKzKOf/F/Rf0WIgphBBTCNOHTOfr/l/Tr2E/H5dRnwZ9spz7UjeNR3pYuHchEhkw69PtdfPln78AAWqR160LCxZovvLkZK2lW0hINk+nKOsoIVcUCMcTjwf0h3ukh4PxB4vBotzRunJrBP6rWovewk+Df+L006cZ3GRw5viRhCOMWTqGG3+6kZphNXN9P4/0cGPDG4N2DHInlQcgtHyA1HyF4hJUrJKiQGhbtS3pbn/RsRqsXFf3umKwKHe81u01lhxY4uNesRvtPNv5WT8f/6bjm+gxpQdOjxOnx4n5gBmByHaD1Aep1VUx682kewKIdYq2FI92/Ek7euXpmRSXD2pFrigQqoRW4cG2D2I32jPHTHoTkbZI7m1zbzFaljNaVm7JijtXcE3Na7AZbdQuX5sPrv+Al7q85HfuffPvI9mZnOkbzxBivbjwiUQgsBltAVf5oBXZ2h+3P9PP7odDE3Lzqp+0uuOBimMpFOdRUSuKAsPr9fLyypeZuGUiTo+T/o368+H1HxJpiyxu0wqMFGcK5d8pHzRNXy/0eKQHvdBTL7weFWwVWH9sfdD5gq7kF34C24dzzlCR8sIK5ctr3X+qVy+gJ1GUJlTUiqJIkFLywIIH+HjDx5xxnCHJmcTMXTP5dtu3xW1agWLUG9GJ4P/beKQn8/vhhMPUDKuJ3WgPujLPEPGLj+u9oE+OopKMpXyyG5KS4MQJreO9QhEAJeSKAmH9sfX8tOMnUlwpSCRe6SXVncqrK1/laMLR4javwDDpTQxqPAiT3pTtuemedGZGz0RKmaX/XI+eh9o+RP+G/bmx4Y08u8VKu/+iqJt+5sJJHg+sWOGfDKRQoDY7FQXE7OjZAeOwBYKFexdyf9v7i8GqwuGrfl9xJOEI209tR6/T43Q7SfekBxRrj/RkW3BLr9PTr1E/etfvrQ08XIEW7ijqECDaR3W3VwRArcgVBYLVYA0YfqgX+oCNFUoz5SzlWHfPOtaOXMv3A75n+4Pb6Va7m5/LJZg75VIkkiaRTS4MDBlCLJdUPtTpoGNHrSenQnEJSsgVBcLtLW7HqDP6jXukh/6N+he5PWnuND7d+ClXfXMV3Sd15+edPwdtuZZXWlZuyeAmg2lQoQHf9v+WSFskISYtOSfEFEKYOSxgv86L0Qs9AxsPzKxPDiDHjuMMkUQZE7QBu13r+PPddwVqv6LsoFwrigKhcWRj3u/1Pk8teQqDMGh9LL1ept00jXBreJHYsC1mG2uPriXKFsWHGz5k5+mdme6etUfX8vGGj3mj+xv0rNszyw3LvFAnvA4HHj3AjH9n8N/Z/2hVuRVNKzalw9cdgka4hJnCeKTDI7zS9RWf8QR9BG4galhPqP481K8PQ4dqgp5BfDzMnas1W+7dG+rUKdDnUZQuVPihokA5lXyKRfsWYdQZ6dewX2aVv8LE4/Vwy8xb+H3f73ilF4Eg1R14U9Cit1A3oi6r717NudRzTN0+lSRnEjc2vJEutboghCAhLYFUdyphpjBmRs9kS8wWGldozO0tbifMfKHzTkJaAj/u+JE9Z/fQrmo7bm56s58bafrO6dwz7x50Qqf1+JRejHojZr2ZcpZyrB25lprlanLWcZap26dyIP4Adb3X8/gNfZk8GUaMCPAQf/wBgwdr7haPR/ObP/ccvPpqAf5WFSWJ7MIPlZArSjROj5NtMduwm+xcEXUFIkBxqK82f8WTi5/MUeVCAB062ldrz98n/8bldWXGfbev2p5QUygrj6xEIHB5XQgEHunBpDcRYgxh/b3raVihIbvP7KbTt51I96TjcDkIMYUQZYti5V0rOZ54nEhbJA0qNAC0fp8PLHiAn3f+7FNgSy/0dKrRifG9x2e2kkt1p2KN6UnqV0uZOdfBTf0v8YmnpEDlylqdlYux2WDpUs2PrihzZCfkyrWiKLHMiZ7D3XPvRkqJR3qoGlqV/3X5Hyadic41O1OzXE3WHV3Hs0ufzbGIA3jxsuH4Bp8xj/Sw/njwxB2nx0mcJ44WX7bg6ppXs+3kNp/StcnOZFJdqdQbXw+byYbL4+KKilcwb9g8qoRWYeWhlX5VEj3Sw8bjGxk2cxiJ6YmZ46kJmgtl7tFvuIlHfQ354w9tJX4pqakwebIS8ssUJeSKEsmeM3sYPme4j0DvjdvL3b/ejd1oxy3d9KzdkxWHV+RKxPNLuiedZQeXBTyWkQyUIcp/x/xNv2n92DJqCy5P4BR7KSWHEw77Djq0TNilJ6fBpUKe0SnIfyKt7ZviskQJuaLE4ZVe3ln7TsAiXBJJsktzKyzctzB3haqKGLd0s+PUDgb+PJD6EfU5m3rWb1XeoEID9sXt873wfMEsS7kkrYHE779r9VZCQ+GmmwLXXbHbYdiwwnoURQlHCbkiKFJKZu6ayTfbvsHlcTGi5QiGtxiebUhdfvhj3x/cNfcuYlNiM1e4Qe0rwSKegcvrYu6euVj0FtxeNzajDYfLgdVgxaQ3Me2maYyaP4pNJzZdaDLhiAKjg/va3QqDBsHy5ZpPXK/X6o8PGQIzZ4LbrX3ZbNp515X8KpOKwkEJuSIo98y7hxn/ziDFlQLAX8f/YtrOaSy6fVGBh+8B/Hf2PwbPGFygrpLmFZsTHRvt1/CiqEnzaB2CapWrRa+6vagXUY87WtxBuDWcaTdN4+rvryYpPQmnx4kntQqGsCSejmsEy97SNjhBi1BJTYVffoHVq+G33zSB798frrlGdQm6jCkVQu5wOUh3pxdZPLICdp7eyc87f/YJ40txpbDu6DqWHljKdfX8V3+J6YnohC4zKSaDpPQkJNIndC8Qn//1ebZt03JLQnoCb1/7NnP3zGXDsQ1BGzkUFXvO7mHHgzt8smDrhNfh0GOHWLh3IUcTj/Ljsr649OUwzpxzQcQvxmiEgwdVuKEikxKd2Xku9RyDpw8m/O1wKr1fiSafN2H90eCRBYqCY8XBFQH7SSY7k1myf4nP2O4zu+nwdQci340k4p0Iuk/uzpGEIxyKP0TX77tS4d0KRL4bScdvOrL37N6g9zxw7kDQ5Jm8ciThCC+teIl64fUClhDILRfXHM8LBmEIGEJp1BsZ0HgAD7d/GHdyeaKihNbCLVCEihBgtebLDkXZokQLeZ8f+7DgvwU4vU5cXhe7z+ym1w+9OBR/qLhNK/NEWCMw6v1T7s16M1H2C40kE9MTafd1O/468RcurwuX18Wfh/6k87ed6fRtJ9YcXZM5vvH4Rjp914kUZ4BVJnBt3WsL5VlS3alM3THVr1t9XsjOb58VAsHVNa/O1i0VGwuRkWhlay0B6tQIAdcWzu9KUTopsUL+98m/2Xl6J06v70dtp8fJ5399XkxWXT4MbDww4OpTr9MzvMXwzNfDZw8n2embnOLFS6wjlvi0eJ9VvUSS5kpjxr8z/OY96zjLD9t/KMAn8KWgV/oXoxf6gHVmLi2aJZGsP7aer7Z8leV8sbHnmy536AAvvaSJeUiIFrUSFgbz5wcWeMVlS4kV8gPnDgT8KOzyuog+E10MFl1e2E12Ft+xmEr2SoSaQgkzhVHeUp5Zt8yiamhVAOJS41i4d2HA650eZ8BelMmuZJ9mzJP/nkz1D6sT+V4kW2K2FM7DFDJGnTGgGypQVE2qO5VnFj8T9NOBw6F9RWV86BkzBg4cgM8/h0mT4ORJbWNTobiIErvZ2apyq4AbX1aDlc41OheDRZcf7au15/iTx9l8YjMur4sO1Tr4uFu2nNiCWW8OWm/brDf71TwJMYXQunJrAKb8M4WHFj5U6Ak9AoFO6PLlFsmKYLXIg9ojBNGx0bSu0trv2MnTbsBAsuEgHm9NbTFTpUqQoisKhUaJXZHXDa/LoMaDsBoubOrohZ4QU0iZalKQW2ZHz6bjtx2p/0l9HlrwECeSThTq/fQ6PR2qd+Dqmlf7+cwr2isG3LgDCLeE0zSqKWb9hebCBp2BMHMYjSMbc+DcAZ78Pef1UfJDZXtlBjcZHND9URDkNp7d6XH67DNksOLgCtp8eD0AH25/nmofVmPDsQ1+5ylKEf/8oyVx1a0LN94If/1VKLcpsUIOMGXQFF7p+go1y9UkwhrBsGbD2DJqCxHWiOI2rVh4a/Vb3DHnDjYc28D+c/v5Zus3tJrQilPJp4rFnhaVWlA3vK6fL92gMzBn2BxW3rWSR9o/QqQtEp3QIRDEO+Jp/mVzGn7akLNpZ4vEznPp57i2zrW0rtwau9FOqCk0x00fglHOXI5mUc2wGYI3etAJnd/GpklvolP1TlQP822iHJsSy43TbiQhTnuzSTMd5VTKKa7/4XqS0pPyZauimNiwATp10rJyDx6EBQuge3dYsiT7a3NJiRZyg87Ac1c/x+HHD3P22bNMHTyVGuVqFLdZxUJieiJv/PmGzwrW5XWRkJ7Ah+s/LBabhBD8Pvx3WldpjdVgJcwURqgplG/7f0uXWl0IMYXw3nXvUSOsRqa9Do8Dj/QUmpsjEGnuNEYvGk1Mcgw1y9WkR50eNKrQKF9zrr9nPT/f/HPQ1bhBZ6BDtQ681u01bEYbYeYwLAYLnWp04pdbfvE7f9rOadrvxHF+pW7TugN58TIrela+bFUUE088oW14ZNTGkVJ7/eijWV+XB0qsj1zhy87TOzHqjX4+Z6fHydIDS4vJKqgaWpVN921if9x+zqWdo3nF5pgNF9wph+MPs/vM7oCbgUWJ2+vmaKLWBLogNsvrhNfBYrBwTa1r+PPwnz6bl6GmUJaNWEa7au0AeLLjk/x7+l8q2iv6dAK6mDOOM9oc5+usYNeEPN2dzhnHmYDXKEo4W7cGHt+zR6uXYyw4V1+JXpErLlAlpErAzV+BoGb5msVgkS/1IurRtmpbHxEHLSu3MNL5i5Pa5WtnNpD4deivPHDlA4SZwzDpTFxf73o2j9qcKeIANqONdtXaBRVxgO61u2sZsY5I0LnAEg9oiULda3cv1OdRFBIVKgQeDw0FQ8GuocvW/2FlmDrhdehQrQMmncln3Gq08nTHpwvsPieSTnDT9JuwvGnBNtbGiDkjiEuNy/U8qw6tovWE1jT7ohmprsDdei7GarBiKAUfEM16M7NvmZ352mq08lHvj0gYk0D6S+n8Pvx3GlZomOt5u9XuxjU1r8GQVgVsZ0CA3WjnxoY3cmXVKwvyERRFxTPP+DfLttk010oB18VRHYJKEedSz3HbrNtYcWgFRr0Rg87Ap30+9UnQyQ+prlQafNqAk8knM33YJp2J+hXqs+PBHTleWW86voluk7v5RaTohR6P9GRuNEokRp0Ro96IXuhJcpbsTb065euw5I4l1IuoVyjzu71u2vc8wZ69bq4aex8jW4/k1ua3lrlPNJcNUsLzz8Mnn2grcJcL7rkHxo/XKlnmAtXqrQxyKvkUcalx1I+oHzCNPq9M+WcKoxeMzqz3nUGIKYSZQ2bSolIL1hxZQ4Q1gm61uwWtXXLDjzewcJ9/opBe6Lm56c1cW+da9Do9yw4uo2a5mtzb5l6aft40YAJRUSMQNIlqwq7YXZljIaYQIm2RrL9nPZVDKhfq/Tt3BrNZq1yrKCMkJ8ORI1C9upaZmwdUq7cySKWQSlQKqVTg8+44tcNPxEHbUH1/3fusPrIak15z7YSYQlg2YhlNopr4z3N6R8D5rUYrr3d/PdP1MKjJIGbumsns6Nm0rtzar/1acbHkjiWEmkJZtG8R/539jyaRTejfqH+BvmkGIzYWWvvnCSlKMyEh0LRpod4iWyEXQtQApgCVAS8wUUo5XggRAUwHagOHgFuklOeCzaMo+VxR8QpCjCF+Yq4XelYfWU26Jz1z1ZzsTKbvT3058OgBv6SgplFNMyNELsbj9VAttBoAKw+upM9PfXB73Xi8nhLTJMKo01xWoeZQbrniFkCze/5/81m4dyGRtkhGth5J/Yj6hXL/M2cuSs9XKHJITpxvbuApKWUT4CpgtBCiKTAGWCalbAAsO/9aUYq55YpbCDWH+iT4GHVGdELn5/aQSM44zrA1xj/EKiN2+mJsRhuj24/GbrLj8rjo/WNv0txpuL3uEiPiOqGjZeWWVLRXzBxzeVz0nNKTO+bcwddbv+b9de/T4ssW/PKvfyx4fnG54Nw5JeSK3JOtkEspY6SUW8//nAREA9WAAcDk86dNBgYWko2KIsJmtLHx3o30adAHg86ASW9icJPBtKjYIuD5OqHz2aA8nXKaRxc9yrCZw6gSUiWzuFaENYLbmt3G1pitVPuwGvU+qVci/OEZGHQGQk2hVLRXZNpN03yOTd0+lc0nNmdWeHR5XaS6Uxk5b2SOonFyw9nzia6RkQU6reIyIFc+ciFEbaA1sBGoJKWMAU3shRAVg1wzChgFULNm3uKd166FXbuyP09RENSgP/O5sZK2ShbnBCsOrmBL9Ey/OPZ0g4V/y3dir16LF3915fskpTvxSK1WtklvonuNq2kc2ZhvvvsGl7cuULeoHyhLBDqaVGxG55qdaRHRguWzDFy8z/j2mlOknLvV7zq3wcqL7x+mcWTjArMlJkb7rlbkityS46gVIUQIsAoYK6WcLYSIl1KWv+j4OSlllr3Y8hq1Mno0fPFFri9TKEodQmgJga1aFbclipJEgUStCCGMwCzgRyllRjbEKSFElfOr8SrA6fybG5ixY+GFFwprdkVOSHenM2/PPJYeWEqkLZLhLYb7RKzcOvNWVh/50+86uzGEVHcq3iKsrZIbaobVYvXI1QFDKcetHsdXW77CE6ApRYS1Atvu31Yg7eMuxmqFiMuzJpwiH+QkakUA3wLRUsqLqzPNA+4E3j7/fW6hWAiUL699KYoTM4/XGsLjDAl4tEm9MNbGn8SLb00Vr96KScgCabOWVwQi6Ibquif+olpYYDGOTl+KJ+RIwGOPdL2PmjUKVsQVirySk6iVzsAdQA8hxN/nv/qiCXgvIcReoNf514rLlIfbPRxQLN3STQVLkJoTRYBJb2JUm1EBjw1vPpxqYVo4ZHxaPMcTj3Oxq7FFpRZBa5i/teYtxq0eV/AGKxR5INsVuZRyDQQt3tyzYM1RlFaOJh7FbDD7rbxdXhfHk48X+v0bRTTiQPwBXF5X5phBZ6BX3V5M3j7Z73y90PNS15c46zjLiDkjWHpwKTqho6K9It/1/46edXvSrmq7oCt5p8fJ2NVj6VO/T8BOPwpFUaKKOFwGuL1uvtj0Ba0ntOaKL65g3OpxBd6ZZ8uJLaS7iyekUCCYNXQWtcvXJtQUih6tGbJA8M+pf3B5XH7X6HV65u+ZT58f+7DkwBKcHidp7jSOJBzhhp9uYOC0gdw3/74smzanudMKtWF0kXL4MIwaBQ0bQo8esHhxcVukyAUqRf8yYMgvQ1i8f3GmeL/555vMjp7Nhns3YNDl/5+AlBKnx1mofTGz4su+X3JFxSvYNXoXM/6dwUMLHiLFmYJbujmWeCzgNR6vhyMJR9gVu8tnFQ9aD865/2W/5SOl9Lu2VHL4sBYmk5wMbjfs3QsbN8JHH2nirijxqBV5GWdrzFYfEQetk/ues3uYv2d+vuf3Si+3/HILb615q1hE3Kw3M33XdJweJwadgSMJR3B6nLhl8JU0aHY3imyUr6gTm9HG0CuG5vn6EsMbb0BSkibiGTgcWhlWp38NfEXJQwl5GWfd0XUBu/MkO5NZeXhlvuf/eefPLNy3sFhEHLTV84ZjG/jsr88AWLx/sV8XpWB0r909T+4ggcBmtDG8xXA61+ic6+tLHMuXgyfA309K2L+/6O1R5Bol5GWcKiFVAkZeWAwWaoblv7PQd9u+y5O/XSCoFlqN5hWbI87/l1dS3al8t+07AGqVq5Wj+t0Wg4UGFRowouUIv7owWWHQGbit+W0sG7GMCf0m+BUMK5VUqxZ43OlUaaalBCXkZZx+DfthNVj9hNKgM3BHyzvyPX9eC14ZdUYGNBrAiaQTWI3WAiuc9dhVj2HRW7I8x2qwcl+b+zDoDEzoN4H3er1HpDVnBU7cXjczd80kIS2BuNS4zBospZrnn/fvZGM2Q9++qvBLKUEJeRnHbDCz6u5VNIlsgtVgxW60UyOsBn8M/8Onyl9eubvV3diN9lxf5/Q6+WbbN5xNPZvtit5msFHeXB6z3hzwuNVg5e5WdwPQqnIrJg+aTIQ1ghBTCBaDhRphNbDoLYSaQrEYLAxrNoz3rnsP0Ap/PdTuIQ49fojmFZvnaHWe7kmn94+9qfR+JSLeiaDvj305nVJoic2FT9++8PbbWt3s0FBNxK+/HqZMKW7LFDlEdQi6jDhw7gAuj4uGFRoWmEvA4/Vw8y83s2T/ElJcKbm6Vid0Af33GZj0JvrU68Nb175FwwoNuWfePUz/d7pPrLrFYKF9tfYsHr7Yp/Gz2+tmz5k9lLeUp1pYNZKdyRyKP0TV0KpEWAPnwKe70xk5dyTT/52eK5+/QWegUYVG7HhwR+l2taSlwb59ULGi9qUoMahWb4pCR0rJuqPrmLtnLu+vez/HbpKMHp6BMOvNNKvYjKUjllLeUj5zfPOJzfy6+1f2x+2nZrma9KrXi551ehaYgN4x5w6mbp+a6+tCTCEsun0RV9e8ukDsUCguRrV6UxQoqa5UYpJjqBxSOdMNIYSgc83OdK7Zma+3fE18enyO5gq2iNALPa90fYUxV4/BK70cPHeQ8pbyhFvDaVu1LW2rBv337DP3kYQj2Iw2ouw537BrWaklM/Qz/Er25oRD8YeUkCuKBeUjV+QIKSUvr3iZyPciafFlCyLfjeS5Jc/5uEYOnjtIUnpSFrNcMmeQlbtZb+aRDo8wO3o2VT6oQrMvm1HlgyoM/HkgCWkJ2c678tBKao+vTZPPm1Djoxp0ndSVmKSYHNk0svXILN09wfB4PbSurFL1FcWDEnJFjhi/cTzvrXsPh8tBiiuFVHcqn236jLfXaLXSnB4nnb7thIec+5YvFnKBwKw3YzVY+eWWX9gVu4sRv44g1hGLw+Ug3ZPO7/t+Z8gvgasvZnDw3EFu+PEGjiQcIdWdSronnXVH1tFjSo+gnwAuJsIawRVRV+T4GUDbbO1VtxdXVNSui0+L5+edPzN953Ti0+JzNZdCkReUa0WRLW6vmzFLx/i1Z3O4HLy/7n1euOYFXlr+EidTTub5HhXtFXmzx5sMbjKYCGsEQ2YM8Wullu5JZ/WR1RyOP0yt8rUCzvPGqjdwuH2jYNzSzdGEo6w7uo7ONX0TeNLcaXi8HqxGK4lpiew4vYMqIVUCpu5fjF7oMevNRNojGdVmFM92fhaAaTuncc/cezJLH7i9biYPnMyQK7J+AypSpISVK2H1am1Tc+hQCM+yJ4yihKOEXJEtX2z6ImiPzXNp5/BKL19t+Spf90hzp3Fvm3szXx84dyCg68WsN3M86Ti1ytfiSMIRvtr8Ffvi9tGtdjfuaHEH03dNDzi/R3p86q6cSj7FPfPuYfH+xbi97swImox7Zpeg5JEebCYbhx8/nDl2LPEY98y9xy+z9M5f7+TqmldTJbRK9r+IwsblghtugPXrISVF62Tx7LPwxx/QsWNxW6fII8q1UgpweVxM3DKRzt91psv3Xfjhnx/y5MfNKxM2Twh6rH54fXRCl+/EGJPexKpDq/B4NddMt9rdMOlNfuele9JpGtWU1YdX0/Tzpry//n1m7JrBM0ueocFnDYJWK0xzp3E65TRSSrzSyzXfX8Mf+//A5XUhkXikx+eNI+PnYPXIAb/9gF/+/SXo32XmrplZ/wKKim++0ZrgJidrK3OHQ6uzcvPN4C26f1OKgkWtyEs4Xunlhp9uYO3RtZmJM1tjtvLbf78xfUjg1WdBk1Xtkpe6vARAh2odWHdsXZ7vEeuI5cZpN2I1Wll0+yKe6vQUk/6ZREJaQmaIot1o58mOT1LOXI4Rv47wiVtPcaWQ7k7PMgzx+WXPsyt2F4ObDOZk8sksS9RmYDVaqW2vzd64vX7HOtXo5PM61Z0acE63113gZYPzzPffa+J9KYmJsHMntGhR9DYp8o1akZdwlh9czvqj632EIMWVwm97f2PLiS1FYsPNTW8OmFVZJaRKZpr/p30/JcQU4lcWVyd0Oa6jkuRM4nTKaa774ToibZFsu38bI1qOoHpodVpVbsXEGydyS9Nb6PRdJw7FH/K73i3dWYpziiuFSf9MYv2x9TkScQAkPNXxKexGOwahPZtRZyTUFMr43uN9Tu3XsF/ATxEGnYF+Dfvl7H6FTbA3OimDH1OUeJSQl3CWH1xOssvfbeH2ull5aGWR2PBcp+eIskVhMWg1TMx6M3ajnV+G/JK5Am5TpQ1/3/83Q68Y6iPcF/udc4rL42LpgaXULFeT7wZ8x9Enj7Lt/m10q92Nzt93ZsOxDUGvrRJSBaveGvS41+vNrJ2eEwx6A/e0uYdt929jZJuRXFX9Ku5vez/bH9xO80rNfc5tUakFo64chd1ozywEZjfaebDdg5kRLcXOyJH+dVVA6/jcrFnR26MoEJRrpYRTyV4Ji8Hi10LNpDflKtElr6w+vJohvwwhxZWClBKrwcrtzW/n1W6vZva7BG3zcEvMFkx6EwadwS/iw6Q3EWYKIy4tDillwHMy8OINGC/+2V+fZdnE2WqwUj2sOmdSzwQ9x+l10iiiEa2rtGbz8c2keYLPZ9KbmH3LbAw6Aw0qNOCrftlv6H50/Ufc1OQmftzxIzqh47bmt5WsJKF77oF582DVKi0l32IBvR5mzVIr8lKMEvISzq3Nb+V/y//nN64XegY3GVyo9z6VfIrrpl7nJ54zds3gw+s/zHz9ztp3eHXlqxh1RtLd6UEF+oVrXuDBdg/ilV7m7ZnHvD3zmLN7jn+fT4+LbrW7+V2/JWZL0IxLvdDj8rj468Rf2T6XW7r5Y/gfvLbyNSZumRgwE9WkN/HH8D/oWrtrtvNlkOZOY070HA4nHOamJjfRs27PoCt/KSXpnnTMenPR1mcxGOC332DdOvjzT6hUSdvoDAsrOhsUBY5yrZRwKtor8tttvxFliyLUFEqIKYSqoVVZcscSQkwh+Z4/IS2BPWf2+DVYOJ1ymmZfNAu4AvZ4PZlRGGuPrOX1Va+T5k4jyZmE0xtYaHVCR/9G/bEYLNiMNoY1G8aUQVNoX629T/VEm9HG89c87xOqdyLpBG+seoMTiSfQC/+OPnqhR0qZbVegDDusRis2o413er1D3HNx3NbsNl8bDDYGNBoQ8M0kGPvi9lHr41rc/9v9vLj8RQbPGEzHbzoG3OT85d9fqPVxLezj7ES8E8G41eNylKxUYAgBnTtr5WtHjlQiXgZQK/JSQLfa3Yh5KoatMVvR6/S0qtwqxz7eYKS707n/t/v5eefPGPVaiN2rXV/lqU5PAfDwwoeJS40LfK0nnVhHLABfbfnKL3EnA4FAJ3SY9CZeuOYF6kXU8zlu0BlYesdSpu2cxox/ZxBqCmXUlaPoXqd75jnrjq7j+qnX4/K4AsayWwwWnB4nXnIWOqcXevo26HvBRiH4YfAPzNszj/EbxrPpxCZcHhe/7v6Vcm+Vo15EPYY0HcJD7R6inKVc0HmHzx7OGceZzPDDZGcy209tZ+yfYxnbc2zmeYv2LuLOX+/MjASKT49n7OqxuLwuXun6So6eQaG4FFX98DLl/vn388P2H3xCC21GG98P+J4hTYdgGWsJ6sawG+0sG7GMDtU7MPDngczd49+oWIcm4LXL1+ata99iYOOBObZNSsmqw6v478x/vPbna5xIOhHUjmHNhvHdtu9yvKE6ZeCUgA014tPiqfVxLRLTE/2OWQwWKtsrs+2BbT6VGDOIS42jygdVAv6+qodV5+gTRzNft53Yli0x/tFGoaZQzj57NvNNVaG4mOyqHyrXymVIqiuVKdun+MWHO1wOxq7WVo9ZvcH3qteL9tXaA3DLFbcEbCzhxUuaJ43/4v7jjjl3EB0bnSPbzjrO0mJCC26cdiOP/fFYUBEHmDxwMp/3/TzHn0506Fh8YDEh40IIGRfCyLkjMz91TNsxLctkopMpJ/lk4ycBj2f1u7r02IFzBwKe5/K6OJd2LiePoVD4oYT8MiSrQk4xSTEIIejXsF9m3PTFtK3alplDZpLmTuPbrd8y498ZlLOUw2oIHPLnlV4cLgcvr3w5R7Y98NsD7Dmzh2RncpYRKqDVDk9MT2RAowE5mluv0zN953RSXCmkuFKYun0qnb7thNvr5njS8SyTdtLcaczd7f/JA6CCrUJm79GLMevN3N78dp+xplFNA85hMVioYK2Qo+dQKC5FCfllSKWQSoSaQv3GBYKWlVoC8Hnfz6kSWiVzQzXUFErNcjWZf+t8Ut2ptPu6HY/9/hhz98zlVPIpPNLDlZWv9EsIAk3M1x3JPuvT7XUzd8/cLItV+dgrBHN2z2H6zdOzrVho0pvQ6/Q+c7u8Lk4knWDR3kVcVf2qbDePs2qNN3XwVCKsEZmfTkJMITSObMyLXV70Oe+tnm/5venZjDZe6/Yaep3/Rq5CkRPK/Ganx+vhs78+45O/PiExPZE+9fswtsdYapSrUdym5Qiv9LL84HJ2nNpBgwoN6F2/d0CxzA06oeOj3h8xav4on1WoRPLnkT8ZOXck3/T/hr2P7GV29Gx2n9lNk6gmDGo8CLPBzLtr3+XAuQOZrhmP9ODxeNh7bi+6IGuD6mHVs7VLSpmrFmuprlSe+OMJFuxdwIybZ3Au7Ry//fcbFe0VCbOE8d7a9zgUf4gGEQ1oXqk503ZO85vD4XKw8/ROnu38LE0im7DpxKag92sc2ZhzqecIt/pXCmwc2ZhDjx9ixr8zOBx/mLZV29K3QV8/cb6m1jUsuG0Bzyx5hn9j/6VqaFVe7vIyd7a6M8fPrVBcSpnf7MzowZghWHqhJ9waTvToaCJtJbtDeEJaAl0ndWX/uf04PU7MejMV7RVZO3ItlUIq5Xv+ZQeWMeSXIX6+WZvRxru93uWBKx/gWOIxwq3hhJkvhKgF27ADzZ3g8Xp8QgFtRhs/Df6JAY2zd4F0+b4La46s8atVLhBBI1MEghBTCFtGbaFBhQY+xzxeD2NXj+Wdte8EdJ2EmkL5fsD33NT0JhwuB/ZxwRtJ2ww2EDD7ltlcX//6bJ9FoSgoLuvNzqMJR5m2c5rP/8Ae6SHZmcyXm74sRstyxpilY4g+E02yMxmnx0mSM4nDCYcZNX9UgczfpkqbgA2THS4HY1eNpdL7lWj6RVMqvleR4bOHZ/4eswrDS/ekI5EYhAG70U45czneu/a9HIk4wMQbJ1LeUj6zjZzdaKdySGVGtByBzWgLWLdFIn02ai/mqcVPBRVxgzAQYY2gf6P+AAFj1C/G4XbgcDm4+ZebS04RLIWCMu5a+efUP5j1Zr9NszR3Gn8e/rOYrMo503ZO8wtpc3vdLNy3ELfXnW8XS4orJah4nUw56bMqnhU9C6fHyYwhM3i43cNsPLYx4JsAaG+Wle2VWTNyDTXK1QhYSCoYjSMbs//R/Uz+ZzI7T++kbdW2DG8xHLvRzj1t7uHzvz5nVvQsPz+6R3pYf3S9z1hSehJfbfkq4KapQNC3QV8m9JuQGfJn1BuxGqxZVnsEzTW19MDSzDcAhaK4KdNCXrt87YAbZwadgUaRjYrBotwRrLa1lLJAMgGrhVYjyh7FkYQjPuMC4ReXneZOY/6e+ZxxnGFg44H0rt+bWdGzgs59MuUkdcLr5DpxySu9GPVGHuvwmF/q+tU1r6ZxZGPm7J4T8NpLE46OJh4NeB5ArXK1mHurbxSKTugYdeUovtr8VZY1WJDkvHqiQlEElGnXSrOKzWhVqZXfitCkN/FYh8eKyaqcM6DxgIBlYbvW7logiSNCCCYNmITNaMtsoGA1WIOKr1Fv5GTySYQQARNnLqZaaLVcibhXenlj1RuEvxNO+DvhVPuwGlO3T/U7L9IWyaDGgzIrMWZgM9p44ZoXfMYW7l0YNISxZeWWAcff7fUug5sOxqw3az7xALi8Lq6te21OHkuhKBLKtJAD/Hbbb9zQ4AZMehNmvZl64fVYcNsCv02xwsLj9TDlnyl0m9SNrpO6MunvSZldcLLjg+s+oFpotcywOLvRTqQ1kq9v/LrA7Otepzv/PPAPQ5sNpW3VtjzV8SmGXjE0oMvFK73UC9dWvadTTged06w3M67nuBzb8Pu+32n0aSNeXfUqiemJuL1uYpJjuP+3+5m3Z57f+d8P/J7bmt+GxWDBYrBQJaQKUwZO8aky6Pa6eX3V60Hv+VC7hwKOm/Qmfhz8I4cfP8yyEcu4pektmWVpTToTVoOVb/p/47P5W+js3AkLFsCJ4MlRisubMu1aAQi3hjN76GySncmkulKJtEUWWbU5KSVDfhnC4v2LM/3JW05sYXb0bOYOm5utHRaDhVe6vsKaI2sw6Ay0r9aeYc2GYTcFj6zILWcdZxk+ezg7Tu/AqDOy89RObmp6EzajjRRXSqZ7x2a08Uq3V7AatRjofg37sfvMbr/6JwLBhH4TGNFyRI7u/8aqN3hrzVsB/dIOl4OXV7zs54u2GCx82/9bPuvzGYnpiUTZo/xW/2cdZ7PckAyWYZlBpZBKVAqpxM/Vf2b9sfXM3zOfUHMotzW/jdrla+fo2fJNXBz07Qs7doDRCOnpcPfd8NlnoCvzazBFLijzQp5BiCmkQKoF5oYNxzb4iDhoG4zLDy5n7dG1WdapXrJ/CYOmD0IIgVd68UovNcrVKFARBy07ctvJbT6bqnN2z2FM5zHsit3FqsOrqBJahTGdx/h0gn/iqieY/M9kzjjOkOZOQyCwGq2M7z2eu1rdlaN7n3GcYdyacVlmcAbqBJSB1WjNfGO5lHBreNDORDntWASa+6lTjU5+bd2KhDvugG3bwHnRhvfkydCyJdx/f9HboyixZPu2LoT4TghxWgix86KxCCHEEiHE3vPf/TMkFKw8tDKgSDlcDlYcXBH0uhRnCoOmDyLFlUKyMxmHy0GaO4231rzFxmMb/c5Pc6ex6fgm9sftz5V951LPsfzgcr/IGIfLwbSd05h28zROPHWCLaO2+Ig4aGnp/zzwD89f/Tztq7ZnYOOB/DH8D+5tc2+O77/h2IZsI1ry2lnHpDdxd+u7Ax4z6o05TusvNuLjYelSXxEHrd/m+PEBL1FcvuTk89kkoPclY2OAZVLKBsCy868VlxBpi/TblANtQzGrZKQ/9v8RcKMwzZ3GpL8n+YxN2jaJqPeiuHbKtTT/sjntvm5HTFJMjuxLdiYH3ZBMSPfv0HMpEdYIXu76Mhvv28jsobNz3Qkn0hYZNDIHNHfO2z3fztWcFzOh3wS61+ruM2bUGfms72c+9c4vJik9ibm75zJ/z3wcLgdOj5NPN35Km6/acOXEK/li0xe4PDkrIZAvkpODu08Ssv/bKC4vsnWtSCn/FELUvmR4ANDt/M+TgZXAcwVpWFlgyBVDeHLxk37jOp2Ooc2GBr0uWPlYr/T6+KTXH13P6EWjfXzB22K20efHPvz9wN/Z2lc9rDoVbBU4lnjMZ9ygM9CvQeE3C+5QrQMV7RVxuBx+gt4sqhmf9f2Ma2pdk+f5dULH8ruWEx0bzazoWVgNVm5uejO1ytcKeP7MXTO589c7MyOFvNJL3fJ12XduX+bvePeZ3czfM5+Fty8s3L2WatUgMhKO+f5tMBjghhsK776KUkled0wqSSljAM5/D1pNSAgxSgixWQixOTY2No+3K52Ut5Tn99t/p6K9IqGmUEJNoUTZolh420IirBFBr+tVt1fA+He70c7QKy68AYzfON6vqYNHetgbt5edp3deerkfQgi+7f8tNqMtM0rFYrAQYY3glW6F3+RACMHSO5bSsEJD7EY7YeYwQkwhTBowiR0P7chVm7WsaBLVhBe7vMhTnZ4KKuJHE44yYs4IHC4HiemJJKYnas0hTm/3eaN0uBysPrKadUezLwKWL4SA777TGiXrz0cQWSxak+RXXy3ceytKHYW+2SmlnAhMBK3WSmHfr6A5cO4AB88dpGlU06Afx7Oic83OnHjyBFtjtiKRXFnlymyr3FWwVeCTPp/w2KLHcHldeLwebEYbAxoP4Lp612WedyzxWMCGCkadkVPJp2hWMfuu6NfVu47N923mk42fsDduL91qd+PBtg9SwVY0JVXrhNdh10O7+Df2XxLSEmhTpU3ADcyk9CQ2n9hMuDWclpVaFvhq+OedP+e4YFe6O53VR1bTuWbnArXBj169YPNm+OQT2LsXunWDBx+ECqrcrcKXvAr5KSFEFSlljBCiChA8qLiUkuJM4eYZN7Py8ErMejPpnnSGtxjOhBsm5LrcqF6np121drm65r4299GlZhd+2P4DSc4kBjUeRNdaXX0E7IYGN7AlZovfhmq6J50rq16Z43s1iWrCl/2Kr/aMECLLN50v/vqCp5c8jVFvxOP1UCOsBouGLwoaBhiXGsdba95i9q7Z2E12RrcbzX1X3pdlglKSMynHvm+LwULlkMo5OjffNGkCX5b8ukCK4iWvrpV5QEbdzTuBwBX3SzGjF45mxaEVpLnTSEhPIM2dxk87fuKjDR8VmQ2NIhvxZo83Gd97PN1qd/NbhT7Y7kEq2Sth1pszx+xGO690fSVgS7KckuZOyzZzE2DKP1Oo90k9LG9aaD2hNUsPLM32mujYaHpP7Y1trI1K71XitZWvBRXQFGcK8/fM54nFT5DqTiUxPZEUVwr/xf1H76m9A5YpSHYm03ZiWz7d+CkH4g+w4/QOnlz8JPfMvSdLu/o26Bs0lPFS9Do9Nze9OUfnZkWqK5Wp26fy0vKXmLlrZtFsoirKJNmWsRVCTEPb2IwETgGvAL8CM4CawBFgiJQycKfeiygtPTudHidhb4UFbPZ7aQ/G4uZc6jk+3vAx8/bMI8oexRNXPUGryq04nXKaRpGNAkbNZDXXvfPu5be9v+GVXhpHNua7/t8F/DTxxV9f8MzSZ3z8x1aDlYW3Lwzaff5Y4jGu+OIKktKTMl1CVoOVQU0G8ePgHzPPOxR/iLt+vYs1R9YEdXeEmEJYddcq2lRp42vXpi94ZskzfslAFoOFfx/6l7rhdQPOJ6Xkrrl3MWvXrMy4f7vRTr+G/Vh3dB1xqXFIJBVtFZk1dJbffXPL4fjDdPy2I0nOJJKdyYSaQqlor8iGezeU+PLKiqInuzK2OYlauTXIoZ55tqqEk+5ODyogOVmpFiXh1nBe6/4ar3V/jYS0BIbNHMaKQyswG8x4pZe3e77N6Pajs51HSsl1P1zH9lPbcXq1qJmdp3fSY0oPokdH+zSG8EovL618yU8sU92pPL/0edbf61uFMIPxG8aT5k7z8eunulOZHT2bowlHqVGuBunudDp924lTKaeyDE3UCV1mv82LWX5wecCMTqPOyKbjm4IKeUbdmaFXDOXH7T+i1+m5s+Wd9KjTA4DoM9EIBI0jGxeIf/6++fdxOuV05r+zJGcSae40nln8DN8P/D7f8ysuL1SebwBCzaGZNUUuRiDoXrt7gCtKBrfOupXlh5aT7knPjLp4dumz/L7v92yv3Rqzlegz0ZkinoHT4+SLTV/4jMWnxZPsTA44z64zu4LeY+PxjQFDK816M9FntObMv+7+lWRncpYiDuDyuGhX1f+TQt3wupkFwC5GIqkWVi3LOYXQStv+eNOPTBk0hZ51eyKEQAhB06imNIlqUiAi7vK4WH5wud9iweV1ZVlRUqEIhhLyIEy8caJPWJ5JbyLMHMZ7vd4rZssCczL5ZNAszXfXvpvt9fvP7Q9YKMvpcRIdG+0zFmYOC+qyqVs+8IoXoEWlFgFrqKd70qkfUT/Tjpw0bRjXc1zABhcPtH3ArzKkXuipGlqVzjUKOcokB0gpWXVoVdA3qqKqA6QoWyghD0KXWl3YMmoLd7e+m841OvNo+0f596F/i6xqYm45nXI6aLr78aTjQa9LTE9k7ZG1hFvCA8auWw1WvzojBp2B5zo/l9nFJwOb0cYbPd4Ieq8nrnrCZ2MWNN91jzo9Ml0erSq3ynLTUSd03NTkJh6/6vGAx+uG12XesHlUC62GzWjDrDdzVfWrWD5ieZ5Ecn/cftYeWVsgLjWv9DJs1jAGTh8YMGzUpDf55AkoFDnlsimalRcaRzYu0JKxhUmjCoEbZRh0BnrV7RXw2Ntr3ub1Va9j0ptwepxYjVaklJlNFfRCT6gpNGD9lOevfh6jzshba94iIT2BqqFVea/Xe/RrGDwjtF5EPZaNWMaDCx7kn1P/YNKbuLPlnXx0/YVIoOvrXU/d8LrsPrPb79NFiCmEeuH1+H5A1j7knnV7cvSJoxw4dwC7yZ6nUMG41DgG/jyQzSc2Z/5+Xuzyol/N89yw4L8FLPhvQcDOSiHGEGqWr8m7vbL/9KRQXEqZb758OTFh8wSeWvxUpmvCoDNQzlyOvx/426+L/bw987ht1m0+omLUGakRVoM0TxoOl4O+9fvy9rVvU6NcjaD3lFLi8rpy1c4NNJeNQWcIGNudmJ7Iyyte5qcdP+GVXtpVbUeH6h24qvpVXFfvulx3HcoLvab04s8jf/q8mdiNdqYOnsrAxgPzNOfts27np50/+Y2b9Cae7vQ0r3d7Pdc5CorLg3xHrShKDw+0fYC64XV5d+27HE88Ts+6PXn+6ucDbvK9v+59v5Why+viRPIJ9j+6n6qhVXN0TyFErkUcyPKaMHMYH/f+mI97f5zreQuCmKQYVh9Z7feJIMWVwvvr3s+zkJv0poBt9Mx6Mx2rd1QirsgzSsjLGNfVu84njT8Yp1JOBRw36oycdZzNsZAXJFJK/jn1D6eST9G2atsiKxNwKXGpcRj1xoB5BFl1RsqOu1vfzYxdM/w2c4UQqnWcIl+ozc7LlL4N+gYM09MJXbE0pj6RdIJWE1px9XdXM3TmUKp/VJ1XV75a5HYANKzQEIPwX+MYdUb61O+T53m71OrC4x0ex2KwYDVYCTGFYDfamTN0Tq4StxSKS1E+8suUk8knaTWhFfFp8aR70jM7/Hx5w5c5btNWkHT4pgNbTmzxia3Or086P/yw/Qce+O0BUl2pSCQmvYnylvL8ff/feSqedjEHzh1g8f7FhJhC6N+of9H2/1SUSrLzkSshv4yJTYnlow0fsXj/YmqWq8lTHZ8q/Ip+ATgUf4imnzcN2LezS60urLprVebrZGcy0bHRVAurVujun3VH1/H+uvc5knCEXnV78UTHJ6hoD1qxWaEoNJSQK0o822K20XVSV5KcSX7HmkU1Y8dDO5BSMm71OMauHotRb8TpcdKzTk9+vvnnIu/FqlAUNdkJufKRK4qdKypeETCk0Kw3Z7pVZvw7g3FrxmVWQUxzp7H0wFJGzh1ZxNYqFCUPJeSKHOFwOfh+2/fcP/9+Plz/IWcdZ3N0nVd6WbR3EaMXjObF5S+y9+xev3NMehNf3PAFNqMtU9CtBiuVQyrzRMcnAHhn7Tt+0R7pnnTm7ZlHfFp8/h5OoSjlqPBDRbbEpsTS/uv2xDpiSXGlYDVYeX3V66y+ezXNKzUPep3H66H/z/3589CfJLuSMeqMfLj+Q77u/zW3N7/d59zbmt9GowqNGL9xPEcTj9Knfh/uv/L+zHoqwcL+9Do951LP5av+ukJR2lErckW2/G/5/ziedDwzgSjVnUpCegJ3zb0ry+tmRc9i1aFVJLu0Sokur4tUdyqj5o8KWD3xyqpXMmXQFFbcuYJnOz/rUxSrR50eAYt62Yw2aparmY+nUyhKP0rIFdkyO3p2wIJaO07tICEtIeh1P+34KWBdEYPOwKpDqwJcEZzXur1GqDnUJ/bdZrTxWZ/PVEak4rJHuVYU2ZJVOn2gsrQZWA1BqhhKMBvMgY8FoU54HbY/sJ13177LikMrqBNehzGdxxRLuKRCUdJQQq7IlpGtR/LB+g98mjwbhIEedXpgN9mDXndvm3uZ/998v1W5Xqena62uubajRrkafNr301xfp1CUdZRrRZEtL3Z5kY7VO2I32rEarISaQqkdXjtH5WQfaf8IFoMFm9FGqCmUMHMYv932m1/zB4VCkXdUQpAiR0gp2XRiE3+f/Jva5Wtzbd1rc1xO9lD8IZYeWEqYOYx+Dfv5NaRQKBRZozI7FQqFopSjMjsVCoWijKOEXKFQKEo5SsgVCoWilKOEXKFQKEo5SsgVCoWilFOkUStCiFjgcCHeIhI4U4jzl1Qux+e+HJ8Z1HNfbmQ8dy0pZVSwk4pUyAsbIcTmrEJ0yiqX43Nfjs8M6rmL246iJqfPrVwrCoVCUcpRQq5QKBSlnLIm5BOL24Bi4nJ87svxmUE99+VGjp67TPnIFQqF4nKkrK3IFQqF4rJDCblCoVCUcsqMkAsh9EKIbUKI34rblqJCCHFICLFDCPG3EOKyKSsphCgvhJgphNgthIgWQnQsbpsKGyFEo/N/54yvRCHE48VtV1EghHhCCPGvEGKnEGKaEMJS3DYVBUKIx84/87/Z/a3LUoegx4BoIKy4DSliukspL7dEifHA71LKm4UQJqDMFziXUu4BWoG2aAGOA3OK06aiQAhRDXgUaCqlTBVCzACGAZOK1bBCRgjRDLgPaA84gd+FEAuklHsDnV8mVuRCiOrADcA3xW2LonARQoQBXYBvAaSUTillfLEaVfT0BPZLKQszS7okYQCsQggD2pv2iWK2pyhoAmyQUjqklG5gFTAo2MllQsiBj4FnAW8x21HUSGCxEGKLEGJUcRtTRNQFYoHvz7vSvhFCBG8cWjYZBkwrbiOKAinlceB94AgQAyRIKRcXr1VFwk6gixCighDCBvQFagQ7udQLuRCiH3BaSrmluG0pBjpLKdsAfYDRQoguxW1QEWAA2gBfSilbAynAmOI1qeg470rqD/xS3LYUBUKIcGAAUAeoCtiFEMOL16rCR0oZDbwDLAF+B/4B3MHOL/VCDnQG+gshDgE/Az2EEFOL16SiQUp54vz302j+0vbFa1GRcAw4JqXceP71TDRhv1zoA2yVUp4qbkOKiGuBg1LKWCmlC5gNdCpmm4oEKeW3Uso2UsouQBwQ0D8OZUDIpZTPSymrSylro33kXC6lLPPv2EIIuxAiNONn4Dq0j2NlGinlSeCoEKLR+aGewK5iNKmouZXLxK1yniPAVUIImxBCoP29o4vZpiJBCFHx/PeawGCy+LuXpaiVy41KwBzt3zYG4Ccp5e/Fa1KR8Qjw43k3wwHg7mK2p0g47yvtBdxf3LYUFVLKjUKImcBWNNfCNi6fdP1ZQogKgAsYLaU8F+xElaKvUCgUpZxS71pRKBSKyx0l5AqFQlHKUUKuUCgUpRwl5AqFQlHKUUKuUCgUpRwl5AqFQlHKUUKuUCgUpZz/A/V90+KbGE1dAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.linspace(column.min(), column.max())\n",
    "plt.plot(x, (x < t)*labels[0] + (x >= t)*labels[-1], c='b', label=str(model))\n",
    "plt.scatter(column, y_train, c=np.array(['r','g'])[(column < t).astype(int)])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5 <a id=\"task5\"></a>  (0.5 points)\n",
    "\n",
    "Keep working with boston dataset. \n",
    "- Use `GridSearchCV` to find the best hyperparameters (`max_depth` and `min_samples_split`) on 5-Fold cross-validation\n",
    "- Train the model with the best set of hyperparameters on the whole train dataset. \n",
    "- Report `RMSE` on test dataset and hyperparameters of the best estimator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "[CV 1/5; 1/40] START max_depth=1, min_samples_split=1...........................\n",
      "[CV 1/5; 1/40] END max_depth=1, min_samples_split=1;, score=-0.042 total time=   0.1s\n",
      "[CV 2/5; 1/40] START max_depth=1, min_samples_split=1...........................\n",
      "[CV 2/5; 1/40] END max_depth=1, min_samples_split=1;, score=0.469 total time=   0.1s\n",
      "[CV 3/5; 1/40] START max_depth=1, min_samples_split=1...........................\n",
      "[CV 3/5; 1/40] END max_depth=1, min_samples_split=1;, score=-0.077 total time=   0.1s\n",
      "[CV 4/5; 1/40] START max_depth=1, min_samples_split=1...........................\n",
      "[CV 4/5; 1/40] END max_depth=1, min_samples_split=1;, score=-0.027 total time=   0.1s\n",
      "[CV 5/5; 1/40] START max_depth=1, min_samples_split=1...........................\n",
      "[CV 5/5; 1/40] END max_depth=1, min_samples_split=1;, score=-1.993 total time=   0.1s\n",
      "[CV 1/5; 2/40] START max_depth=1, min_samples_split=2...........................\n",
      "[CV 1/5; 2/40] END max_depth=1, min_samples_split=2;, score=-0.042 total time=   0.1s\n",
      "[CV 2/5; 2/40] START max_depth=1, min_samples_split=2...........................\n",
      "[CV 2/5; 2/40] END max_depth=1, min_samples_split=2;, score=0.469 total time=   0.1s\n",
      "[CV 3/5; 2/40] START max_depth=1, min_samples_split=2...........................\n",
      "[CV 3/5; 2/40] END max_depth=1, min_samples_split=2;, score=-0.077 total time=   0.1s\n",
      "[CV 4/5; 2/40] START max_depth=1, min_samples_split=2...........................\n",
      "[CV 4/5; 2/40] END max_depth=1, min_samples_split=2;, score=-0.027 total time=   0.1s\n",
      "[CV 5/5; 2/40] START max_depth=1, min_samples_split=2...........................\n",
      "[CV 5/5; 2/40] END max_depth=1, min_samples_split=2;, score=-1.993 total time=   0.1s\n",
      "[CV 1/5; 3/40] START max_depth=1, min_samples_split=5...........................\n",
      "[CV 1/5; 3/40] END max_depth=1, min_samples_split=5;, score=-0.042 total time=   0.1s\n",
      "[CV 2/5; 3/40] START max_depth=1, min_samples_split=5...........................\n",
      "[CV 2/5; 3/40] END max_depth=1, min_samples_split=5;, score=0.469 total time=   0.1s\n",
      "[CV 3/5; 3/40] START max_depth=1, min_samples_split=5...........................\n",
      "[CV 3/5; 3/40] END max_depth=1, min_samples_split=5;, score=-0.077 total time=   0.1s\n",
      "[CV 4/5; 3/40] START max_depth=1, min_samples_split=5...........................\n",
      "[CV 4/5; 3/40] END max_depth=1, min_samples_split=5;, score=-0.027 total time=   0.1s\n",
      "[CV 5/5; 3/40] START max_depth=1, min_samples_split=5...........................\n",
      "[CV 5/5; 3/40] END max_depth=1, min_samples_split=5;, score=-1.993 total time=   0.1s\n",
      "[CV 1/5; 4/40] START max_depth=1, min_samples_split=10..........................\n",
      "[CV 1/5; 4/40] END max_depth=1, min_samples_split=10;, score=-0.042 total time=   0.1s\n",
      "[CV 2/5; 4/40] START max_depth=1, min_samples_split=10..........................\n",
      "[CV 2/5; 4/40] END max_depth=1, min_samples_split=10;, score=0.469 total time=   0.1s\n",
      "[CV 3/5; 4/40] START max_depth=1, min_samples_split=10..........................\n",
      "[CV 3/5; 4/40] END max_depth=1, min_samples_split=10;, score=-0.077 total time=   0.1s\n",
      "[CV 4/5; 4/40] START max_depth=1, min_samples_split=10..........................\n",
      "[CV 4/5; 4/40] END max_depth=1, min_samples_split=10;, score=-0.027 total time=   0.1s\n",
      "[CV 5/5; 4/40] START max_depth=1, min_samples_split=10..........................\n",
      "[CV 5/5; 4/40] END max_depth=1, min_samples_split=10;, score=-1.993 total time=   0.1s\n",
      "[CV 1/5; 5/40] START max_depth=1, min_samples_split=20..........................\n",
      "[CV 1/5; 5/40] END max_depth=1, min_samples_split=20;, score=-0.042 total time=   0.1s\n",
      "[CV 2/5; 5/40] START max_depth=1, min_samples_split=20..........................\n",
      "[CV 2/5; 5/40] END max_depth=1, min_samples_split=20;, score=0.469 total time=   0.1s\n",
      "[CV 3/5; 5/40] START max_depth=1, min_samples_split=20..........................\n",
      "[CV 3/5; 5/40] END max_depth=1, min_samples_split=20;, score=-0.077 total time=   0.1s\n",
      "[CV 4/5; 5/40] START max_depth=1, min_samples_split=20..........................\n",
      "[CV 4/5; 5/40] END max_depth=1, min_samples_split=20;, score=-0.027 total time=   0.1s\n",
      "[CV 5/5; 5/40] START max_depth=1, min_samples_split=20..........................\n",
      "[CV 5/5; 5/40] END max_depth=1, min_samples_split=20;, score=-1.993 total time=   0.1s\n",
      "[CV 1/5; 6/40] START max_depth=1, min_samples_split=50..........................\n",
      "[CV 1/5; 6/40] END max_depth=1, min_samples_split=50;, score=-0.042 total time=   0.1s\n",
      "[CV 2/5; 6/40] START max_depth=1, min_samples_split=50..........................\n",
      "[CV 2/5; 6/40] END max_depth=1, min_samples_split=50;, score=0.469 total time=   0.1s\n",
      "[CV 3/5; 6/40] START max_depth=1, min_samples_split=50..........................\n",
      "[CV 3/5; 6/40] END max_depth=1, min_samples_split=50;, score=-0.077 total time=   0.1s\n",
      "[CV 4/5; 6/40] START max_depth=1, min_samples_split=50..........................\n",
      "[CV 4/5; 6/40] END max_depth=1, min_samples_split=50;, score=-0.027 total time=   0.1s\n",
      "[CV 5/5; 6/40] START max_depth=1, min_samples_split=50..........................\n",
      "[CV 5/5; 6/40] END max_depth=1, min_samples_split=50;, score=-1.993 total time=   0.1s\n",
      "[CV 1/5; 7/40] START max_depth=1, min_samples_split=100.........................\n",
      "[CV 1/5; 7/40] END max_depth=1, min_samples_split=100;, score=-0.042 total time=   0.1s\n",
      "[CV 2/5; 7/40] START max_depth=1, min_samples_split=100.........................\n",
      "[CV 2/5; 7/40] END max_depth=1, min_samples_split=100;, score=0.469 total time=   0.1s\n",
      "[CV 3/5; 7/40] START max_depth=1, min_samples_split=100.........................\n",
      "[CV 3/5; 7/40] END max_depth=1, min_samples_split=100;, score=-0.077 total time=   0.1s\n",
      "[CV 4/5; 7/40] START max_depth=1, min_samples_split=100.........................\n",
      "[CV 4/5; 7/40] END max_depth=1, min_samples_split=100;, score=-0.027 total time=   0.1s\n",
      "[CV 5/5; 7/40] START max_depth=1, min_samples_split=100.........................\n",
      "[CV 5/5; 7/40] END max_depth=1, min_samples_split=100;, score=-1.993 total time=   0.1s\n",
      "[CV 1/5; 8/40] START max_depth=1, min_samples_split=250.........................\n",
      "[CV 1/5; 8/40] END max_depth=1, min_samples_split=250;, score=-0.042 total time=   0.1s\n",
      "[CV 2/5; 8/40] START max_depth=1, min_samples_split=250.........................\n",
      "[CV 2/5; 8/40] END max_depth=1, min_samples_split=250;, score=0.469 total time=   0.1s\n",
      "[CV 3/5; 8/40] START max_depth=1, min_samples_split=250.........................\n",
      "[CV 3/5; 8/40] END max_depth=1, min_samples_split=250;, score=-0.077 total time=   0.1s\n",
      "[CV 4/5; 8/40] START max_depth=1, min_samples_split=250.........................\n",
      "[CV 4/5; 8/40] END max_depth=1, min_samples_split=250;, score=-0.027 total time=   0.1s\n",
      "[CV 5/5; 8/40] START max_depth=1, min_samples_split=250.........................\n",
      "[CV 5/5; 8/40] END max_depth=1, min_samples_split=250;, score=-1.993 total time=   0.1s\n",
      "[CV 1/5; 9/40] START max_depth=2, min_samples_split=1...........................\n",
      "[CV 1/5; 9/40] END max_depth=2, min_samples_split=1;, score=0.439 total time=   0.2s\n",
      "[CV 2/5; 9/40] START max_depth=2, min_samples_split=1...........................\n",
      "[CV 2/5; 9/40] END max_depth=2, min_samples_split=1;, score=0.717 total time=   0.2s\n",
      "[CV 3/5; 9/40] START max_depth=2, min_samples_split=1...........................\n",
      "[CV 3/5; 9/40] END max_depth=2, min_samples_split=1;, score=0.265 total time=   0.2s\n",
      "[CV 4/5; 9/40] START max_depth=2, min_samples_split=1...........................\n",
      "[CV 4/5; 9/40] END max_depth=2, min_samples_split=1;, score=0.262 total time=   0.2s\n",
      "[CV 5/5; 9/40] START max_depth=2, min_samples_split=1...........................\n",
      "[CV 5/5; 9/40] END max_depth=2, min_samples_split=1;, score=-0.550 total time=   0.2s\n",
      "[CV 1/5; 10/40] START max_depth=2, min_samples_split=2..........................\n",
      "[CV 1/5; 10/40] END max_depth=2, min_samples_split=2;, score=0.439 total time=   0.2s\n",
      "[CV 2/5; 10/40] START max_depth=2, min_samples_split=2..........................\n",
      "[CV 2/5; 10/40] END max_depth=2, min_samples_split=2;, score=0.717 total time=   0.3s\n",
      "[CV 3/5; 10/40] START max_depth=2, min_samples_split=2..........................\n",
      "[CV 3/5; 10/40] END max_depth=2, min_samples_split=2;, score=0.265 total time=   0.2s\n",
      "[CV 4/5; 10/40] START max_depth=2, min_samples_split=2..........................\n",
      "[CV 4/5; 10/40] END max_depth=2, min_samples_split=2;, score=0.262 total time=   0.3s\n",
      "[CV 5/5; 10/40] START max_depth=2, min_samples_split=2..........................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 10/40] END max_depth=2, min_samples_split=2;, score=-0.550 total time=   0.3s\n",
      "[CV 1/5; 11/40] START max_depth=2, min_samples_split=5..........................\n",
      "[CV 1/5; 11/40] END max_depth=2, min_samples_split=5;, score=0.439 total time=   0.2s\n",
      "[CV 2/5; 11/40] START max_depth=2, min_samples_split=5..........................\n",
      "[CV 2/5; 11/40] END max_depth=2, min_samples_split=5;, score=0.717 total time=   0.2s\n",
      "[CV 3/5; 11/40] START max_depth=2, min_samples_split=5..........................\n",
      "[CV 3/5; 11/40] END max_depth=2, min_samples_split=5;, score=0.265 total time=   0.2s\n",
      "[CV 4/5; 11/40] START max_depth=2, min_samples_split=5..........................\n",
      "[CV 4/5; 11/40] END max_depth=2, min_samples_split=5;, score=0.262 total time=   0.2s\n",
      "[CV 5/5; 11/40] START max_depth=2, min_samples_split=5..........................\n",
      "[CV 5/5; 11/40] END max_depth=2, min_samples_split=5;, score=-0.550 total time=   0.2s\n",
      "[CV 1/5; 12/40] START max_depth=2, min_samples_split=10.........................\n",
      "[CV 1/5; 12/40] END max_depth=2, min_samples_split=10;, score=0.439 total time=   0.2s\n",
      "[CV 2/5; 12/40] START max_depth=2, min_samples_split=10.........................\n",
      "[CV 2/5; 12/40] END max_depth=2, min_samples_split=10;, score=0.717 total time=   0.2s\n",
      "[CV 3/5; 12/40] START max_depth=2, min_samples_split=10.........................\n",
      "[CV 3/5; 12/40] END max_depth=2, min_samples_split=10;, score=0.265 total time=   0.2s\n",
      "[CV 4/5; 12/40] START max_depth=2, min_samples_split=10.........................\n",
      "[CV 4/5; 12/40] END max_depth=2, min_samples_split=10;, score=0.262 total time=   0.3s\n",
      "[CV 5/5; 12/40] START max_depth=2, min_samples_split=10.........................\n",
      "[CV 5/5; 12/40] END max_depth=2, min_samples_split=10;, score=-0.550 total time=   0.2s\n",
      "[CV 1/5; 13/40] START max_depth=2, min_samples_split=20.........................\n",
      "[CV 1/5; 13/40] END max_depth=2, min_samples_split=20;, score=0.439 total time=   0.2s\n",
      "[CV 2/5; 13/40] START max_depth=2, min_samples_split=20.........................\n",
      "[CV 2/5; 13/40] END max_depth=2, min_samples_split=20;, score=0.717 total time=   0.2s\n",
      "[CV 3/5; 13/40] START max_depth=2, min_samples_split=20.........................\n",
      "[CV 3/5; 13/40] END max_depth=2, min_samples_split=20;, score=0.265 total time=   0.2s\n",
      "[CV 4/5; 13/40] START max_depth=2, min_samples_split=20.........................\n",
      "[CV 4/5; 13/40] END max_depth=2, min_samples_split=20;, score=0.262 total time=   0.2s\n",
      "[CV 5/5; 13/40] START max_depth=2, min_samples_split=20.........................\n",
      "[CV 5/5; 13/40] END max_depth=2, min_samples_split=20;, score=-0.550 total time=   0.2s\n",
      "[CV 1/5; 14/40] START max_depth=2, min_samples_split=50.........................\n",
      "[CV 1/5; 14/40] END max_depth=2, min_samples_split=50;, score=0.439 total time=   0.2s\n",
      "[CV 2/5; 14/40] START max_depth=2, min_samples_split=50.........................\n",
      "[CV 2/5; 14/40] END max_depth=2, min_samples_split=50;, score=0.717 total time=   0.3s\n",
      "[CV 3/5; 14/40] START max_depth=2, min_samples_split=50.........................\n",
      "[CV 3/5; 14/40] END max_depth=2, min_samples_split=50;, score=0.265 total time=   0.2s\n",
      "[CV 4/5; 14/40] START max_depth=2, min_samples_split=50.........................\n",
      "[CV 4/5; 14/40] END max_depth=2, min_samples_split=50;, score=0.262 total time=   0.3s\n",
      "[CV 5/5; 14/40] START max_depth=2, min_samples_split=50.........................\n",
      "[CV 5/5; 14/40] END max_depth=2, min_samples_split=50;, score=-0.550 total time=   0.2s\n",
      "[CV 1/5; 15/40] START max_depth=2, min_samples_split=100........................\n",
      "[CV 1/5; 15/40] END max_depth=2, min_samples_split=100;, score=0.439 total time=   0.2s\n",
      "[CV 2/5; 15/40] START max_depth=2, min_samples_split=100........................\n",
      "[CV 2/5; 15/40] END max_depth=2, min_samples_split=100;, score=0.717 total time=   0.2s\n",
      "[CV 3/5; 15/40] START max_depth=2, min_samples_split=100........................\n",
      "[CV 3/5; 15/40] END max_depth=2, min_samples_split=100;, score=0.265 total time=   0.2s\n",
      "[CV 4/5; 15/40] START max_depth=2, min_samples_split=100........................\n",
      "[CV 4/5; 15/40] END max_depth=2, min_samples_split=100;, score=0.260 total time=   0.2s\n",
      "[CV 5/5; 15/40] START max_depth=2, min_samples_split=100........................\n",
      "[CV 5/5; 15/40] END max_depth=2, min_samples_split=100;, score=-0.550 total time=   0.2s\n",
      "[CV 1/5; 16/40] START max_depth=2, min_samples_split=250........................\n",
      "[CV 1/5; 16/40] END max_depth=2, min_samples_split=250;, score=-0.042 total time=   0.1s\n",
      "[CV 2/5; 16/40] START max_depth=2, min_samples_split=250........................\n",
      "[CV 2/5; 16/40] END max_depth=2, min_samples_split=250;, score=0.469 total time=   0.1s\n",
      "[CV 3/5; 16/40] START max_depth=2, min_samples_split=250........................\n",
      "[CV 3/5; 16/40] END max_depth=2, min_samples_split=250;, score=-0.001 total time=   0.2s\n",
      "[CV 4/5; 16/40] START max_depth=2, min_samples_split=250........................\n",
      "[CV 4/5; 16/40] END max_depth=2, min_samples_split=250;, score=0.260 total time=   0.2s\n",
      "[CV 5/5; 16/40] START max_depth=2, min_samples_split=250........................\n",
      "[CV 5/5; 16/40] END max_depth=2, min_samples_split=250;, score=-1.122 total time=   0.2s\n",
      "[CV 1/5; 17/40] START max_depth=5, min_samples_split=1..........................\n",
      "[CV 1/5; 17/40] END max_depth=5, min_samples_split=1;, score=0.663 total time=   0.7s\n",
      "[CV 2/5; 17/40] START max_depth=5, min_samples_split=1..........................\n",
      "[CV 2/5; 17/40] END max_depth=5, min_samples_split=1;, score=0.469 total time=   0.7s\n",
      "[CV 3/5; 17/40] START max_depth=5, min_samples_split=1..........................\n",
      "[CV 3/5; 17/40] END max_depth=5, min_samples_split=1;, score=0.668 total time=   0.7s\n",
      "[CV 4/5; 17/40] START max_depth=5, min_samples_split=1..........................\n",
      "[CV 4/5; 17/40] END max_depth=5, min_samples_split=1;, score=0.407 total time=   0.7s\n",
      "[CV 5/5; 17/40] START max_depth=5, min_samples_split=1..........................\n",
      "[CV 5/5; 17/40] END max_depth=5, min_samples_split=1;, score=-0.842 total time=   0.7s\n",
      "[CV 1/5; 18/40] START max_depth=5, min_samples_split=2..........................\n",
      "[CV 1/5; 18/40] END max_depth=5, min_samples_split=2;, score=0.663 total time=   0.7s\n",
      "[CV 2/5; 18/40] START max_depth=5, min_samples_split=2..........................\n",
      "[CV 2/5; 18/40] END max_depth=5, min_samples_split=2;, score=0.469 total time=   0.7s\n",
      "[CV 3/5; 18/40] START max_depth=5, min_samples_split=2..........................\n",
      "[CV 3/5; 18/40] END max_depth=5, min_samples_split=2;, score=0.668 total time=   0.7s\n",
      "[CV 4/5; 18/40] START max_depth=5, min_samples_split=2..........................\n",
      "[CV 4/5; 18/40] END max_depth=5, min_samples_split=2;, score=0.407 total time=   0.7s\n",
      "[CV 5/5; 18/40] START max_depth=5, min_samples_split=2..........................\n",
      "[CV 5/5; 18/40] END max_depth=5, min_samples_split=2;, score=-0.842 total time=   0.7s\n",
      "[CV 1/5; 19/40] START max_depth=5, min_samples_split=5..........................\n",
      "[CV 1/5; 19/40] END max_depth=5, min_samples_split=5;, score=0.661 total time=   0.7s\n",
      "[CV 2/5; 19/40] START max_depth=5, min_samples_split=5..........................\n",
      "[CV 2/5; 19/40] END max_depth=5, min_samples_split=5;, score=0.611 total time=   0.7s\n",
      "[CV 3/5; 19/40] START max_depth=5, min_samples_split=5..........................\n",
      "[CV 3/5; 19/40] END max_depth=5, min_samples_split=5;, score=0.686 total time=   0.7s\n",
      "[CV 4/5; 19/40] START max_depth=5, min_samples_split=5..........................\n",
      "[CV 4/5; 19/40] END max_depth=5, min_samples_split=5;, score=0.424 total time=   0.7s\n",
      "[CV 5/5; 19/40] START max_depth=5, min_samples_split=5..........................\n",
      "[CV 5/5; 19/40] END max_depth=5, min_samples_split=5;, score=-0.632 total time=   0.8s\n",
      "[CV 1/5; 20/40] START max_depth=5, min_samples_split=10.........................\n",
      "[CV 1/5; 20/40] END max_depth=5, min_samples_split=10;, score=0.662 total time=   0.7s\n",
      "[CV 2/5; 20/40] START max_depth=5, min_samples_split=10.........................\n",
      "[CV 2/5; 20/40] END max_depth=5, min_samples_split=10;, score=0.610 total time=   0.7s\n",
      "[CV 3/5; 20/40] START max_depth=5, min_samples_split=10.........................\n",
      "[CV 3/5; 20/40] END max_depth=5, min_samples_split=10;, score=0.685 total time=   0.7s\n",
      "[CV 4/5; 20/40] START max_depth=5, min_samples_split=10.........................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 20/40] END max_depth=5, min_samples_split=10;, score=0.436 total time=   0.7s\n",
      "[CV 5/5; 20/40] START max_depth=5, min_samples_split=10.........................\n",
      "[CV 5/5; 20/40] END max_depth=5, min_samples_split=10;, score=-0.620 total time=   0.8s\n",
      "[CV 1/5; 21/40] START max_depth=5, min_samples_split=20.........................\n",
      "[CV 1/5; 21/40] END max_depth=5, min_samples_split=20;, score=0.667 total time=   0.7s\n",
      "[CV 2/5; 21/40] START max_depth=5, min_samples_split=20.........................\n",
      "[CV 2/5; 21/40] END max_depth=5, min_samples_split=20;, score=0.610 total time=   0.7s\n",
      "[CV 3/5; 21/40] START max_depth=5, min_samples_split=20.........................\n",
      "[CV 3/5; 21/40] END max_depth=5, min_samples_split=20;, score=0.579 total time=   0.7s\n",
      "[CV 4/5; 21/40] START max_depth=5, min_samples_split=20.........................\n",
      "[CV 4/5; 21/40] END max_depth=5, min_samples_split=20;, score=0.444 total time=   0.7s\n",
      "[CV 5/5; 21/40] START max_depth=5, min_samples_split=20.........................\n",
      "[CV 5/5; 21/40] END max_depth=5, min_samples_split=20;, score=-0.620 total time=   0.7s\n",
      "[CV 1/5; 22/40] START max_depth=5, min_samples_split=50.........................\n",
      "[CV 1/5; 22/40] END max_depth=5, min_samples_split=50;, score=0.699 total time=   0.6s\n",
      "[CV 2/5; 22/40] START max_depth=5, min_samples_split=50.........................\n",
      "[CV 2/5; 22/40] END max_depth=5, min_samples_split=50;, score=0.730 total time=   0.6s\n",
      "[CV 3/5; 22/40] START max_depth=5, min_samples_split=50.........................\n",
      "[CV 3/5; 22/40] END max_depth=5, min_samples_split=50;, score=0.547 total time=   0.6s\n",
      "[CV 4/5; 22/40] START max_depth=5, min_samples_split=50.........................\n",
      "[CV 4/5; 22/40] END max_depth=5, min_samples_split=50;, score=0.393 total time=   0.6s\n",
      "[CV 5/5; 22/40] START max_depth=5, min_samples_split=50.........................\n",
      "[CV 5/5; 22/40] END max_depth=5, min_samples_split=50;, score=-0.745 total time=   0.6s\n",
      "[CV 1/5; 23/40] START max_depth=5, min_samples_split=100........................\n",
      "[CV 1/5; 23/40] END max_depth=5, min_samples_split=100;, score=0.668 total time=   0.5s\n",
      "[CV 2/5; 23/40] START max_depth=5, min_samples_split=100........................\n",
      "[CV 2/5; 23/40] END max_depth=5, min_samples_split=100;, score=0.718 total time=   0.5s\n",
      "[CV 3/5; 23/40] START max_depth=5, min_samples_split=100........................\n",
      "[CV 3/5; 23/40] END max_depth=5, min_samples_split=100;, score=0.562 total time=   0.5s\n",
      "[CV 4/5; 23/40] START max_depth=5, min_samples_split=100........................\n",
      "[CV 4/5; 23/40] END max_depth=5, min_samples_split=100;, score=0.363 total time=   0.4s\n",
      "[CV 5/5; 23/40] START max_depth=5, min_samples_split=100........................\n",
      "[CV 5/5; 23/40] END max_depth=5, min_samples_split=100;, score=-0.672 total time=   0.5s\n",
      "[CV 1/5; 24/40] START max_depth=5, min_samples_split=250........................\n",
      "[CV 1/5; 24/40] END max_depth=5, min_samples_split=250;, score=-0.042 total time=   0.1s\n",
      "[CV 2/5; 24/40] START max_depth=5, min_samples_split=250........................\n",
      "[CV 2/5; 24/40] END max_depth=5, min_samples_split=250;, score=0.469 total time=   0.1s\n",
      "[CV 3/5; 24/40] START max_depth=5, min_samples_split=250........................\n",
      "[CV 3/5; 24/40] END max_depth=5, min_samples_split=250;, score=-0.001 total time=   0.2s\n",
      "[CV 4/5; 24/40] START max_depth=5, min_samples_split=250........................\n",
      "[CV 4/5; 24/40] END max_depth=5, min_samples_split=250;, score=0.260 total time=   0.2s\n",
      "[CV 5/5; 24/40] START max_depth=5, min_samples_split=250........................\n",
      "[CV 5/5; 24/40] END max_depth=5, min_samples_split=250;, score=-1.122 total time=   0.2s\n",
      "[CV 1/5; 25/40] START max_depth=10, min_samples_split=1.........................\n",
      "[CV 1/5; 25/40] END max_depth=10, min_samples_split=1;, score=0.649 total time=   1.4s\n",
      "[CV 2/5; 25/40] START max_depth=10, min_samples_split=1.........................\n",
      "[CV 2/5; 25/40] END max_depth=10, min_samples_split=1;, score=0.411 total time=   1.4s\n",
      "[CV 3/5; 25/40] START max_depth=10, min_samples_split=1.........................\n",
      "[CV 3/5; 25/40] END max_depth=10, min_samples_split=1;, score=0.623 total time=   1.4s\n",
      "[CV 4/5; 25/40] START max_depth=10, min_samples_split=1.........................\n",
      "[CV 4/5; 25/40] END max_depth=10, min_samples_split=1;, score=0.394 total time=   1.4s\n",
      "[CV 5/5; 25/40] START max_depth=10, min_samples_split=1.........................\n",
      "[CV 5/5; 25/40] END max_depth=10, min_samples_split=1;, score=-0.844 total time=   1.4s\n",
      "[CV 1/5; 26/40] START max_depth=10, min_samples_split=2.........................\n",
      "[CV 1/5; 26/40] END max_depth=10, min_samples_split=2;, score=0.649 total time=   1.3s\n",
      "[CV 2/5; 26/40] START max_depth=10, min_samples_split=2.........................\n",
      "[CV 2/5; 26/40] END max_depth=10, min_samples_split=2;, score=0.411 total time=   1.3s\n",
      "[CV 3/5; 26/40] START max_depth=10, min_samples_split=2.........................\n",
      "[CV 3/5; 26/40] END max_depth=10, min_samples_split=2;, score=0.623 total time=   1.4s\n",
      "[CV 4/5; 26/40] START max_depth=10, min_samples_split=2.........................\n",
      "[CV 4/5; 26/40] END max_depth=10, min_samples_split=2;, score=0.394 total time=   1.4s\n",
      "[CV 5/5; 26/40] START max_depth=10, min_samples_split=2.........................\n",
      "[CV 5/5; 26/40] END max_depth=10, min_samples_split=2;, score=-0.844 total time=   1.4s\n",
      "[CV 1/5; 27/40] START max_depth=10, min_samples_split=5.........................\n",
      "[CV 1/5; 27/40] END max_depth=10, min_samples_split=5;, score=0.634 total time=   1.5s\n",
      "[CV 2/5; 27/40] START max_depth=10, min_samples_split=5.........................\n",
      "[CV 2/5; 27/40] END max_depth=10, min_samples_split=5;, score=0.553 total time=   1.5s\n",
      "[CV 3/5; 27/40] START max_depth=10, min_samples_split=5.........................\n",
      "[CV 3/5; 27/40] END max_depth=10, min_samples_split=5;, score=0.635 total time=   1.5s\n",
      "[CV 4/5; 27/40] START max_depth=10, min_samples_split=5.........................\n",
      "[CV 4/5; 27/40] END max_depth=10, min_samples_split=5;, score=0.430 total time=   1.3s\n",
      "[CV 5/5; 27/40] START max_depth=10, min_samples_split=5.........................\n",
      "[CV 5/5; 27/40] END max_depth=10, min_samples_split=5;, score=-0.624 total time=   1.4s\n",
      "[CV 1/5; 28/40] START max_depth=10, min_samples_split=10........................\n",
      "[CV 1/5; 28/40] END max_depth=10, min_samples_split=10;, score=0.647 total time=   1.2s\n",
      "[CV 2/5; 28/40] START max_depth=10, min_samples_split=10........................\n",
      "[CV 2/5; 28/40] END max_depth=10, min_samples_split=10;, score=0.562 total time=   1.2s\n",
      "[CV 3/5; 28/40] START max_depth=10, min_samples_split=10........................\n",
      "[CV 3/5; 28/40] END max_depth=10, min_samples_split=10;, score=0.676 total time=   1.2s\n",
      "[CV 4/5; 28/40] START max_depth=10, min_samples_split=10........................\n",
      "[CV 4/5; 28/40] END max_depth=10, min_samples_split=10;, score=0.430 total time=   1.2s\n",
      "[CV 5/5; 28/40] START max_depth=10, min_samples_split=10........................\n",
      "[CV 5/5; 28/40] END max_depth=10, min_samples_split=10;, score=-0.659 total time=   1.2s\n",
      "[CV 1/5; 29/40] START max_depth=10, min_samples_split=20........................\n",
      "[CV 1/5; 29/40] END max_depth=10, min_samples_split=20;, score=0.640 total time=   1.0s\n",
      "[CV 2/5; 29/40] START max_depth=10, min_samples_split=20........................\n",
      "[CV 2/5; 29/40] END max_depth=10, min_samples_split=20;, score=0.593 total time=   1.0s\n",
      "[CV 3/5; 29/40] START max_depth=10, min_samples_split=20........................\n",
      "[CV 3/5; 29/40] END max_depth=10, min_samples_split=20;, score=0.593 total time=   1.0s\n",
      "[CV 4/5; 29/40] START max_depth=10, min_samples_split=20........................\n",
      "[CV 4/5; 29/40] END max_depth=10, min_samples_split=20;, score=0.434 total time=   1.0s\n",
      "[CV 5/5; 29/40] START max_depth=10, min_samples_split=20........................\n",
      "[CV 5/5; 29/40] END max_depth=10, min_samples_split=20;, score=-0.612 total time=   1.0s\n",
      "[CV 1/5; 30/40] START max_depth=10, min_samples_split=50........................\n",
      "[CV 1/5; 30/40] END max_depth=10, min_samples_split=50;, score=0.718 total time=   0.7s\n",
      "[CV 2/5; 30/40] START max_depth=10, min_samples_split=50........................\n",
      "[CV 2/5; 30/40] END max_depth=10, min_samples_split=50;, score=0.720 total time=   0.7s\n",
      "[CV 3/5; 30/40] START max_depth=10, min_samples_split=50........................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 30/40] END max_depth=10, min_samples_split=50;, score=0.544 total time=   0.8s\n",
      "[CV 4/5; 30/40] START max_depth=10, min_samples_split=50........................\n",
      "[CV 4/5; 30/40] END max_depth=10, min_samples_split=50;, score=0.376 total time=   0.7s\n",
      "[CV 5/5; 30/40] START max_depth=10, min_samples_split=50........................\n",
      "[CV 5/5; 30/40] END max_depth=10, min_samples_split=50;, score=-0.742 total time=   0.7s\n",
      "[CV 1/5; 31/40] START max_depth=10, min_samples_split=100.......................\n",
      "[CV 1/5; 31/40] END max_depth=10, min_samples_split=100;, score=0.668 total time=   0.5s\n",
      "[CV 2/5; 31/40] START max_depth=10, min_samples_split=100.......................\n",
      "[CV 2/5; 31/40] END max_depth=10, min_samples_split=100;, score=0.718 total time=   0.4s\n",
      "[CV 3/5; 31/40] START max_depth=10, min_samples_split=100.......................\n",
      "[CV 3/5; 31/40] END max_depth=10, min_samples_split=100;, score=0.563 total time=   0.6s\n",
      "[CV 4/5; 31/40] START max_depth=10, min_samples_split=100.......................\n",
      "[CV 4/5; 31/40] END max_depth=10, min_samples_split=100;, score=0.363 total time=   0.4s\n",
      "[CV 5/5; 31/40] START max_depth=10, min_samples_split=100.......................\n",
      "[CV 5/5; 31/40] END max_depth=10, min_samples_split=100;, score=-0.668 total time=   0.5s\n",
      "[CV 1/5; 32/40] START max_depth=10, min_samples_split=250.......................\n",
      "[CV 1/5; 32/40] END max_depth=10, min_samples_split=250;, score=-0.042 total time=   0.1s\n",
      "[CV 2/5; 32/40] START max_depth=10, min_samples_split=250.......................\n",
      "[CV 2/5; 32/40] END max_depth=10, min_samples_split=250;, score=0.469 total time=   0.1s\n",
      "[CV 3/5; 32/40] START max_depth=10, min_samples_split=250.......................\n",
      "[CV 3/5; 32/40] END max_depth=10, min_samples_split=250;, score=-0.001 total time=   0.2s\n",
      "[CV 4/5; 32/40] START max_depth=10, min_samples_split=250.......................\n",
      "[CV 4/5; 32/40] END max_depth=10, min_samples_split=250;, score=0.260 total time=   0.2s\n",
      "[CV 5/5; 32/40] START max_depth=10, min_samples_split=250.......................\n",
      "[CV 5/5; 32/40] END max_depth=10, min_samples_split=250;, score=-1.122 total time=   0.2s\n",
      "[CV 1/5; 33/40] START max_depth=20, min_samples_split=1.........................\n",
      "[CV 1/5; 33/40] END max_depth=20, min_samples_split=1;, score=0.640 total time=   1.7s\n",
      "[CV 2/5; 33/40] START max_depth=20, min_samples_split=1.........................\n",
      "[CV 2/5; 33/40] END max_depth=20, min_samples_split=1;, score=0.408 total time=   1.6s\n",
      "[CV 3/5; 33/40] START max_depth=20, min_samples_split=1.........................\n",
      "[CV 3/5; 33/40] END max_depth=20, min_samples_split=1;, score=0.619 total time=   1.7s\n",
      "[CV 4/5; 33/40] START max_depth=20, min_samples_split=1.........................\n",
      "[CV 4/5; 33/40] END max_depth=20, min_samples_split=1;, score=0.370 total time=   1.7s\n",
      "[CV 5/5; 33/40] START max_depth=20, min_samples_split=1.........................\n",
      "[CV 5/5; 33/40] END max_depth=20, min_samples_split=1;, score=-0.860 total time=   1.7s\n",
      "[CV 1/5; 34/40] START max_depth=20, min_samples_split=2.........................\n",
      "[CV 1/5; 34/40] END max_depth=20, min_samples_split=2;, score=0.640 total time=   1.6s\n",
      "[CV 2/5; 34/40] START max_depth=20, min_samples_split=2.........................\n",
      "[CV 2/5; 34/40] END max_depth=20, min_samples_split=2;, score=0.408 total time=   1.6s\n",
      "[CV 3/5; 34/40] START max_depth=20, min_samples_split=2.........................\n",
      "[CV 3/5; 34/40] END max_depth=20, min_samples_split=2;, score=0.619 total time=   1.7s\n",
      "[CV 4/5; 34/40] START max_depth=20, min_samples_split=2.........................\n",
      "[CV 4/5; 34/40] END max_depth=20, min_samples_split=2;, score=0.370 total time=   1.6s\n",
      "[CV 5/5; 34/40] START max_depth=20, min_samples_split=2.........................\n",
      "[CV 5/5; 34/40] END max_depth=20, min_samples_split=2;, score=-0.860 total time=   1.6s\n",
      "[CV 1/5; 35/40] START max_depth=20, min_samples_split=5.........................\n",
      "[CV 1/5; 35/40] END max_depth=20, min_samples_split=5;, score=0.626 total time=   1.4s\n",
      "[CV 2/5; 35/40] START max_depth=20, min_samples_split=5.........................\n",
      "[CV 2/5; 35/40] END max_depth=20, min_samples_split=5;, score=0.548 total time=   1.4s\n",
      "[CV 3/5; 35/40] START max_depth=20, min_samples_split=5.........................\n",
      "[CV 3/5; 35/40] END max_depth=20, min_samples_split=5;, score=0.630 total time=   1.6s\n",
      "[CV 4/5; 35/40] START max_depth=20, min_samples_split=5.........................\n",
      "[CV 4/5; 35/40] END max_depth=20, min_samples_split=5;, score=0.414 total time=   1.4s\n",
      "[CV 5/5; 35/40] START max_depth=20, min_samples_split=5.........................\n",
      "[CV 5/5; 35/40] END max_depth=20, min_samples_split=5;, score=-0.643 total time=   1.4s\n",
      "[CV 1/5; 36/40] START max_depth=20, min_samples_split=10........................\n",
      "[CV 1/5; 36/40] END max_depth=20, min_samples_split=10;, score=0.639 total time=   1.3s\n",
      "[CV 2/5; 36/40] START max_depth=20, min_samples_split=10........................\n",
      "[CV 2/5; 36/40] END max_depth=20, min_samples_split=10;, score=0.557 total time=   1.2s\n",
      "[CV 3/5; 36/40] START max_depth=20, min_samples_split=10........................\n",
      "[CV 3/5; 36/40] END max_depth=20, min_samples_split=10;, score=0.678 total time=   1.4s\n",
      "[CV 4/5; 36/40] START max_depth=20, min_samples_split=10........................\n",
      "[CV 4/5; 36/40] END max_depth=20, min_samples_split=10;, score=0.431 total time=   1.2s\n",
      "[CV 5/5; 36/40] START max_depth=20, min_samples_split=10........................\n",
      "[CV 5/5; 36/40] END max_depth=20, min_samples_split=10;, score=-0.673 total time=   1.2s\n",
      "[CV 1/5; 37/40] START max_depth=20, min_samples_split=20........................\n",
      "[CV 1/5; 37/40] END max_depth=20, min_samples_split=20;, score=0.631 total time=   1.1s\n",
      "[CV 2/5; 37/40] START max_depth=20, min_samples_split=20........................\n",
      "[CV 2/5; 37/40] END max_depth=20, min_samples_split=20;, score=0.593 total time=   1.0s\n",
      "[CV 3/5; 37/40] START max_depth=20, min_samples_split=20........................\n",
      "[CV 3/5; 37/40] END max_depth=20, min_samples_split=20;, score=0.591 total time=   1.1s\n",
      "[CV 4/5; 37/40] START max_depth=20, min_samples_split=20........................\n",
      "[CV 4/5; 37/40] END max_depth=20, min_samples_split=20;, score=0.435 total time=   1.0s\n",
      "[CV 5/5; 37/40] START max_depth=20, min_samples_split=20........................\n",
      "[CV 5/5; 37/40] END max_depth=20, min_samples_split=20;, score=-0.611 total time=   1.1s\n",
      "[CV 1/5; 38/40] START max_depth=20, min_samples_split=50........................\n",
      "[CV 1/5; 38/40] END max_depth=20, min_samples_split=50;, score=0.718 total time=   0.8s\n",
      "[CV 2/5; 38/40] START max_depth=20, min_samples_split=50........................\n",
      "[CV 2/5; 38/40] END max_depth=20, min_samples_split=50;, score=0.720 total time=   0.7s\n",
      "[CV 3/5; 38/40] START max_depth=20, min_samples_split=50........................\n",
      "[CV 3/5; 38/40] END max_depth=20, min_samples_split=50;, score=0.543 total time=   0.9s\n",
      "[CV 4/5; 38/40] START max_depth=20, min_samples_split=50........................\n",
      "[CV 4/5; 38/40] END max_depth=20, min_samples_split=50;, score=0.376 total time=   0.7s\n",
      "[CV 5/5; 38/40] START max_depth=20, min_samples_split=50........................\n",
      "[CV 5/5; 38/40] END max_depth=20, min_samples_split=50;, score=-0.742 total time=   0.7s\n",
      "[CV 1/5; 39/40] START max_depth=20, min_samples_split=100.......................\n",
      "[CV 1/5; 39/40] END max_depth=20, min_samples_split=100;, score=0.668 total time=   0.5s\n",
      "[CV 2/5; 39/40] START max_depth=20, min_samples_split=100.......................\n",
      "[CV 2/5; 39/40] END max_depth=20, min_samples_split=100;, score=0.718 total time=   0.5s\n",
      "[CV 3/5; 39/40] START max_depth=20, min_samples_split=100.......................\n",
      "[CV 3/5; 39/40] END max_depth=20, min_samples_split=100;, score=0.563 total time=   0.6s\n",
      "[CV 4/5; 39/40] START max_depth=20, min_samples_split=100.......................\n",
      "[CV 4/5; 39/40] END max_depth=20, min_samples_split=100;, score=0.363 total time=   0.4s\n",
      "[CV 5/5; 39/40] START max_depth=20, min_samples_split=100.......................\n",
      "[CV 5/5; 39/40] END max_depth=20, min_samples_split=100;, score=-0.668 total time=   0.6s\n",
      "[CV 1/5; 40/40] START max_depth=20, min_samples_split=250.......................\n",
      "[CV 1/5; 40/40] END max_depth=20, min_samples_split=250;, score=-0.042 total time=   0.1s\n",
      "[CV 2/5; 40/40] START max_depth=20, min_samples_split=250.......................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 40/40] END max_depth=20, min_samples_split=250;, score=0.469 total time=   0.1s\n",
      "[CV 3/5; 40/40] START max_depth=20, min_samples_split=250.......................\n",
      "[CV 3/5; 40/40] END max_depth=20, min_samples_split=250;, score=-0.001 total time=   0.2s\n",
      "[CV 4/5; 40/40] START max_depth=20, min_samples_split=250.......................\n",
      "[CV 4/5; 40/40] END max_depth=20, min_samples_split=250;, score=0.260 total time=   0.2s\n",
      "[CV 5/5; 40/40] START max_depth=20, min_samples_split=250.......................\n",
      "[CV 5/5; 40/40] END max_depth=20, min_samples_split=250;, score=-1.122 total time=   0.2s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "s = GridSearchCV(model, param_grid=dict(max_depth=[1,2,5,10,20], min_samples_split=[1,2,5,10,20,50,100,250]), verbose=10)\n",
    "s.fit(X,y)\n",
    "best_model = s.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 5, 'min_samples_split': 10}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.194368464056595"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "best_model.fit(X_train, y_train)\n",
    "y_pred = best_model.predict(X_test)\n",
    "mean_squared_error(y_test, y_pred, squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6 <a id=\"task6\"></a>  (2 points)\n",
    "\n",
    "Recall definition of bias and variance:\n",
    "$$\n",
    "\\text{Bias}^2 = \\mathbb{E}_{p(x, y)} \\left[  (f(x) - \\mathbb{E}_{\\mathbb{X}}a_{\\mathbb{X}}(x))^2 \\right] \\\\\n",
    "\\text{Variance} = \\mathbb{E}_{p(x, y)} \\left[  \\mathbb{V}_{\\mathbb{X}}( a_{\\mathbb{X}}(x))  \\right]\n",
    "$$\n",
    "\n",
    "We wil now use use the following algorithm to estimate bias^2 and variance:\n",
    "\n",
    "1. Use bootsrap to create `n_iter` samples from the original dataset: $X_1, \\dots, X_{n\\_iter}$. Each $X_i$ has $N$ observations (randomly selected from the original dataset with replacement)\n",
    "2. For each bootstrapped sample define out-of-bag (OOB) sample $Z_1, \\dots, Z_{n\\_iter}$, which contains all the observations, which did not appear in the corresponding boostraped sample\n",
    "3. Fit the model on observations from $X_i$s and compute predictions on points from $Z_i$s\n",
    "4. For a given *object* $x_n$:\n",
    "     - bias^2: squared difference between true value $y_n$ and average prediction (average over the algorithms, for which $x_n$ was in OOB)\n",
    "     - variance: variance of the predictions (predictions of the algorithms, for which $x_n$ was in OOB)\n",
    "5. Average bias^2 and variance over all the points\n",
    "\n",
    "\n",
    "**Consider a toy example.** You are given a dataset with 5 observations: $((x_1 ,y_1), (x_2, y_2), (x_3, y_3), (x_4, y_4), (x_5, y_5))$, where $x_i$ is a vector of features, $y_i$ is a target variable . And choose `n_iter` to be 3. \n",
    "* Example of bootstrapped samples:\n",
    "$$X_1 = (x_2, x_5, x_2, x_3, x_2, x_5)$$\n",
    "$$X_2 = (x_5, x_2, x_4, x_4, x_1, x_5)$$\n",
    "$$X_3 = (x_1, x_3, x_1, x_4, x_3, x_1)$$\n",
    "\n",
    "* Corresponding OOB samples:\n",
    "$$Z_1 = (x_1, x_4)$$\n",
    "$$Z_2 = (x_3)$$\n",
    "$$Z_3 = (x_2, x_5)$$\n",
    "\n",
    "* Fit models using $X_1$, $X_2$ and $X_3$ as training data. Use 1st model to make predictions for points from $Z_1$, second - for $Z_2$, etc. and use these predictions to estimate bias and variance. \n",
    "\n",
    "    \n",
    "**Implement `get_bias_variance` function, using the algorithm above**\n",
    "\n",
    "*Note:*  You can only use 1 loop (for bootsrap iterations `n_iter`). All other operations should be vectorized. \n",
    "\n",
    "P.S. These numpy functions might be usefull here `np.nanmean`, `np.nanstd` (but you are not obliged to use them). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def get_bias_variance(estimator, x, y, n_iter):\n",
    "    \"\"\" \n",
    "    Calculate bias^2 and variance of the `estimator`. Using a given dataset and bootstrap with `n_iter` samples. \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : ndarray, shape (n_samples, n_features)\n",
    "        The input samples.\n",
    "    y : ndarray, shape (n_samples, n_features)\n",
    "        The input samples.\n",
    "    n_iter: int\n",
    "        Number of samples in \n",
    "    Returns\n",
    "    -------\n",
    "    bias2 : float, \n",
    "        Estiamted squared bias\n",
    "    variance : float, \n",
    "        Estiamted variance\n",
    "    \"\"\"\n",
    "    \n",
    "    all_pred = np.full((n_iter, y.shape[0]), np.nan)\n",
    "    index = np.arange(y.shape[0])\n",
    "    \n",
    "    for i in range(n_iter):\n",
    "        x_index = np.random.choice(index, size=len(index), replace=True)\n",
    "        # z_index = set(index) - set(x_index)\n",
    "        z_index = np.setdiff1d(index, x_index)\n",
    "        estimator.fit(x[x_index], y[x_index])\n",
    "        all_pred[i][z_index] = estimator.predict(x[z_index])\n",
    "        \n",
    "    avg_pred = np.nanmean(all_pred, axis=0)\n",
    "    bias2 = np.nanmean((avg_pred - y)**2)\n",
    "    variance = np.nanmean((avg_pred - all_pred)**2)\n",
    "    return bias2, variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17.284772268339367, 9.783479691158625)"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test\n",
    "estimator = MyDecisionTreeRegressor(max_depth=8, min_samples_split=15)\n",
    "\n",
    "get_bias_variance(estimator, X_train, y_train, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7 <a id=\"task7\"></a>  (0.5 points = 0.25 for code + 0.25 for comments)\n",
    "\n",
    "Compute bias and variance for the trees of different depths. Plot how bias and variance change as depth increases. \n",
    "\n",
    "Comment on what you observe, how does your result correspond to what we have discussed in class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "depths=np.arange(1,16)\n",
    "bias, var = [], []\n",
    "\n",
    "for depth in depths:\n",
    "    estimator = MyDecisionTreeRegressor(max_depth=depth, min_samples_split=5)\n",
    "    bias_, var_ = get_bias_variance(estimator, X, y, 100)\n",
    "    bias.append(bias_)\n",
    "    var.append(var_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x17f61f19b80>"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(depths, bias, label='Bias')\n",
    "plt.plot(depths, var, label='Variance')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the more nodes the model has, the higher the variance and the lower the bias. This corresponds to what was said on lectures and seminars, adding more complexity increases the variance and decreases the bias. So with higher values of max_depth the model is better at predicting features from the training set, but it's more complex, which means that a small change in the input can change the prediction a lot (variance is high)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 8 <a id=\"task8\"></a>  (0.5 points = 0.25 for code + 0.25 for comments)\n",
    "\n",
    "Let's try to reduce variance with bagging. Use `sklearn.ensemble.BaggingRegressor` to get an ensemble and compute its bias and variance. \n",
    "\n",
    "Answer the following questions:\n",
    " - How bagging should affect bias and variance in theory?\n",
    " - How bias and variance change (if they change) compared to an individual tree in you experiments? \n",
    " - Do your results align with the theory? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "model = MyDecisionTreeRegressor(max_depth=5)\n",
    "bagging = BaggingRegressor(MyDecisionTreeRegressor(max_depth=5))\n",
    "\n",
    "bagging_metrics = get_bias_variance(bagging, X, y, 10)\n",
    "model_metrics = get_bias_variance(model, X, y, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x135dadceeb0>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(2)  \n",
    "_, ax = plt.subplots()\n",
    "ax.bar(x - 0.2, bagging_metrics, 0.4, \n",
    "       label=f'Bagging (b: {bagging_metrics[0]:.2f} v: {bagging_metrics[1]:.2f})')\n",
    "ax.bar(x + 0.2, model_metrics, 0.4, \n",
    "       label=f'Decision Tree (b: {model_metrics[0]:.2f} v: {model_metrics[1]:.2f}')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(['Bias', 'Variance'])\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Bagging should not affect bias but should reduce the variance given that the selected models are not highly correlated.\n",
    "\n",
    "2. Variance is much lower for bagging, but bias is a little higher for the bare model.\n",
    "\n",
    "3. Yes, the results do align with the theory (Although the bias has also dropped slightly for some reason), it seems like the models that were chosen by BaggingRegressor are not very correlated, so the variance is about 3 times less for the bagging model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2. More Ensembles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part we will be working with [Thyroid Disease Data Set](https://archive.ics.uci.edu/ml/datasets/thyroid+disease) to solve a classification task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>on_thyroxine</th>\n",
       "      <th>query_on_thyroxine</th>\n",
       "      <th>on_antithyroid_medication</th>\n",
       "      <th>sick</th>\n",
       "      <th>pregnant</th>\n",
       "      <th>thyroid_surgery</th>\n",
       "      <th>I131_treatment</th>\n",
       "      <th>query_hypothyroid</th>\n",
       "      <th>...</th>\n",
       "      <th>T3</th>\n",
       "      <th>TT4_measured</th>\n",
       "      <th>TT4</th>\n",
       "      <th>T4U_measured</th>\n",
       "      <th>T4U</th>\n",
       "      <th>FTI_measured</th>\n",
       "      <th>FTI</th>\n",
       "      <th>TBG_measured</th>\n",
       "      <th>TBG</th>\n",
       "      <th>referral_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.0</td>\n",
       "      <td>F</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>t</td>\n",
       "      <td>125.0</td>\n",
       "      <td>t</td>\n",
       "      <td>1.14</td>\n",
       "      <td>t</td>\n",
       "      <td>109.0</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SVHC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.0</td>\n",
       "      <td>F</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>t</td>\n",
       "      <td>102.0</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46.0</td>\n",
       "      <td>M</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t</td>\n",
       "      <td>109.0</td>\n",
       "      <td>t</td>\n",
       "      <td>0.91</td>\n",
       "      <td>t</td>\n",
       "      <td>120.0</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70.0</td>\n",
       "      <td>F</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>...</td>\n",
       "      <td>1.9</td>\n",
       "      <td>t</td>\n",
       "      <td>175.0</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70.0</td>\n",
       "      <td>F</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>...</td>\n",
       "      <td>1.2</td>\n",
       "      <td>t</td>\n",
       "      <td>61.0</td>\n",
       "      <td>t</td>\n",
       "      <td>0.87</td>\n",
       "      <td>t</td>\n",
       "      <td>70.0</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SVI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    age sex on_thyroxine query_on_thyroxine on_antithyroid_medication sick  \\\n",
       "0  41.0   F            f                  f                         f    f   \n",
       "1  23.0   F            f                  f                         f    f   \n",
       "2  46.0   M            f                  f                         f    f   \n",
       "3  70.0   F            t                  f                         f    f   \n",
       "4  70.0   F            f                  f                         f    f   \n",
       "\n",
       "  pregnant thyroid_surgery I131_treatment query_hypothyroid  ...   T3  \\\n",
       "0        f               f              f                 f  ...  2.5   \n",
       "1        f               f              f                 f  ...  2.0   \n",
       "2        f               f              f                 f  ...  NaN   \n",
       "3        f               f              f                 f  ...  1.9   \n",
       "4        f               f              f                 f  ...  1.2   \n",
       "\n",
       "  TT4_measured    TT4 T4U_measured   T4U FTI_measured    FTI  TBG_measured  \\\n",
       "0            t  125.0            t  1.14            t  109.0             f   \n",
       "1            t  102.0            f   NaN            f    NaN             f   \n",
       "2            t  109.0            t  0.91            t  120.0             f   \n",
       "3            t  175.0            f   NaN            f    NaN             f   \n",
       "4            t   61.0            t  0.87            t   70.0             f   \n",
       "\n",
       "  TBG  referral_source  \n",
       "0 NaN             SVHC  \n",
       "1 NaN            other  \n",
       "2 NaN            other  \n",
       "3 NaN            other  \n",
       "4 NaN              SVI  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df = pd.read_csv('thyroid_disease.csv')\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df['Class'])\n",
    "X = df.drop('Class', axis=1)\n",
    "X.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 <a id=\"task2_1\"></a> (1 point)\n",
    "\n",
    "Let's start with data preprocessing. \n",
    "\n",
    "0. Drop columns, which are not usefull (e.g. a lot of missing values). Motivate your choice. \n",
    "1. Split dataset into train and test\n",
    "2. You've probably noticed that we have both categorical and numerical columns. Here is what you need to do with them:\n",
    "    - Categorical: Fill missing values and apply one-hot-encoding (take a look at the argument `drop` in [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) to figure out the best way to apply OHE to binary variables)\n",
    "    - Numeric: Fill missing values\n",
    "    \n",
    "Use `ColumnTranformer` ([docs](https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html#sklearn.compose.ColumnTransformer)) to define a single transformer for all the columns in the dataset. It takes as input a list of tuples\n",
    "\n",
    "```\n",
    "ColumnTransformer([\n",
    "    ('name1', transorm1, column_names1),\n",
    "    ('name2', transorm2, column_names2)\n",
    "])\n",
    "```\n",
    "\n",
    "Pay attention to an argument `remainder='passthrough'`. [Here](https://scikit-learn.org/stable/modules/compose.html#column-transformer) you can find some examples of how to use column transformer. \n",
    "    \n",
    "Since we want to apply 2 transformations to categorical feature, it is very convenient to combine them into a `Pipeline`:\n",
    "\n",
    "```\n",
    "double_transform = make_pipeline(\n",
    "                                 transform_1,\n",
    "                                 transform_2\n",
    "                                )\n",
    "```\n",
    "\n",
    "P.S. Choose your favourite way to fill missing values. \n",
    "\n",
    "*Hint* Categorical column usually have `dtype = 'object'`. This may help to obtain list of categorical and numerical columns in the dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. The column 'TBG' is literally empty, so I think it's pretty safe to drop it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3772 entries, 0 to 3771\n",
      "Data columns (total 29 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   age                        3771 non-null   float64\n",
      " 1   sex                        3622 non-null   object \n",
      " 2   on_thyroxine               3772 non-null   object \n",
      " 3   query_on_thyroxine         3772 non-null   object \n",
      " 4   on_antithyroid_medication  3772 non-null   object \n",
      " 5   sick                       3772 non-null   object \n",
      " 6   pregnant                   3772 non-null   object \n",
      " 7   thyroid_surgery            3772 non-null   object \n",
      " 8   I131_treatment             3772 non-null   object \n",
      " 9   query_hypothyroid          3772 non-null   object \n",
      " 10  query_hyperthyroid         3772 non-null   object \n",
      " 11  lithium                    3772 non-null   object \n",
      " 12  goitre                     3772 non-null   object \n",
      " 13  tumor                      3772 non-null   object \n",
      " 14  hypopituitary              3772 non-null   object \n",
      " 15  psych                      3772 non-null   object \n",
      " 16  TSH_measured               3772 non-null   object \n",
      " 17  TSH                        3403 non-null   float64\n",
      " 18  T3_measured                3772 non-null   object \n",
      " 19  T3                         3003 non-null   float64\n",
      " 20  TT4_measured               3772 non-null   object \n",
      " 21  TT4                        3541 non-null   float64\n",
      " 22  T4U_measured               3772 non-null   object \n",
      " 23  T4U                        3385 non-null   float64\n",
      " 24  FTI_measured               3772 non-null   object \n",
      " 25  FTI                        3387 non-null   float64\n",
      " 26  TBG_measured               3772 non-null   object \n",
      " 27  TBG                        0 non-null      float64\n",
      " 28  referral_source            3772 non-null   object \n",
      "dtypes: float64(7), object(22)\n",
      "memory usage: 854.7+ KB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also drop TBG_measured and hypopituitary as they have 0 and 1 true values, and the rest are false "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F    2480\n",
      "M    1142\n",
      "Name: sex, dtype: int64\n",
      "\n",
      "f    3308\n",
      "t     464\n",
      "Name: on_thyroxine, dtype: int64\n",
      "\n",
      "f    3722\n",
      "t      50\n",
      "Name: query_on_thyroxine, dtype: int64\n",
      "\n",
      "f    3729\n",
      "t      43\n",
      "Name: on_antithyroid_medication, dtype: int64\n",
      "\n",
      "f    3625\n",
      "t     147\n",
      "Name: sick, dtype: int64\n",
      "\n",
      "f    3719\n",
      "t      53\n",
      "Name: pregnant, dtype: int64\n",
      "\n",
      "f    3719\n",
      "t      53\n",
      "Name: thyroid_surgery, dtype: int64\n",
      "\n",
      "f    3713\n",
      "t      59\n",
      "Name: I131_treatment, dtype: int64\n",
      "\n",
      "f    3538\n",
      "t     234\n",
      "Name: query_hypothyroid, dtype: int64\n",
      "\n",
      "f    3535\n",
      "t     237\n",
      "Name: query_hyperthyroid, dtype: int64\n",
      "\n",
      "f    3754\n",
      "t      18\n",
      "Name: lithium, dtype: int64\n",
      "\n",
      "f    3738\n",
      "t      34\n",
      "Name: goitre, dtype: int64\n",
      "\n",
      "f    3676\n",
      "t      96\n",
      "Name: tumor, dtype: int64\n",
      "\n",
      "f    3771\n",
      "t       1\n",
      "Name: hypopituitary, dtype: int64\n",
      "\n",
      "f    3588\n",
      "t     184\n",
      "Name: psych, dtype: int64\n",
      "\n",
      "t    3403\n",
      "f     369\n",
      "Name: TSH_measured, dtype: int64\n",
      "\n",
      "t    3003\n",
      "f     769\n",
      "Name: T3_measured, dtype: int64\n",
      "\n",
      "t    3541\n",
      "f     231\n",
      "Name: TT4_measured, dtype: int64\n",
      "\n",
      "t    3385\n",
      "f     387\n",
      "Name: T4U_measured, dtype: int64\n",
      "\n",
      "t    3387\n",
      "f     385\n",
      "Name: FTI_measured, dtype: int64\n",
      "\n",
      "f    3772\n",
      "Name: TBG_measured, dtype: int64\n",
      "\n",
      "other    2201\n",
      "SVI      1034\n",
      "SVHC      386\n",
      "STMW      112\n",
      "SVHD       39\n",
      "Name: referral_source, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Categorical value counts\n",
    "for col in X[X.columns[X.dtypes.eq('object')]].columns:\n",
    "    print(X[col].value_counts(), end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>on_thyroxine</th>\n",
       "      <th>query_on_thyroxine</th>\n",
       "      <th>on_antithyroid_medication</th>\n",
       "      <th>sick</th>\n",
       "      <th>pregnant</th>\n",
       "      <th>thyroid_surgery</th>\n",
       "      <th>I131_treatment</th>\n",
       "      <th>query_hypothyroid</th>\n",
       "      <th>...</th>\n",
       "      <th>TSH</th>\n",
       "      <th>T3_measured</th>\n",
       "      <th>T3</th>\n",
       "      <th>TT4_measured</th>\n",
       "      <th>TT4</th>\n",
       "      <th>T4U_measured</th>\n",
       "      <th>T4U</th>\n",
       "      <th>FTI_measured</th>\n",
       "      <th>FTI</th>\n",
       "      <th>referral_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.0</td>\n",
       "      <td>F</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>...</td>\n",
       "      <td>1.30</td>\n",
       "      <td>t</td>\n",
       "      <td>2.5</td>\n",
       "      <td>t</td>\n",
       "      <td>125.0</td>\n",
       "      <td>t</td>\n",
       "      <td>1.14</td>\n",
       "      <td>t</td>\n",
       "      <td>109.0</td>\n",
       "      <td>SVHC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.0</td>\n",
       "      <td>F</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>...</td>\n",
       "      <td>4.10</td>\n",
       "      <td>t</td>\n",
       "      <td>2.0</td>\n",
       "      <td>t</td>\n",
       "      <td>102.0</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46.0</td>\n",
       "      <td>M</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>...</td>\n",
       "      <td>0.98</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t</td>\n",
       "      <td>109.0</td>\n",
       "      <td>t</td>\n",
       "      <td>0.91</td>\n",
       "      <td>t</td>\n",
       "      <td>120.0</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70.0</td>\n",
       "      <td>F</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>...</td>\n",
       "      <td>0.16</td>\n",
       "      <td>t</td>\n",
       "      <td>1.9</td>\n",
       "      <td>t</td>\n",
       "      <td>175.0</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70.0</td>\n",
       "      <td>F</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>...</td>\n",
       "      <td>0.72</td>\n",
       "      <td>t</td>\n",
       "      <td>1.2</td>\n",
       "      <td>t</td>\n",
       "      <td>61.0</td>\n",
       "      <td>t</td>\n",
       "      <td>0.87</td>\n",
       "      <td>t</td>\n",
       "      <td>70.0</td>\n",
       "      <td>SVI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    age sex on_thyroxine query_on_thyroxine on_antithyroid_medication sick  \\\n",
       "0  41.0   F            f                  f                         f    f   \n",
       "1  23.0   F            f                  f                         f    f   \n",
       "2  46.0   M            f                  f                         f    f   \n",
       "3  70.0   F            t                  f                         f    f   \n",
       "4  70.0   F            f                  f                         f    f   \n",
       "\n",
       "  pregnant thyroid_surgery I131_treatment query_hypothyroid  ...   TSH  \\\n",
       "0        f               f              f                 f  ...  1.30   \n",
       "1        f               f              f                 f  ...  4.10   \n",
       "2        f               f              f                 f  ...  0.98   \n",
       "3        f               f              f                 f  ...  0.16   \n",
       "4        f               f              f                 f  ...  0.72   \n",
       "\n",
       "  T3_measured   T3 TT4_measured    TT4 T4U_measured   T4U FTI_measured    FTI  \\\n",
       "0           t  2.5            t  125.0            t  1.14            t  109.0   \n",
       "1           t  2.0            t  102.0            f   NaN            f    NaN   \n",
       "2           f  NaN            t  109.0            t  0.91            t  120.0   \n",
       "3           t  1.9            t  175.0            f   NaN            f    NaN   \n",
       "4           t  1.2            t   61.0            t  0.87            t   70.0   \n",
       "\n",
       "  referral_source  \n",
       "0            SVHC  \n",
       "1           other  \n",
       "2           other  \n",
       "3           other  \n",
       "4             SVI  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X.drop(columns=['TBG', 'TBG_measured', 'hypopituitary'])\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "column_transformer = ColumnTransformer([\n",
    "    ('categorical', make_pipeline( \n",
    "                              SimpleImputer(strategy='most_frequent'), \n",
    "                              OneHotEncoder(drop='first')), \n",
    "     X.columns[X.dtypes.eq('object')]),\n",
    "    ('fillna', make_pipeline(\n",
    "        SimpleImputer(),\n",
    "        # otherwise svc gives a really bad score \n",
    "        StandardScaler()),\n",
    "     X.columns[X.dtypes.eq('float64')]),\n",
    "], remainder='passthrough')\n",
    "\n",
    "# Transform the data\n",
    "X_train = column_transformer.fit_transform(X_train)\n",
    "X_test = column_transformer.transform(X_test)\n",
    "\n",
    "# PS why did we transform it after splitting, if the next task envolves using a specific splitting\n",
    "# method, so we need to transform the whole dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = column_transformer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 <a id=\"task2_2\"></a> (0.7 points  = 0.4 for code + 0.3 for comments)\n",
    "\n",
    "Fit and compare 5 different models (use sklearn): Gradient Boosting, Random Forest, Decision Tree, SVM, Logitics Regression\n",
    "    \n",
    "* Choose one classification metric and justify your choice .\n",
    "* Compare the models using score on cross validation. Mind the class balance when choosing the cross validation. (You can read more about different CV strategies [here](https://scikit-learn.org/stable/modules/cross_validation.html#stratified-k-fold))\n",
    "* Which model has the best performance? Which models overfit or underfit?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we're trying to predict whether or not a patient has thyroid disease, it makes sense for us to predict as much true positive cases as possible, as false positives are far less dangerous then false negatives. In general, our metric should depend on what type of treatment we should give to that patient, as it might be dangerous for a healthy person. But ultimately, most treatments are disgned to be as safe as possible, so it should not be a big issue if we give some medicine a healthy person, especially if the downside is that we let a deadly disease go undiagnosed. This means we should use Recall as our metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use straified shuffle split for cross-validation, as it reduces class inbalance desparity between the training set and the testing set. (maybe we don't need to shuffle, but it does not hurt to do so)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bias_variance_classif(estimator, x, y, n_iter):\n",
    "    all_pred = np.full((n_iter, y.shape[0]), np.nan)\n",
    "    index = np.arange(y.shape[0])\n",
    "    \n",
    "    for i in range(n_iter):\n",
    "        x_index = np.random.choice(index, size=len(index), replace=True)\n",
    "        z_index = np.setdiff1d(index, x_index)\n",
    "        estimator.fit(x[x_index], y[x_index])\n",
    "        all_pred[i][z_index] = estimator.predict_proba(x[z_index])[:,1]\n",
    "        \n",
    "    avg_pred = np.nanmean(all_pred, axis=0)\n",
    "    bias2 = np.nanmean((avg_pred - y)**2)\n",
    "    variance = np.nanmean((avg_pred - all_pred)**2)\n",
    "    return bias2, variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier model: Bias: 1.02e-2, Variance: 0.16e-2, recall: 0.86\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "models = [\n",
    "    GradientBoostingClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    DecisionTreeClassifier(),\n",
    "    SVC(probability=True),\n",
    "    LogisticRegression()\n",
    "]\n",
    "\n",
    "def get_scores(model, X, y, n_iter=30):\n",
    "    splitter = StratifiedShuffleSplit(random_state=342)\n",
    "    scores = []\n",
    "    for train_index, test_index in splitter.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        model.fit(X_train, y_train)\n",
    "        bias, variance = get_bias_variance_classif(model, X_train, y_train, n_iter)\n",
    "        y_pred = model.predict(X_test)\n",
    "        scores.append([bias, variance, recall_score(y_test, y_pred)])\n",
    "    return np.array(scores).mean(axis=0)\n",
    "\n",
    "for model in models:\n",
    "    bias, variance, recall = get_scores(model, X, y, 30)\n",
    "    print(f\"{str(model)[:-2]} model: \", end=\"\")\n",
    "    print(f\"Bias: {100*bias:.2f}e-2, Variance: {100*variance:.2f}e-2, recall: {recall:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like SVC and Logistic Regression are underfitting. The bias scores for these models is pretty high. (makes sense, they're linear, after all)\n",
    "\n",
    "Other models are better at predicting: the bias is lower.\n",
    "\n",
    "The Decision tree had the highest variance of 0.0074 and it also had the best results for the recall score - 0.87. Clearly, this model is overfitting. \n",
    "\n",
    "RandomForest is the least overfitted with a variance of 0.0006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3 <a id=\"task2_3\"></a> (0.5 points = 0.4 for code + 0.1 for comments)\n",
    "\n",
    "More Gradient Boosting. Choose one of the three popular boosting implementations (xgboost, lightgbm, catboost). Select hyperparameters (number of trees, learning rate, depth) on cross-validation and compare with the methods from the previous task. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in d:\\anaconda3\\lib\\site-packages (1.5.0)\n",
      "Requirement already satisfied: numpy in d:\\anaconda3\\lib\\site-packages (from xgboost) (1.19.2)\n",
      "Requirement already satisfied: scipy in d:\\anaconda3\\lib\\site-packages (from xgboost) (1.5.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 599,\n",
       " 'max_depth': 52,\n",
       " 'learning_rate': 0.021544346900318846,\n",
       " 'eval_metric': 'logloss'}"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "scores = []\n",
    "params = {\n",
    "    'n_estimators': np.array(np.logspace(2,3,10), dtype=int),\n",
    "    'learning_rate': np.logspace(-5,0,10),\n",
    "    'max_depth': np.array(np.logspace(0.7, 3, 10), dtype=int),\n",
    "    'eval_metric': ['auc', 'aucpr', 'logloss']\n",
    "}\n",
    "rs = RandomizedSearchCV(XGBClassifier(), params, scoring='recall')\n",
    "rs.fit(X, y)\n",
    "rs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias score: 0.008341487065523175\n",
      "Variance score: 0.0017663857368206022\n",
      "Recall score: 0.8913043478260869\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "model = XGBClassifier(eval_metric='logloss', n_estimators=200, learning_rate=2e-2, max_depth=50)\n",
    "for metric, val in zip('Bias Variance Recall'.split(), get_scores(model, X, y, n_iter=30)):\n",
    "    print(f\"{metric} score: {val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bias score for this model is had the smallest value overall, as well as recall score. The results have imporved after some paramter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4 <a id=\"task2_4\"></a> (0.7 points = 0.4 for code + 0.3 for comments)\n",
    "\n",
    "Now let's train more fancy ensembles:\n",
    "\n",
    "* Bagging with decision trees as base estimators\n",
    "* Bagging with gradient boosting as base estimators (use large amount of trees in gradient boosting, >100)\n",
    "* [Voting classifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html#sklearn.ensemble.VotingClassifier) \n",
    "* [Stacking Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingClassifier.html#sklearn.ensemble.StackingClassifier) with Logistic Regression as a final model\n",
    "* [Stacking Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingClassifier.html#sklearn.ensemble.StackingClassifier) with Gradeint Boosting as a final model\n",
    "\n",
    "\n",
    "If not stated in the task, feel free to tune / choose hyperparameters and base models.\n",
    "\n",
    "Answer the questions:\n",
    "* Which model has the best performance?\n",
    "* Does bagging reduce overfitting of the gradient boosting with large amount of trees? \n",
    "* What is the difference between voting and staking? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging DecTree model: Bias: 0.91e-2, Variance: 0.24e-2, recall: 0.86\n",
      "Bagging GradBoost model: Bias: 1.01e-2, Variance: 0.15e-2, recall: 0.84\n",
      "Voting model: Bias: 0.93e-2, Variance: 0.08e-2, recall: 0.83\n",
      "Stacking Logres model: Bias: 0.94e-2, Variance: 0.15e-2, recall: 0.83\n",
      "Staking GradBoost model: Bias: 0.91e-2, Variance: 0.47e-2, recall: 0.86\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier, VotingClassifier, StackingClassifier\n",
    "\n",
    "estimator_list = list(zip('GradBoost, RandomForest, XGB'.split(', '), [\n",
    "    GradientBoostingClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    XGBClassifier(eval_metric='logloss', n_estimators=200, learning_rate=2e-2, max_depth=30)\n",
    "]))\n",
    "\n",
    "models = [\n",
    "    BaggingClassifier(DecisionTreeClassifier()),\n",
    "    BaggingClassifier(GradientBoostingClassifier(n_estimators=250)),\n",
    "    VotingClassifier(estimator_list, voting='soft'),\n",
    "    StackingClassifier(estimator_list, LogisticRegression()),\n",
    "    StackingClassifier(estimator_list, GradientBoostingClassifier()),\n",
    "]\n",
    "                      \n",
    "names = 'Bagging DecTree, Bagging GradBoost, Voting, Stacking Logres, Staking GradBoost'\n",
    "for name, model in zip(names.split(', '), models):\n",
    "    bias, variance, recall = get_scores(model, X, y)\n",
    "    print(f\"{name} model: \", end=\"\")\n",
    "    print(f\"Bias: {100*bias:.2f}e-2, Variance: {100*variance:.2f}e-2, recall: {recall:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same gradient boost with no bagging:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradBoost(n=250) model: Bias: 0.95e-2, Variance: 0.24e-2, recall: 0.84\n"
     ]
    }
   ],
   "source": [
    "bias, variance, recall = get_scores(GradientBoostingClassifier(n_estimators=250), X, y, 30)\n",
    "print(f\"GradBoost(n=250) model: \", end=\"\")\n",
    "print(f\"Bias: {100*bias:.2f}e-2, Variance: {100*variance:.2f}e-2, recall: {recall:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. XGBClassifier model produced the best results - 0.89\n",
    "2. Yes, but only a little bit less variance: 0.0015 vs 0.0024\n",
    "3. Both models take multiple estimators and make a prediction for every one of them. The difference is that the voting model combines these predictions with a certain weight, and the stacking model stacks the output of these models together and then uses another model to make the final prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5 <a id=\"task2_5\"></a> (0.1 points)\n",
    "\n",
    "Report the test score for the best model, that you were able to get on this dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bagging with the Gradient Boost model produced the best results - 0.89"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
